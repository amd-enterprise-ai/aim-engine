# Service with autoscaling configuration
# Verifies minReplicas, maxReplicas, and autoScaling propagate to InferenceService
apiVersion: aim.eai.amd.com/v1alpha1
kind: AIMService
metadata:
  name: test-autoscaling-service
spec:
  model:
    name: test-autoscaling-model

  # Autoscaling configuration
  minReplicas: 1
  maxReplicas: 3

  # Advanced autoscaling with custom metrics
  autoScaling:
    metrics:
      - type: PodMetric
        podmetric:
          metric:
            backend: "opentelemetry"
            metricNames:
              - vllm:num_requests_running
            query: "vllm:num_requests_running"
            operationOverTime: "avg"
          target:
            type: Value
            value: "1"
