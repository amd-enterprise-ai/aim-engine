{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AIM Engine","text":"<p>AIM (AMD Inference Microservice) Engine is a Kubernetes operator that simplifies the deployment and management of AI inference workloads on AMD GPUs. It provides a declarative, cloud-native approach to running ML models at scale.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Deploy an inference service with a single resource:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <p>AIM images (like <code>amdenterpriseai/aim-qwen-qwen3-32b</code>) are container images that package open-source models optimized for AMD Instinct GPUs. Each image includes the model weights and a serving runtime tuned for specific GPU configurations and precision modes.</p> <p>AIM Engine automatically resolves the model, selects an optimal runtime configuration for your hardware, deploys a KServe InferenceService, and optionally creates HTTP routing through Gateway API.</p>"},{"location":"#where-to-start","title":"Where to Start","text":"<ul> <li> <p> Cluster Administrators</p> <p>Install AIM Engine, configure KServe, manage GPU resources, and set up cluster-wide defaults.</p> <p> Installation</p> </li> <li> <p> Developers &amp; Integrators</p> <p>Deploy inference services, configure scaling, set up routing, and integrate with your applications.</p> <p> Quickstart</p> </li> <li> <p> Data Scientists</p> <p>Browse the model catalog, deploy models for experimentation, and tune inference parameters.</p> <p> Model Catalog</p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simple Service Deployment -- Deploy inference endpoints with minimal configuration using <code>AIMService</code> resources</li> <li>Automatic Optimization -- Smart template selection picks the best runtime profile based on GPU availability, precision, and optimization goals</li> <li>Model Catalog -- Maintain a catalog of available models with automatic discovery from container registries</li> <li>Model Caching -- Pre-download model artifacts to shared PVCs for faster startup and reduced bandwidth</li> <li>HTTP Routing -- Expose services through Gateway API with customizable path templates</li> <li>Autoscaling -- KEDA integration with OpenTelemetry metrics for demand-based scaling</li> <li>Multi-tenancy -- Namespace-scoped and cluster-scoped resources for flexible team isolation</li> </ul>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation -- Prerequisites and Helm chart installation</li> <li>Quickstart -- Deploy your first model in 5 minutes</li> <li>Architecture -- High-level architecture and component overview</li> </ul>"},{"location":"#guides","title":"Guides","text":"<p>Task-oriented walkthroughs for common workflows:</p> <ul> <li>Deploying Services -- Deploy and manage inference endpoints</li> <li>Model Catalog -- Browse and select models</li> <li>Scaling and Autoscaling -- Replicas, KEDA, and metrics</li> <li>Model Caching -- Pre-cache models for faster startup</li> <li>Routing and Ingress -- Gateway API patterns and path templates</li> <li>Private Registries -- Authentication for HuggingFace, S3, and OCI</li> <li>Multi-Tenancy -- Namespace isolation patterns</li> </ul>"},{"location":"#administration","title":"Administration","text":"<ul> <li>Installation Reference -- Full install reference with all Helm values</li> <li>KServe Configuration -- Install and configure KServe</li> <li>GPU Management -- GPU allocation, node selectors, topology</li> <li>Storage Configuration -- PVCs, shared storage for caching</li> <li>Upgrading -- Version migration and CRD upgrades</li> <li>Monitoring -- Metrics, observability, and log formats</li> <li>Troubleshooting -- Common issues and diagnostic steps</li> <li>Security -- RBAC, network policies, and secrets management</li> </ul>"},{"location":"#concepts","title":"Concepts","text":"<ul> <li>AIM Services -- Service deployment lifecycle, template selection, and caching</li> <li>AIM Models -- Model catalog, discovery, and resolution</li> <li>Model Sources -- Automatic model discovery from container registries</li> <li>Service Templates -- Runtime profiles, derivation, and discovery cache</li> <li>Runtime Configuration -- Storage defaults, routing, and environment resolution</li> <li>Model Caching -- Cache hierarchy, ownership, and deletion behavior</li> <li>Resource Lifecycle -- Ownership, finalizers, and deletion behavior</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>CRD API Reference -- Complete API specification for all custom resources</li> <li>Helm Chart Values -- All configurable Helm chart values</li> <li>CLI and Operator Flags -- Operator binary flags and endpoints</li> <li>Environment Variables -- Operator and downloader configuration</li> <li>Naming and Labels -- Derived naming algorithm and label conventions</li> <li>Conditions -- Full catalog of conditions across all CRDs</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>See GitHub Releases for release notes and version history.</p>"},{"location":"admin/gpu-management/","title":"GPU Management","text":"<p>AIM Engine detects available GPUs in the cluster and uses this information for template selection and node scheduling.</p>"},{"location":"admin/gpu-management/#gpu-detection","title":"GPU Detection","text":"<p>AIM Engine detects GPUs through node labels set by the AMD GPU device plugin.</p>"},{"location":"admin/gpu-management/#amd-gpu-labels","title":"AMD GPU Labels","text":"Label Description Example <code>amd.com/gpu.device-id</code> PCI device ID <code>74a1</code> <code>amd.com/gpu.family</code> GPU family <code>MI300X</code> <code>amd.com/gpu.vram</code> VRAM in MiB <code>196608</code> <p>Legacy labels with <code>beta.amd.com/</code> prefix are also supported.</p>"},{"location":"admin/gpu-management/#template-selection-and-gpus","title":"Template Selection and GPUs","text":"<p>During template auto-selection, AIM Engine filters templates to only those whose required GPU is available in the cluster. A template requiring MI325X GPUs is excluded if no MI325X nodes exist.</p> <p>GPU preference scoring (highest to lowest): MI325X &gt; MI300X &gt; MI250X &gt; MI210.</p>"},{"location":"admin/gpu-management/#gpu-resource-requests","title":"GPU Resource Requests","text":"<p>Templates specify GPU requirements that translate to Kubernetes resource requests:</p> <pre><code># In an AIMServiceTemplate profile\nhardware:\n  gpu:\n    model: MI300X\n    requests: 4\n</code></pre> <p>This results in the inference pod requesting <code>amd.com/gpu: 4</code>.</p>"},{"location":"admin/gpu-management/#node-affinity","title":"Node Affinity","text":"<p>AIM Engine automatically configures node affinity on inference pods to schedule them on nodes with the correct GPU. It matches the <code>amd.com/gpu.device-id</code> label against the device IDs for the required GPU model.</p>"},{"location":"admin/gpu-management/#verifying-gpu-availability","title":"Verifying GPU Availability","text":"<p>Check which GPU labels are present on your nodes:</p> <pre><code>kubectl get nodes -o custom-columns='NAME:.metadata.name,DEVICE_ID:.metadata.labels.amd\\.com/gpu\\.device-id,FAMILY:.metadata.labels.amd\\.com/gpu\\.family,VRAM:.metadata.labels.amd\\.com/gpu\\.vram'\n</code></pre>"},{"location":"admin/gpu-management/#next-steps","title":"Next Steps","text":"<ul> <li>AIM Services \u2014 Template selection algorithm</li> <li>Service Templates \u2014 Runtime profiles and GPU requirements</li> </ul>"},{"location":"admin/installation/","title":"Installation Reference","text":"<p>This page covers advanced installation options for AIM Engine. For a basic install, see the Getting Started guide.</p>"},{"location":"admin/installation/#helm-chart-configuration","title":"Helm Chart Configuration","text":"<p>All configuration is done through Helm values. See Helm Chart Values for the complete reference.</p>"},{"location":"admin/installation/#operator-resources","title":"Operator Resources","text":"<p>Adjust operator resource limits for larger clusters:</p> <pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --create-namespace \\\n  --set manager.resources.limits.memory=8Gi \\\n  --set manager.resources.requests.memory=512Mi\n</code></pre>"},{"location":"admin/installation/#leader-election","title":"Leader Election","text":"<p>Leader election is enabled by default (<code>--leader-elect</code> in <code>manager.args</code>). This ensures only one operator instance is active when running multiple replicas for high availability.</p>"},{"location":"admin/installation/#metrics","title":"Metrics","text":"<p>The metrics endpoint is enabled by default on port 8443 with TLS. To disable TLS for the metrics endpoint:</p> <pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --set 'manager.args={--leader-elect,--metrics-secure=false}'\n</code></pre>"},{"location":"admin/installation/#crd-management","title":"CRD Management","text":"<p>CRDs are distributed as a separate Helm chart and should be installed before the operator. See Installation.</p>"},{"location":"admin/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Helm Chart Values \u2014 Full values reference</li> <li>KServe Configuration \u2014 Configure the KServe dependency</li> <li>Security \u2014 RBAC and pod security configuration</li> </ul>"},{"location":"admin/kserve-configuration/","title":"KServe Configuration","text":"<p>AIM Engine requires KServe v0.16.1 or later with specific configuration. Use the values file below when installing KServe.</p>"},{"location":"admin/kserve-configuration/#required-values","title":"Required Values","text":"<pre><code># kserve-values.yaml\nkserve:\n  controller:\n    deploymentMode: Standard\n    gateway:\n      ingressGateway:\n        enableGatewayApi: false\n  localmodel:\n    enabled: false\n  inferenceservice:\n    resources:\n      limits:\n        cpu: \"\"\n        memory: \"\"\n      requests:\n        cpu: \"\"\n        memory: \"\"\n</code></pre>"},{"location":"admin/kserve-configuration/#installation","title":"Installation","text":"<pre><code>helm install kserve-crd oci://ghcr.io/kserve/charts/kserve-crd \\\n  --namespace kserve-system \\\n  --create-namespace \\\n  --version v0.16.1\n\nhelm install kserve oci://ghcr.io/kserve/charts/kserve \\\n  --namespace kserve-system \\\n  --version v0.16.1 \\\n  --values kserve-values.yaml\n</code></pre>"},{"location":"admin/kserve-configuration/#why-these-values-matter","title":"Why These Values Matter","text":""},{"location":"admin/kserve-configuration/#resource-limits-critical","title":"Resource Limits (Critical)","text":"<p>Warning</p> <p>Without clearing the default resource limits, AIM Engine deployments will fail.</p> <p>KServe applies default CPU and memory limits (<code>cpu: 1</code>, <code>memory: 2Gi</code>) to all InferenceService containers. AIM Engine sets CPU requests based on GPU count (4 CPUs per GPU) but intentionally does not set CPU limits, allowing inference workloads to burst and fully utilize available CPU for optimal throughput. KServe's default limit of <code>1</code> conflicts with the calculated request, causing Kubernetes to reject the pod.</p> <p>For GPU workloads, AIM Engine also sets memory defaults per GPU (<code>requests.memory: 32Gi</code>, <code>limits.memory: 48Gi</code>), unless overridden by template/service resources. Clearing KServe defaults avoids accidental request/limit mismatches and hidden caps when resources are omitted or partially overridden.</p> <p>Setting limits and requests to <code>\"\"</code> removes the defaults so AIM Engine controls per-workload CPU/memory behavior.</p>"},{"location":"admin/kserve-configuration/#deployment-mode","title":"Deployment Mode","text":"<p>AIM Engine uses KServe in Standard mode (without Knative) to support KEDA-based autoscaling with OpenTelemetry metrics.</p>"},{"location":"admin/kserve-configuration/#local-model-cache","title":"Local Model Cache","text":"<p>AIM Engine manages model caching independently via AIMArtifact and AIMTemplateCache resources. KServe's built-in local model feature must be disabled to avoid conflicts.</p> <p>This is already configured in the values snippet above via <code>kserve.localmodel.enabled: false</code> (and in the repository's local dependency Helmfile).</p>"},{"location":"admin/kserve-configuration/#verifying-configuration","title":"Verifying Configuration","text":"<p>After installation, verify the resource limits are removed:</p> <pre><code>kubectl get configmap -n kserve-system inferenceservice-config -o jsonpath='{.data.inferenceService}'\n</code></pre> <p>The output should show empty or missing <code>cpuLimit</code> and <code>memoryLimit</code> values.</p>"},{"location":"admin/monitoring/","title":"Monitoring and Observability","text":"<p>AIM Engine exposes metrics and structured logs for monitoring operator health and inference workloads.</p>"},{"location":"admin/monitoring/#metrics","title":"Metrics","text":""},{"location":"admin/monitoring/#endpoint","title":"Endpoint","text":"<p>The controller exposes metrics on port 8443 (HTTPS by default). Configure via Helm:</p> Value Default Description <code>metrics.enable</code> <code>true</code> Enable metrics endpoint <code>metrics.port</code> <code>8443</code> Metrics port"},{"location":"admin/monitoring/#prometheus-servicemonitor","title":"Prometheus ServiceMonitor","text":"<p>Enable automatic scraping with Prometheus:</p> <pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --set prometheus.enable=true\n</code></pre> <p>This creates a <code>ServiceMonitor</code> resource that Prometheus Operator picks up automatically.</p>"},{"location":"admin/monitoring/#controller-runtime-metrics","title":"Controller Runtime Metrics","text":"<p>AIM Engine exposes standard controller-runtime metrics:</p> <ul> <li><code>controller_runtime_reconcile_total</code> \u2014 Total reconciliations by controller and result</li> <li><code>controller_runtime_reconcile_errors_total</code> \u2014 Total reconciliation errors</li> <li><code>controller_runtime_reconcile_time_seconds</code> \u2014 Reconciliation duration</li> <li><code>workqueue_depth</code> \u2014 Current work queue depth per controller</li> </ul>"},{"location":"admin/monitoring/#logs","title":"Logs","text":""},{"location":"admin/monitoring/#format","title":"Format","text":"<p>Operator logs are JSON-formatted with these key fields:</p> Field Description Example <code>level</code> Log level <code>info</code>, <code>error</code>, <code>debug</code> <code>controller</code> Controller name <code>artifact</code>, <code>service</code>, <code>model</code> <code>namespace</code> Resource namespace <code>ml-team</code> <code>name</code> Resource name <code>qwen-chat</code> <code>condition</code> Condition being updated <code>Ready</code> <code>status</code> Condition status <code>True</code>, <code>False</code> <code>reason</code> Condition reason <code>RuntimeReady</code>"},{"location":"admin/monitoring/#log-levels","title":"Log Levels","text":"<p>Configure via operator flags:</p> Flag Values Default <code>--zap-log-level</code> <code>debug</code>, <code>info</code>, <code>error</code>, or integer <code>info</code> <code>--zap-encoder</code> <code>json</code>, <code>console</code> <code>json</code> <code>--zap-devel</code> \u2014 <code>false</code> (production mode) <p>Enable debug logging in Helm:</p> <pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --set 'manager.args={--leader-elect,--zap-log-level=debug}'\n</code></pre>"},{"location":"admin/monitoring/#useful-log-queries","title":"Useful Log Queries","text":"<pre><code># View operator logs\nkubectl logs -n aim-system deployment/aim-engine-controller-manager -f\n\n# Filter for errors\nkubectl logs -n aim-system deployment/aim-engine-controller-manager | \\\n  jq 'select(.level == \"error\")'\n\n# Filter by controller\nkubectl logs -n aim-system deployment/aim-engine-controller-manager | \\\n  jq 'select(.controller == \"aimservice\")'\n\n# Filter by namespace\nkubectl logs -n aim-system deployment/aim-engine-controller-manager | \\\n  jq 'select(.namespace == \"ml-team\")'\n</code></pre>"},{"location":"admin/monitoring/#kubernetes-events","title":"Kubernetes Events","text":"<p>The operator emits Kubernetes Events on AIM resources when conditions change. Events provide a timeline of state transitions visible via <code>kubectl describe</code>.</p>"},{"location":"admin/monitoring/#event-types","title":"Event Types","text":"Type When Emitted <code>Normal</code> Condition transitions to a healthy state <code>Warning</code> Condition transitions to an unhealthy state, or persists unhealthy on every reconcile"},{"location":"admin/monitoring/#event-reasons","title":"Event Reasons","text":"<p>Events use the condition's <code>reason</code> field as the event reason. Common event reasons:</p> <p>AIMService:</p> Reason Type Description <code>ModelResolved</code> Normal Model found and ready <code>ModelNotFound</code> Warning Referenced model does not exist <code>Resolved</code> Normal Template resolved successfully <code>TemplateSelectionAmbiguous</code> Warning Multiple templates scored equally <code>CacheReady</code> Normal Model cache is populated <code>CacheFailed</code> Warning Cache download failed <code>RuntimeReady</code> Normal InferenceService is serving <code>InvalidImageReference</code> Warning Model image URI is invalid <code>PathTemplateInvalid</code> Warning Routing path template failed to resolve <p>AIMModel:</p> Reason Type Description <code>AllTemplatesReady</code> Normal All discovered templates are ready <code>AllTemplatesFailed</code> Warning All discovered templates failed <code>MetadataExtractionFailed</code> Warning Failed to extract model metadata <p>AIMArtifact:</p> Reason Type Description <code>Verified</code> Normal Download complete and verified <code>Downloading</code> Normal Download in progress"},{"location":"admin/monitoring/#viewing-events","title":"Viewing Events","text":"<pre><code># Events for a specific resource\nkubectl describe aimservice qwen-chat -n &lt;namespace&gt;\n\n# All AIM-related events in a namespace\nkubectl get events -n &lt;namespace&gt; --field-selector involvedObject.apiVersion=aim.eai.amd.com/v1alpha1\n</code></pre>"},{"location":"admin/monitoring/#recurring-events","title":"Recurring Events","text":"<p>Some warning events are emitted on every reconcile (not just on transitions) for critical conditions that remain unhealthy. These are useful for alerting \u2014 a persistent stream of warnings indicates a stuck or failing resource.</p> <p>See Conditions Reference for the full catalog of conditions and reasons.</p>"},{"location":"admin/monitoring/#health-probes","title":"Health Probes","text":"<p>The operator exposes health and readiness probes:</p> Probe Path Port Liveness <code>/healthz</code> 8081 Readiness <code>/readyz</code> 8081 <p>These are configured automatically in the Helm chart deployment.</p>"},{"location":"admin/monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting \u2014 Diagnosing common issues</li> <li>CLI and Operator Flags \u2014 Full operator flag reference</li> </ul>"},{"location":"admin/security/","title":"Security","text":"<p>Security configuration for AIM Engine deployments.</p>"},{"location":"admin/security/#pod-security","title":"Pod Security","text":"<p>The operator runs with restrictive security defaults:</p> Setting Value <code>runAsNonRoot</code> <code>true</code> <code>readOnlyRootFilesystem</code> <code>true</code> <code>allowPrivilegeEscalation</code> <code>false</code> <code>capabilities.drop</code> <code>ALL</code> <code>seccompProfile.type</code> <code>RuntimeDefault</code> <p>These are configured in the Helm chart and can be adjusted via <code>manager.podSecurityContext</code> and <code>manager.securityContext</code> values.</p>"},{"location":"admin/security/#rbac","title":"RBAC","text":""},{"location":"admin/security/#operator-permissions","title":"Operator Permissions","text":"<p>The operator runs with a ClusterRole (<code>aim-engine-manager-role</code>) that grants:</p> <ul> <li>Full access to all AIM CRDs (<code>aim.eai.amd.com</code>)</li> <li>Read access to nodes, namespaces, pods, secrets</li> <li>Manage PVCs, jobs, and events</li> <li>Create/manage KServe InferenceServices</li> <li>Create/manage Gateway API HTTPRoutes</li> <li>Read storage classes</li> </ul>"},{"location":"admin/security/#helper-roles","title":"Helper Roles","text":"<p>When <code>rbacHelpers.enable</code> is <code>true</code> (default), the chart creates admin/editor/viewer ClusterRoles for each CRD:</p> Role Pattern Permissions <code>{crd}-admin</code> Full access including status <code>{crd}-editor</code> Create, update, delete <code>{crd}-viewer</code> Read-only <p>Available for: <code>aimservice</code>, <code>aimmodel</code>, <code>aimclustermodel</code>, <code>aimartifact</code>, <code>aimtemplatecache</code>, <code>aimservicetemplate</code>, <code>aimclusterservicetemplate</code>, <code>aimruntimeconfig</code>, <code>aimclusterruntimeconfig</code>.</p>"},{"location":"admin/security/#example-team-rbac","title":"Example: Team RBAC","text":"<p>Grant a team editor access to services and viewer access to cluster resources:</p> <pre><code># Edit services in their namespace\nkubectl create rolebinding team-a-services \\\n  --clusterrole=aimservice-editor \\\n  --group=team-a \\\n  --namespace=ml-team-a\n\n# View cluster models (read-only)\nkubectl create clusterrolebinding team-a-models \\\n  --clusterrole=aimclustermodel-viewer \\\n  --group=team-a\n</code></pre>"},{"location":"admin/security/#tls","title":"TLS","text":""},{"location":"admin/security/#metrics-endpoint","title":"Metrics Endpoint","text":"<p>The metrics endpoint serves over HTTPS by default (port 8443). Provide certificates via:</p> <ul> <li>cert-manager \u2014 Set <code>certManager.enable: true</code> in Helm values</li> <li>Manual \u2014 Mount certificates and set <code>--metrics-cert-path</code></li> </ul> <p>To disable TLS for metrics (not recommended for production):</p> <pre><code>--set 'manager.args={--leader-elect,--metrics-secure=false}'\n</code></pre>"},{"location":"admin/security/#secrets-management","title":"Secrets Management","text":"<p>Sensitive credentials (registry tokens, S3 keys) are managed through Kubernetes Secrets referenced in runtime configurations:</p> <pre><code>spec:\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: hf-credentials\n          key: token\n</code></pre> <p>The operator reads these references but never stores credential values in CRD status or logs.</p>"},{"location":"admin/security/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Tenancy \u2014 Team isolation patterns</li> <li>Installation Reference \u2014 Helm security values</li> <li>Private Registries \u2014 Credential configuration</li> </ul>"},{"location":"admin/storage-configuration/","title":"Storage Configuration","text":"<p>AIM Engine uses persistent volumes for model caching. This guide covers storage setup and sizing.</p>"},{"location":"admin/storage-configuration/#requirements","title":"Requirements","text":"<p>Model caching requires <code>ReadWriteMany</code> (RWX) persistent volumes so that multiple pods can mount the same cached model data. You need a CSI driver that supports RWX access mode, such as:</p> <ul> <li>Longhorn</li> <li>CephFS</li> <li>NFS-based provisioners</li> </ul>"},{"location":"admin/storage-configuration/#default-storage-class","title":"Default Storage Class","text":"<p>Set the default storage class for all AIM PVCs via cluster runtime configuration:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  storage:\n    defaultStorageClassName: longhorn\n</code></pre> <p>Without this setting, AIM Engine uses the cluster's default storage class.</p>"},{"location":"admin/storage-configuration/#pvc-headroom","title":"PVC Headroom","text":"<p>AIM Engine sizes PVCs based on discovered model sizes plus a configurable headroom percentage. This accounts for filesystem overhead and temporary files during downloads.</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  storage:\n    pvcHeadroomPercent: 15\n</code></pre> <p>The default headroom is 10%. The final PVC size is rounded up to the nearest GiB.</p>"},{"location":"admin/storage-configuration/#storage-sizing-guidelines","title":"Storage Sizing Guidelines","text":"<p>Model storage requirements vary significantly:</p> Model Size Category Approximate Storage Example Small (7-8B params) 15-20 GiB Qwen3 8B Medium (30-70B params) 60-140 GiB Qwen3 32B, DeepSeek R1 70B Large (100B+ params) 200+ GiB Mixtral 8x22B <p>These are per-model estimates. A template cache PVC holds all model sources for that template.</p>"},{"location":"admin/storage-configuration/#monitoring-storage","title":"Monitoring Storage","text":"<p>Check PVC usage:</p> <pre><code># List AIM-related PVCs\nkubectl get pvc -l aim.eai.amd.com/artifact -n &lt;namespace&gt;\n\n# Check artifact download status\nkubectl get aimartifact -n &lt;namespace&gt;\n</code></pre>"},{"location":"admin/storage-configuration/#cleanup","title":"Cleanup","text":"<p>Template cache PVCs are owned by <code>AIMTemplateCache</code> resources, which are owned by templates. When a template is deleted, its caches and PVCs are cleaned up automatically.</p> <p>To manually reclaim storage:</p> <pre><code># Delete a template cache (also deletes its PVCs and artifacts)\nkubectl delete aimtemplatecache &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"admin/storage-configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Model Caching Guide \u2014 Caching modes and configuration</li> <li>Model Caching Concepts \u2014 Cache hierarchy and ownership</li> </ul>"},{"location":"admin/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and diagnostic steps for AIM Engine.</p>"},{"location":"admin/troubleshooting/#service-status","title":"Service Status","text":"<p>Check the overall status:</p> <pre><code>kubectl get aimservice &lt;name&gt; -n &lt;namespace&gt;\n</code></pre> <p>For detailed diagnostics, inspect conditions and component health:</p> <pre><code>kubectl get aimservice &lt;name&gt; -n &lt;namespace&gt; -o jsonpath='{.status.conditions}' | jq\n</code></pre>"},{"location":"admin/troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"admin/troubleshooting/#service-stuck-in-pending","title":"Service Stuck in \"Pending\"","text":"<p>The service is waiting for upstream dependencies.</p> <p>Check which conditions are blocking readiness:</p> <pre><code>kubectl get aimservice &lt;name&gt; -n &lt;namespace&gt; -o jsonpath='{.status.conditions}' | jq\n</code></pre> Blocked Component Likely Cause Model Model not found \u2014 check <code>model.name</code> spelling or <code>model.image</code> accessibility Template No matching template \u2014 verify templates exist and are <code>Ready</code> RuntimeConfig Runtime config not found or invalid"},{"location":"admin/troubleshooting/#service-stuck-in-starting","title":"Service Stuck in \"Starting\"","text":"<p>Downstream resources are being created but haven't become ready.</p> <p>Check the InferenceService:</p> <pre><code>kubectl get inferenceservice -n &lt;namespace&gt; -l aim.eai.amd.com/service.name=&lt;name&gt;\nkubectl describe inferenceservice &lt;isvc-name&gt; -n &lt;namespace&gt;\n</code></pre> <p>Check pods:</p> <pre><code>kubectl get pods -l serving.kserve.io/inferenceservice=&lt;isvc-name&gt; -n &lt;namespace&gt;\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre> <p>Use the InferenceService name returned by the first command as <code>&lt;isvc-name&gt;</code>.</p> <p>Common causes:</p> <ul> <li>Image pull errors \u2014 Wrong image URL or missing imagePullSecrets</li> <li>Insufficient resources \u2014 Not enough GPU, memory, or CPU available</li> <li>PVC not binding \u2014 Storage class doesn't support RWX, or insufficient capacity</li> </ul>"},{"location":"admin/troubleshooting/#template-selection-fails","title":"Template Selection Fails","text":"<p>\"No templates found\":</p> <pre><code># List templates for the model\nkubectl get aimservicetemplates -n &lt;namespace&gt;\nkubectl get aimclusterservicetemplates\n\n# Check template status\nkubectl get aimservicetemplates -o custom-columns=NAME:.metadata.name,STATUS:.status.status\n</code></pre> <p>Templates may be excluded because:</p> <ul> <li>Status is not <code>Ready</code> (still discovering or failed)</li> <li>Status is <code>NotAvailable</code> (required GPU not in cluster)</li> <li>Profile is <code>unoptimized</code> and <code>allowUnoptimized</code> is not set</li> </ul> <p>\"Ambiguous selection\":</p> <p>Multiple templates scored equally. Resolve by specifying <code>template.name</code> explicitly.</p>"},{"location":"admin/troubleshooting/#cache-or-artifact-failures","title":"Cache or Artifact Failures","text":"<pre><code># Check template cache\nkubectl get aimtemplatecache -n &lt;namespace&gt;\n\n# Check artifacts\nkubectl get aimartifact -n &lt;namespace&gt;\n\n# Check download job\nkubectl get jobs -l aim.eai.amd.com/artifact=&lt;artifact-name&gt; -n &lt;namespace&gt;\nkubectl logs job/&lt;job-name&gt; -n &lt;namespace&gt;\n</code></pre> <p>Common causes:</p> <ul> <li>StorageSizeError \u2014 Model size not yet discovered; typically resolves automatically</li> <li>Download failure \u2014 Network issues, authentication errors, or protocol incompatibility</li> <li>PVC binding failure \u2014 Storage class doesn't support <code>ReadWriteMany</code></li> </ul>"},{"location":"admin/troubleshooting/#routing-not-working","title":"Routing Not Working","text":"<pre><code># Check HTTPRoute\nkubectl get httproute -n &lt;namespace&gt;\nkubectl describe httproute &lt;name&gt; -n &lt;namespace&gt;\n\n# Check the gateway\nkubectl get gateway -n &lt;gateway-namespace&gt;\n</code></pre> <p>Common causes:</p> <ul> <li>Gateway doesn't exist or isn't ready</li> <li><code>routing.enabled</code> is not set (check runtime config)</li> <li>Gateway namespace mismatch in <code>gatewayRef</code></li> </ul>"},{"location":"admin/troubleshooting/#operator-logs","title":"Operator Logs","text":"<p>View operator logs for detailed error information:</p> <pre><code>kubectl logs -n aim-system deployment/aim-engine-controller-manager -f\n</code></pre> <p>Filter for errors related to a specific resource:</p> <pre><code>kubectl logs -n aim-system deployment/aim-engine-controller-manager | \\\n  jq 'select(.name == \"&lt;resource-name&gt;\")'\n</code></pre>"},{"location":"admin/troubleshooting/#status-values","title":"Status Values","text":"Status Meaning <code>Pending</code> Waiting for upstream dependencies <code>Starting</code> Creating downstream resources <code>Progressing</code> Resources created, waiting for readiness <code>Running</code> Fully operational <code>Ready</code> Resource is ready (for non-service CRDs) <code>Degraded</code> Partially functional <code>NotAvailable</code> Required infrastructure not present <code>Failed</code> Critical failure"},{"location":"admin/troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring \u2014 Log format and metrics details</li> <li>CLI and Operator Flags \u2014 Enable debug logging</li> </ul>"},{"location":"admin/upgrading/","title":"Upgrading","text":"<p>This guide covers upgrading AIM Engine to a new version.</p>"},{"location":"admin/upgrading/#upgrade-procedure","title":"Upgrade Procedure","text":""},{"location":"admin/upgrading/#1-update-crds-first","title":"1. Update CRDs First","text":"<p>CRDs must be updated before the operator, as new operator versions may depend on new CRD fields:</p> <pre><code>helm upgrade aim-engine-crds oci://docker.io/amdenterpriseai/charts/aim-engine-crds \\\n  --version &lt;new-version&gt; \\\n  --namespace aim-system\n</code></pre>"},{"location":"admin/upgrading/#2-upgrade-the-operator","title":"2. Upgrade the Operator","text":"<pre><code>helm upgrade aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;new-version&gt; \\\n  --namespace aim-system \\\n  --reuse-values\n</code></pre> <p>Or with updated values:</p> <pre><code>helm upgrade aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;new-version&gt; \\\n  --namespace aim-system \\\n  --values my-values.yaml\n</code></pre>"},{"location":"admin/upgrading/#3-verify","title":"3. Verify","text":"<pre><code>kubectl get pods -n aim-system\nkubectl get aimservice --all-namespaces\n</code></pre>"},{"location":"admin/upgrading/#rollback","title":"Rollback","text":"<p>Roll back to the previous Helm release:</p> <pre><code>helm rollback aim-engine -n aim-system\n</code></pre> <p>Note</p> <p>Rolling back the operator does not roll back CRD changes. New CRD fields are additive and backward compatible. If a CRD change is not backward compatible, this will be noted in the release notes.</p>"},{"location":"admin/upgrading/#version-compatibility","title":"Version Compatibility","text":"<p>AIM Engine follows semantic versioning. Within a major version:</p> <ul> <li>CRD changes are additive (new optional fields)</li> <li>Existing resources continue to work without modification</li> <li>API group remains <code>aim.eai.amd.com/v1alpha1</code></li> </ul>"},{"location":"admin/upgrading/#next-steps","title":"Next Steps","text":"<ul> <li>Installation Reference \u2014 Full installation options</li> <li>Changelog \u2014 Release notes and changes</li> </ul>"},{"location":"concepts/caching/","title":"Model Caching","text":"<p>AIM provides a hierarchical caching system that allows model artifacts to be pre-downloaded and shared across services in the same namespace. This document explains the caching architecture, resource lifecycle, and deletion behavior.</p>"},{"location":"concepts/caching/#overview","title":"Overview","text":"<p>Model caching in AIM uses three resource types:</p> <ol> <li>AIMArtifact: Manages the model artifacts download process onto a PVC</li> <li>AIMTemplateCache: Groups <code>AIMArtifacts</code> for a specific template and allows caching a cluster-scoped <code>AIMClusterServiceTemplate</code> into a specific namespace.</li> <li>AIMService: Can trigger template cache creation via <code>spec.caching.mode: Shared|Dedicated</code>. See AIM Services for more information.</li> </ol>"},{"location":"concepts/caching/#shared-and-dedicated-mode","title":"Shared and dedicated mode","text":"<p>An AIMTemplateCache can run in two modes, which differ by who creates it and how <code>AIMArtifacts</code> are owned:</p> <ul> <li>Shared mode (<code>spec.mode: Shared</code>, default): AIMArtifacts created by the template cache have no owner references. They persist independently and can be reused by other template caches or services. Used when the template creates the cache (template caching enabled; that template cache is template-owned) or when the service uses <code>spec.caching.mode: Shared</code> (service creates or reuses shared caches).</li> <li>Dedicated mode (<code>spec.mode: Dedicated</code>): AIMArtifacts are owned by the template cache. When the template cache is deleted, its artifacts are garbage-collected. Used when the service uses <code>spec.caching.mode: Dedicated</code>; the template cache is then owned by the service and cleaned up with it. Dedicated template caches and artifacts are only used by a single service and never shared.</li> </ul>"},{"location":"concepts/caching/#caching-hierarchy","title":"Caching Hierarchy","text":""},{"location":"concepts/caching/#ownership-structure","title":"Ownership Structure","text":"<p>AIMTemplateCache may be owned by an <code>AIMServiceTemplate</code>, by an <code>AIMService</code>, or by nothing (unowned). <code>AIMArtifact</code> are owned by the template cache only in Dedicated mode; in Shared mode they have no owner.</p> <pre><code>Who owns AIMTemplateCache (one of):\n  \u2022 AIMServiceTemplate   (template-created, Shared)\n  \u2022 AIMService           (service-created, Dedicated)\n  \u2022 (none)               (service-created with Shared)\n\nResource hierarchy:\n  AIMTemplateCache (Shared or Dedicated mode)\n      \u2514\u2500\u2500 AIMArtifact(s)  [created by template, owned by TemplateCache only if Dedicated]\n              \u2514\u2500\u2500 PVC(s) + Download Job(s) (owned by model cache)\n</code></pre>"},{"location":"concepts/caching/#creation-flow","title":"Creation Flow","text":"<p>An AIMTemplateCache is created by an AIMServiceTemplate (when the template has caching enabled and is ready), by an AIMService (when the service has caching enabled and no suitable cache exists), or manually. Ownership depends on the creator and mode: template-owned (template-created), service-owned (service-created with Dedicated), unowned (service-created with Shared), or no owner (manually created).</p> <p>For each needed model (matching <code>sourceURI</code> and storage class), the AIMTemplateCache uses an existing artifact when possible, otherwise creates one. A shared template cache reuses any matching shared artifact in the namespace; a dedicated template cache uses its own dedicated artifact. New artifacts are created shared or dedicated according to the template cache's mode. The AIMArtifact handles the download.</p>"},{"location":"concepts/caching/#cache-status-values","title":"Cache Status Values","text":"<p>AIMTemplateCache and AIMArtifact use the same status values. The template cache's status is typically derived from its artifacts.</p> Status Description <code>Pending</code> Created, waiting for processing <code>Progressing</code> Download or provisioning in progress <code>Ready</code> Ready and can be used <code>Degraded</code> Partially available or limited (e.g. some artifacts failed) <code>NotAvailable</code> Dependencies not available. AIMTemplateCache may report this when its template is not available (e.g. GPU not ready); AIMArtifact never sets this. <code>Failed</code> Creation failed (download error, storage issue, etc.) <p>A <code>Failed</code> <code>AIMArtifact</code> retries the download periodically, so its status may change over time.</p>"},{"location":"concepts/caching/#deletion-behavior","title":"Deletion Behavior","text":"<p>Deletion follows Kubernetes ownership: owned resources are garbage-collected when the owner is deleted. AIM finalizers additionally delete non-Ready caches so that Failed/Pending caches do not block recreation. Manually created AIMTemplateCaches and AIMArtifact (no owner) are never garbage-collected.</p>"},{"location":"concepts/caching/#when-aimservice-is-deleted","title":"When AIMService is deleted","text":"<ul> <li>Template caches owned by the service (Dedicated, service-created): Garbage-collected with the service.</li> <li>Service finalizer: Deletes any template caches created by this service (by label) that are not Ready, so stuck Pending/Progressing/Failed caches do not block a future service from creating a new cache.</li> <li>Template caches not owned by the service (template-owned or unowned Shared): Unchanged; they persist and can be reused by other services.</li> </ul>"},{"location":"concepts/caching/#when-aimservicetemplate-is-deleted","title":"When AIMServiceTemplate is deleted","text":"<ul> <li>Template caches owned by the template: When a template creates a cache, the cache is automatically deleted when the template is deleted via Kubernetes garbage collection. Template-created caches use Shared mode by default, so the cached artifacts themselves persist even after the cache is removed.</li> </ul>"},{"location":"concepts/caching/#when-aimtemplatecache-is-deleted","title":"When AIMTemplateCache is deleted","text":"<ul> <li>Template cache finalizer: Ensure that artifacts created by this template cache (by label) that are not Ready are deleted. Ready model caches are left in place so they can be reused by other template caches.</li> <li>The template cache is then removed.</li> </ul> <p>If a service with caching enabled was using this template cache, a new template cache will be created automatically, provided the template itself is still healthy and ready.</p>"},{"location":"concepts/caching/#when-aimartifact-is-deleted","title":"When AIMArtifact is deleted","text":"<ul> <li>The PVC and any download Job owned by the artifact is marked for garbage-collection.</li> <li>Any AIMService pod still using that cache keeps the PVC mounted until the pod is gone.</li> </ul>"},{"location":"concepts/caching/#cache-reuse","title":"Cache Reuse","text":"<p>Shared artifacts are deduplicated per namespace: if two shared template caches request the same source (e.g. same <code>sourceURI</code> and storage class), the download runs once and both use the same artifact and PVC. Dedicated template caches only reuse artifacts they already own, so they do not share artifacts across caches.</p>"},{"location":"concepts/caching/#automatic-reuse","title":"Automatic Reuse","text":"<p>Services automatically detect and use existing caches:</p> <ol> <li>Service resolves its template</li> <li>Controller looks for <code>AIMTemplateCache</code> matching the template. If <code>AIMTemplateCache</code> isn't available, the service waits until it is.</li> <li>PVCs from the AIMArtifacts linked in the AIMTemplateCache are mounted into the InferenceService.</li> <li>No re-download is needed</li> </ol>"},{"location":"concepts/caching/#cross-service-sharing","title":"Cross-Service Sharing","text":"<p>Multiple services can share the same cached models:</p> <ul> <li>Services using the same template reference the same <code>AIMTemplateCache</code></li> <li>artifacts are identified by <code>sourceURI</code>, enabling reuse across templates</li> </ul>"},{"location":"concepts/caching/#manual-cache-management","title":"Manual Cache Management","text":"<ul> <li>To manually make sure a model is available create an AIMArtifact for that model.</li> <li>To make sure all models that belong to a AIMServiceTemplate or AIMClusterServiceTemplate is available, create an AIMTemplateCache with correctly set templateName in the namespace.</li> <li>Cleanup: <code>Ready</code> AIMArtifacts that have no owner (Shared, or manually created) are not garbage-collected; delete them manually if you want to free space. Artifacts owned by a template cache (Dedicated) are removed when that template cache is deleted.</li> </ul>"},{"location":"concepts/caching/#aimservice-with-cache-enabled","title":"AIMService with cache enabled","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\n  labels:\n    project: conversational-ai\nspec:\n  model:\n    ref: qwen-qwen3-32b\n  caching:\n    mode: Shared   # default; use Dedicated for service-owned caches\n</code></pre>"},{"location":"concepts/caching/#aimtemplatecache-to-prepopulate-the-namespace-with-caches-for-a-aimservicetemplate","title":"AIMTemplateCache to prepopulate the namespace with caches for a AIMServiceTemplate","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMTemplateCache\nmetadata:\n  name: template-cache\nspec:\n  templateName: name-of-service-template\n</code></pre>"},{"location":"concepts/caching/#aimartifact-that-uses-the-kserve-downloader-with-xet-disabled","title":"AIMArtifact that uses the kserve downloader with XET disabled","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMArtifact\nmetadata:\n  name: kserve-smollm2-135mx\nspec:\n  modelDownloadImage: kserve/storage-initializer:v0.16.0\n  env:\n    - name: HF_HUB_DISABLE_XET\n      value: \"1\"\n  sourceUri: hf://HuggingFaceTB/SmolLM2-135Mx\n  size: 500M\n  storageClassName: rwx-nfs\n</code></pre>"},{"location":"concepts/caching/#download-protocol-strategy","title":"Download Protocol Strategy","text":"<p>AIMArtifact downloads from HuggingFace support multiple download protocols. The operator automatically tries protocols in a configurable sequence, falling back to the next protocol if the current one fails. The main reason for this approach is that some models require XET for parts of the download, while XET seems to have a hard time handling network instability in certain environments. A mixed protocol approach where different protocols are tried in sequence is default to alliviate this, but the default behavior can be changed by setting the AIM_DOWNLOADER_PROTOCOL in the default AIMClusterRuntimeConfig.</p>"},{"location":"concepts/caching/#supported-protocols","title":"Supported Protocols","text":"Protocol Description <code>XET</code> HuggingFace's content-addressable chunk-based protocol. Default in <code>huggingface_hub</code> &gt;= 0.32. Efficient for large files with deduplication. <code>HF_TRANSFER</code> Rust-based parallel HTTP downloader (deprecated by HuggingFace in favor of XET). <code>HTTP</code> Standard HTTP range-request downloads. Most compatible, no extra dependencies."},{"location":"concepts/caching/#configuration","title":"Configuration","text":"<p>The download strategy is controlled by the <code>AIM_DOWNLOADER_PROTOCOL</code> environment variable, which specifies a comma-separated sequence of protocols to try in order.</p> <p>Default: <code>XET,HF_TRANSFER</code></p> <p>This can be overridden at three levels (highest precedence first):</p> <ol> <li>Per-artifact via <code>AIMArtifact.spec.env</code></li> <li>Per-namespace via <code>AIMRuntimeConfig.spec.env</code></li> <li>Cluster-wide via <code>AIMClusterRuntimeConfig.spec.env</code></li> </ol>"},{"location":"concepts/caching/#example-override-per-artifact","title":"Example: Override per artifact","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMArtifact\nmetadata:\n  name: my-model\nspec:\n  sourceUri: hf://Qwen/Qwen3-32B\n  env:\n    - name: AIM_DOWNLOADER_PROTOCOL\n      value: \"HTTP\"\n</code></pre>"},{"location":"concepts/caching/#example-cluster-wide-default","title":"Example: Cluster-wide default","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  env:\n    - name: AIM_DOWNLOADER_PROTOCOL\n      value: \"XET,XET,HTTP\"\n</code></pre>"},{"location":"concepts/caching/#observing-download-status","title":"Observing Download Status","text":"<p>During downloads, the artifact's <code>status.download</code> field is updated by the downloader pod with protocol attempt metadata:</p> <pre><code>status:\n  download:\n    protocol: HTTP          # Currently active protocol\n    attempt: 2              # Current attempt number (1-based)\n    totalAttempts: 3        # Total attempts in the sequence\n    protocolSequence: \"XET,XET,HTTP\"\n    message: Complete       # Human-readable status\n</code></pre> <p>View these fields with:</p> <pre><code>kubectl get aimart -o wide          # Protocol and Attempt columns (priority=1)\nkubectl get aimart my-model -o yaml # Full status.download details\n</code></pre>"},{"location":"concepts/caching/#how-protocol-switching-works","title":"How Protocol Switching Works","text":"<ol> <li>The downloader iterates through the protocol sequence left to right</li> <li>For each protocol, the appropriate HuggingFace environment variables are set (<code>HF_HUB_DISABLE_XET</code>, <code>HF_HUB_ENABLE_HF_TRANSFER</code>)</li> <li>If a protocol fails, any <code>.incomplete</code> files are cleaned before switching to the next protocol</li> <li>Already-completed files are skipped regardless of protocol (metadata-based)</li> <li>If all protocols are exhausted, the Job fails and Kubernetes retries via <code>backoffLimit</code></li> </ol>"},{"location":"concepts/caching/#related-documentation","title":"Related Documentation","text":"<ul> <li>Templates - Understanding ServiceTemplates and discovery</li> <li>Services - Deploying services with caching</li> <li>Runtime Configuration - Cluster-wide and namespace-scoped configuration</li> </ul>"},{"location":"concepts/model-sources/","title":"Model Sources","text":"<p>AIMClusterModelSource automatically discovers and syncs AI model images from container registries, creating AIMClusterModel resources for matched images.</p>"},{"location":"concepts/model-sources/#overview","title":"Overview","text":"<p>Model sources eliminate the need to manually create model resources for every image version. They continuously sync with container registries, automatically creating models when new images are published.</p> <p>Key features:</p> <ul> <li>Automatic discovery: Continuously monitors registries for images matching your filters</li> <li>Flexible filtering: Use wildcards, version constraints, and exclusions</li> <li>Multi-registry support: Works with Docker Hub, GitHub Container Registry (ghcr.io), and more</li> <li>Periodic sync: Configurable sync intervals to keep models up to date</li> <li>Private registries: Supports authentication via imagePullSecrets</li> </ul>"},{"location":"concepts/model-sources/#basic-example","title":"Basic Example","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: amd-models\nspec:\n  filters:\n    - image: amdenterpriseai/aim-*\n  syncInterval: 1h\n</code></pre> <p>This source discovers all images matching <code>amdenterpriseai/aim-*</code> from Docker Hub and creates an AIMClusterModel for each.</p>"},{"location":"concepts/model-sources/#configuration","title":"Configuration","text":""},{"location":"concepts/model-sources/#registry","title":"Registry","text":"<p>The <code>registry</code> field specifies which container registry to query. Defaults to <code>docker.io</code> if not specified.</p> <pre><code>spec:\n  registry: ghcr.io  # or docker.io, gcr.io, etc.\n</code></pre>"},{"location":"concepts/model-sources/#filters","title":"Filters","text":"<p>Filters define which images to discover. Each filter specifies a pattern with optional version constraints and exclusions. Multiple filters are combined with OR logic.</p>"},{"location":"concepts/model-sources/#repository-patterns","title":"Repository Patterns","text":"<p>Match repositories using wildcards:</p> <pre><code>spec:\n  filters:\n    - image: amdenterpriseai/aim-*\n</code></pre>"},{"location":"concepts/model-sources/#repository-with-specific-tag","title":"Repository with Specific Tag","text":"<p>Match a specific tag:</p> <pre><code>spec:\n  filters:\n    - image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre>"},{"location":"concepts/model-sources/#full-uri","title":"Full URI","text":"<p>Override the registry for specific filters:</p> <pre><code>spec:\n  registry: docker.io\n  filters:\n    - image: docker.io/amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre>"},{"location":"concepts/model-sources/#full-uri-with-wildcard","title":"Full URI with Wildcard","text":"<p>Override registry and use wildcards:</p> <pre><code>spec:\n  registry: ghcr.io\n  filters:\n    - image: amdenterpriseai/aim-*\n</code></pre>"},{"location":"concepts/model-sources/#version-constraints","title":"Version Constraints","text":"<p>Use semantic version constraints to filter tags. Supports both global and per-filter version constraints.</p>"},{"location":"concepts/model-sources/#global-version-constraints","title":"Global Version Constraints","text":"<p>Apply to all filters:</p> <pre><code>spec:\n  registry: ghcr.io\n  filters:\n    - image: amdenterpriseai/aim-qwen-*\n    - image: amdenterpriseai/aim-deepseek-*\n  versions:\n    - \"&gt;=0.8.0\"\n    - \"&lt;1.0.0\"\n</code></pre>"},{"location":"concepts/model-sources/#per-filter-version-constraints","title":"Per-Filter Version Constraints","text":"<p>Override global constraints for specific filters:</p> <pre><code>spec:\n  registry: ghcr.io\n  versions:\n    - \"&gt;=0.8.0\"  # global default\n  filters:\n    - image: amdenterpriseai/aim-qwen-*\n      versions:\n        - \"&gt;=0.8.5\"  # overrides global for this filter\n    - image: amdenterpriseai/aim-deepseek-*\n      # uses global constraint\n</code></pre>"},{"location":"concepts/model-sources/#version-syntax","title":"Version Syntax","text":"<p>Constraints use standard semver syntax:</p> <ul> <li><code>&gt;=1.0.0</code> - Version 1.0.0 or higher</li> <li><code>&lt;2.0.0</code> - Below version 2.0.0</li> <li><code>~1.2.0</code> - Patch updates only (1.2.x)</li> <li><code>^1.0.0</code> - Minor updates allowed (1.x.x)</li> </ul> <p>Prerelease versions (e.g., <code>0.8.1-rc1</code>) are supported:</p> <pre><code>versions:\n  - \"&gt;=0.8.1-rc1\"  # includes prereleases\n</code></pre> <p>Non-semver tags (e.g., <code>latest</code>, <code>dev</code>) are silently skipped when version constraints are specified.</p>"},{"location":"concepts/model-sources/#exclusions","title":"Exclusions","text":"<p>Exclude specific repositories from matching:</p> <pre><code>spec:\n  filters:\n    - image: amdenterpriseai/aim-*\n      exclude:\n        - amdenterpriseai/aim-base\n        - amdenterpriseai/aim-experimental\n</code></pre> <p>Exclusions match repository names exactly (not including the registry).</p>"},{"location":"concepts/model-sources/#sync-interval","title":"Sync Interval","text":"<p>Control how often the source syncs with the registry:</p> <pre><code>spec:\n  syncInterval: 30m  # supports: 15m, 1h, 2h30m, etc.\n</code></pre> <p>Default is <code>1h</code>. Minimum recommended interval is <code>15m</code> to avoid rate limiting.</p>"},{"location":"concepts/model-sources/#private-registries","title":"Private Registries","text":"<p>Authenticate to private registries using imagePullSecrets:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: ghcr-secret\n  namespace: aim-system  # operator namespace\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_CONFIG\n---\napiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: private-models\nspec:\n  registry: ghcr.io\n  imagePullSecrets:\n    - name: ghcr-secret\n  filters:\n    - image: myorg/private-model-*\n</code></pre> <p>Secrets must exist in the operator namespace (typically <code>aim-system</code>).</p>"},{"location":"concepts/model-sources/#github-container-registry-ghcr-authentication","title":"GitHub Container Registry (GHCR) Authentication","text":"<p>For GitHub Container Registry, use a GitHub Personal Access Token (PAT) with the minimal required scope:</p> <p>Required Scope: - <code>read:packages</code> - Read access to container packages</p> <p>Recommended: Use Fine-Grained Personal Access Tokens</p> <ol> <li>Create a fine-grained PAT at: https://github.com/settings/tokens</li> <li>Set repository access or organization permissions</li> <li>Grant only <code>read:packages</code> permission</li> <li>Set expiration date</li> <li>Create the secret:</li> </ol> <pre><code>kubectl create secret docker-registry ghcr-secret \\\n  --docker-server=ghcr.io \\\n  --docker-username=YOUR_GITHUB_USERNAME \\\n  --docker-password=YOUR_GITHUB_PAT \\\n  --namespace=aim-system\n</code></pre> <p>Security Best Practices: - Use fine-grained PATs instead of classic PATs when possible - Grant minimal permissions (<code>read:packages</code> only) - Set expiration dates on tokens - Rotate tokens regularly - Use separate tokens for different environments (dev/staging/prod) - Enable encryption at rest for Kubernetes Secrets in production - Limit Secret access via RBAC to only the operator namespace</p> <p>Token Scopes to Avoid: - \u274c <code>repo</code> - Grants read/write access to repositories (too broad) - \u274c <code>write:packages</code> - Write access not needed for discovery - \u274c <code>admin:org</code> - Organization admin access (unnecessary) - \u274c <code>delete:packages</code> - Delete permission (unnecessary risk)</p>"},{"location":"concepts/model-sources/#max-models-limit","title":"Max Models Limit","text":"<p>Control the maximum number of models created to prevent runaway resource creation:</p> <pre><code>spec:\n  maxModels: 100  # CRD default: 100, range: 1-10000\n  filters:\n    - image: org/very-broad-pattern-*\n</code></pre> <p>When using the Helm chart's optional <code>clusterModelSource</code>, the chart default is <code>maxModels: 500</code> unless overridden.</p> <p>When the limit is reached:</p> <ul> <li>No new models are created, even if more matching images exist</li> <li>Existing models are never deleted</li> <li>Status shows <code>modelsLimitReached: true</code></li> <li><code>availableModels</code> shows total images found vs <code>discoveredModels</code> created</li> </ul> <p>Use Cases:</p> <ul> <li>Prevent accidental model explosion from overly broad filters</li> <li>Enforce resource quotas in multi-tenant environments</li> <li>Limit cluster resource consumption during initial sync</li> </ul> <p>Example Status:</p> <pre><code>status:\n  status: Ready\n  discoveredModels: 100\n  availableModels: 250\n  modelsLimitReached: true\n  conditions:\n    - type: MaxModelsLimitReached\n      status: \"True\"\n      message: \"Model creation limit reached (100 models created). 150 available images not created as models.\"\n</code></pre>"},{"location":"concepts/model-sources/#status","title":"Status","text":"<p>The status field tracks sync progress and discovered models:</p> <pre><code>kubectl get aimclustermodelsource\n</code></pre> <pre><code>NAME             STATUS   MODELS   LASTSYNC             AGE\namd-models   Ready    12       2025-01-15T10:30:00  2d\n</code></pre>"},{"location":"concepts/model-sources/#status-values","title":"Status Values","text":"<ul> <li>Pending: Waiting for initial sync</li> <li>Progressing: Sync in progress</li> <li>Ready: All filters succeeded</li> <li>Degraded: Some filters failed, but others succeeded</li> <li>Failed: All filters failed</li> </ul>"},{"location":"concepts/model-sources/#detailed-status","title":"Detailed Status","text":"<pre><code>kubectl get aimclustermodelsource amd-models -o yaml\n</code></pre> <p>Key status fields:</p> <ul> <li><code>status</code>: Overall state (Ready, Degraded, Failed, etc.)</li> <li><code>discoveredModels</code>: Count of AIMClusterModel resources created</li> <li><code>availableModels</code>: Total count of images matching filters in registry</li> <li><code>modelsLimitReached</code>: Boolean indicating if maxModels limit was reached</li> <li><code>lastSyncTime</code>: Timestamp of last successful sync</li> <li><code>conditions</code>: Detailed conditions including Ready, Degraded, and MaxModelsLimitReached</li> </ul>"},{"location":"concepts/model-sources/#examples","title":"Examples","text":""},{"location":"concepts/model-sources/#docker-hub-with-wildcards","title":"Docker Hub with Wildcards","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: dockerhub-models\nspec:\n  registry: docker.io\n  filters:\n    - image: amdenterpriseai/aim-*\n      exclude:\n        - amdenterpriseai/aim-base\n  syncInterval: 2h\n</code></pre>"},{"location":"concepts/model-sources/#github-container-registry-with-version-constraints","title":"GitHub Container Registry with Version Constraints","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: ghcr-stable-models\nspec:\n  registry: ghcr.io\n  filters:\n    - image: amdenterpriseai/aim-qwen-*\n    - image: amdenterpriseai/aim-deepseek-*\n  versions:\n    - \"&gt;=0.8.0\"\n    - \"&lt;1.0.0\"\n  syncInterval: 1h\n</code></pre>"},{"location":"concepts/model-sources/#multiple-registries","title":"Multiple Registries","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: multi-registry-models\nspec:\n  registry: docker.io  # default\n  filters:\n    - image: amdenterpriseai/aim-*  # uses docker.io\n    - image: ghcr.io/amdenterpriseai/aim-*  # overrides to ghcr.io\n  syncInterval: 1h\n</code></pre>"},{"location":"concepts/model-sources/#private-registry-with-authentication","title":"Private Registry with Authentication","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: private-registry-creds\n  namespace: aim-system\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_ENCODED_CONFIG\n---\napiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: private-models\nspec:\n  registry: private.registry.io\n  imagePullSecrets:\n    - name: private-registry-creds\n  filters:\n    - image: myorg/model-*\n      versions:\n        - \"&gt;=1.0.0\"\n  syncInterval: 1h\n</code></pre>"},{"location":"concepts/model-sources/#specific-versions-only","title":"Specific Versions Only","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: specific-versions\nspec:\n  registry: ghcr.io\n  filters:\n    - image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n    - image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.4\n    - image: amdenterpriseai/aim-deepseek-deepseek-r1:0.8.5\n  syncInterval: 6h\n</code></pre>"},{"location":"concepts/model-sources/#lifecycle","title":"Lifecycle","text":""},{"location":"concepts/model-sources/#created-models","title":"Created Models","text":"<p>Model sources create AIMClusterModel resources with auto-generated names based on the image URI. These models are owned by the source via an owner reference.</p> <p>Created models have discovery enabled by default and will automatically create service templates if the image includes recommended deployment metadata.</p>"},{"location":"concepts/model-sources/#append-only","title":"Append-Only","text":"<p>Model sources follow an append-only lifecycle during normal operation. Once created, models are never deleted by the source, even if:</p> <ul> <li>The image is removed from the registry</li> <li>The filter is changed or removed</li> </ul> <p>This ensures running services aren't disrupted when registry contents change.</p>"},{"location":"concepts/model-sources/#ownership-and-deletion","title":"Ownership and Deletion","text":"<p>Created models have an owner reference to the source. When you delete the source, Kubernetes will automatically delete all models that were created by it.</p> <p>This cascading deletion happens via Kubernetes garbage collection. To prevent accidentally disrupting running services, consider the impact before deleting a model source.</p> <p>If you need to stop tracking specific models:</p> <ol> <li>Update the source filters to exclude those models</li> <li>Delete the unwanted models manually:</li> </ol> <pre><code>kubectl delete aimclustermodel &lt;model-name&gt;\n</code></pre> <p>Note: You cannot selectively clean up models while keeping the source unchanged - any models matching the active filters will be recreated on the next sync.</p>"},{"location":"concepts/model-sources/#troubleshooting","title":"Troubleshooting","text":""},{"location":"concepts/model-sources/#no-models-discovered","title":"No Models Discovered","text":"<p>Check the source status:</p> <pre><code>kubectl get aimclustermodelsource &lt;name&gt; -o yaml\n</code></pre> <p>Common causes:</p> <ul> <li>No images match the filters</li> <li>Registry is unreachable</li> <li>Authentication failed (check imagePullSecrets)</li> <li>Version constraints too restrictive</li> </ul>"},{"location":"concepts/model-sources/#degraded-status","title":"Degraded Status","text":"<p>Some filters failed while others succeeded. Check conditions:</p> <pre><code>kubectl get aimclustermodelsource &lt;name&gt; -o jsonpath='{.status.conditions}'\n</code></pre> <p>Look for error messages indicating which filters failed and why.</p>"},{"location":"concepts/model-sources/#failed-status","title":"Failed Status","text":"<p>All filters failed. Common causes:</p> <ul> <li>Invalid registry hostname</li> <li>Missing or invalid imagePullSecrets</li> <li>Network connectivity issues</li> <li>Registry catalog API not supported (for wildcard filters)</li> </ul>"},{"location":"concepts/model-sources/#wildcard-filters-not-working","title":"Wildcard Filters Not Working","text":"<p>Wildcard filters require registry catalog API support. GitHub Container Registry (<code>ghcr.io</code>) wildcard discovery is supported via GHCR's REST API.</p>"},{"location":"concepts/model-sources/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - Understanding AIMClusterModel and AIMModel resources</li> <li>Templates - Auto-generated service templates</li> <li>Runtime Config - Authentication and discovery configuration</li> </ul>"},{"location":"concepts/models/","title":"AIM Models","text":"<p>AIM Model resources form a catalog that maps model identifiers to specific container images. This document explains the model resource types, discovery mechanism, and lifecycle.</p>"},{"location":"concepts/models/#overview","title":"Overview","text":"<p>Model resources serve two purposes:</p> <ol> <li>Registry: Translate abstract model references into concrete container images</li> <li>Version control: Update which container serves a model without changing service configurations</li> </ol>"},{"location":"concepts/models/#cluster-vs-namespace-scope","title":"Cluster vs Namespace Scope","text":""},{"location":"concepts/models/#aimclustermodel","title":"AIMClusterModel","text":"<p>Cluster-scoped models are typically installed by administrators through GitOps workflows or Helm charts. They represent curated model catalogs maintained by platform teams or model publishers.</p> <p>Cluster models provide a consistent baseline across all namespaces. Any namespace can reference a cluster model unless it defines a namespace-scoped model with the same name, which takes precedence.</p> <p>Discovery for cluster models runs in the operator namespace (default: <code>aim-system</code>). Auto-generated templates are created as cluster-scoped resources.</p>"},{"location":"concepts/models/#aimmodel","title":"AIMModel","text":"<p>Namespace-scoped models allow teams to:</p> <ul> <li>Define team-specific model variants</li> <li>Override cluster-level definitions for testing</li> <li>Control model access at the namespace level</li> </ul> <p>When both cluster and namespace models exist with the same <code>metadata.name</code>, the namespace resource takes precedence within that namespace.</p> <p>Discovery for namespace models runs in the model's namespace. Auto-generated templates are created as namespace-scoped resources.</p>"},{"location":"concepts/models/#model-specification","title":"Model Specification","text":"<p>An AIM Model uses <code>metadata.name</code> as the canonical model identifier:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: qwen-qwen3-32b\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  discovery:\n    extractMetadata: true\n    createServiceTemplates: true\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n</code></pre>"},{"location":"concepts/models/#fields","title":"Fields","text":"Field Purpose <code>image</code> Container image URI implementing this model. The operator inspects this image during discovery. <code>discovery</code> Controls metadata extraction and automatic template generation. Discovery is attempted automatically. <code>discovery.createServiceTemplates</code> When true (default), creates ServiceTemplates from recommended deployments published by the image. <code>defaultServiceTemplate</code> Default template name to use when services reference this model without specifying a template. Optional. <code>imagePullSecrets</code> Secrets for pulling the container image during discovery and inference. Must exist in the same namespace as the model (or operator namespace for cluster models). <code>serviceAccountName</code> Service account to use for discovery jobs and metadata extraction. If empty, uses the default service account. <code>resources</code> Default resource requirements. These serve as baseline values that templates and services can override."},{"location":"concepts/models/#discovery-mechanism","title":"Discovery Mechanism","text":"<p>Discovery is an automatic process that extracts metadata from container images and creates templates.</p>"},{"location":"concepts/models/#discovery-process","title":"Discovery Process","text":"<p>When discovery is enabled:</p> <ol> <li> <p>Registry Inspection: The controller directly queries the container registry    using the operator's network context and any configured imagePullSecrets</p> </li> <li> <p>Image Metadata Fetch: Using go-containerregistry, the controller pulls    image metadata (labels) without downloading the full image</p> </li> <li> <p>Metadata Storage: Extracted metadata is written to <code>status.imageMetadata</code></p> </li> <li> <p>Template Generation: If <code>createServiceTemplates: true</code>, the controller examines the image's recommended deployments and creates corresponding ServiceTemplate resources</p> </li> </ol>"},{"location":"concepts/models/#expected-labels","title":"Expected Labels","text":"<p>AIM discovery looks for container image labels with the following prefix: - <code>com.amd.aim.model.canonicalName</code> - <code>com.amd.aim.model.deployments</code> Images without these labels will have minimal metadata. If <code>createServiceTemplates: true</code> but no <code>recommendedDeployments</code> are found, no templates are created.</p>"},{"location":"concepts/models/#lifecycle-and-status","title":"Lifecycle and Status","text":""},{"location":"concepts/models/#status-field","title":"Status Field","text":"<p>The <code>status</code> field tracks discovery progress:</p> Field Description <code>status</code> Enum: <code>Pending</code>, <code>Progressing</code>, <code>Ready</code>, <code>Degraded</code>, <code>Failed</code> <code>conditions</code> Detailed conditions including <code>RuntimeConfigReady</code>, <code>ImageMetadataReady</code>, and <code>ServiceTemplatesReady</code> <code>resolvedRuntimeConfig</code> Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>imageMetadata</code> Extracted metadata from the container image including model and OCI metadata"},{"location":"concepts/models/#status-values","title":"Status Values","text":"<ul> <li>Pending: Initial state, waiting for reconciliation</li> <li>Progressing: Discovery job running or templates being created</li> <li>Ready: Discovery succeeded and all auto-generated templates are healthy</li> <li>Degraded: Discovery succeeded but some templates have issues</li> <li>Failed: Discovery failed or required labels missing</li> </ul>"},{"location":"concepts/models/#conditions","title":"Conditions","text":"<p>RuntimeConfigReady: Reports runtime config resolution status. Common reasons:</p> <ul> <li><code>ConfigFound</code>: Runtime configuration was successfully resolved</li> <li><code>DefaultConfigNotFound</code>: No default runtime config found (non-fatal)</li> <li><code>ConfigNotFound</code>: Explicitly referenced runtime config not found</li> </ul> <p>ImageMetadataReady: Reports image inspection status. Common reasons:</p> <ul> <li><code>ImageMetadataFound</code>: Metadata extraction succeeded</li> <li><code>ImageFound</code>: Image is reachable, but metadata labels are missing</li> <li><code>MetadataExtractionFailed</code>: Failed to extract metadata from the image</li> </ul>"},{"location":"concepts/models/#toggling-discovery","title":"Toggling Discovery","text":"<p>You can enable discovery after image creation:</p> <pre><code>kubectl edit aimclustermodel qwen-qwen3-32b\n# Set spec.discovery.extractMetadata: true\n</code></pre> <p>The controller runs extraction on the next reconciliation and updates status accordingly.</p> <p>Disabling discovery after templates exist leaves templates in place. Existing templates are not deleted automatically.</p>"},{"location":"concepts/models/#resource-resolution","title":"Resource Resolution","text":"<p>When services reference a model, the controller merges resources from multiple sources:</p> <ol> <li>Service-level: <code>AIMService.spec.resources</code> (highest precedence)</li> <li>Template-level: <code>AIMServiceTemplate.spec.resources</code></li> <li>Model-level: <code>AIMModel.spec.resources</code> (baseline)</li> </ol> <p>If GPU quantities remain unset after merging, the controller copies them from discovery metadata recorded on the template (<code>status.profile.metadata.gpu_count</code>).</p>"},{"location":"concepts/models/#model-lookup","title":"Model Lookup","text":"<p>For namespace-scoped lookups (from templates or services in a namespace):</p> <ol> <li>Check for <code>AIMModel</code> in the same namespace</li> <li>Fall back to <code>AIMClusterModel</code> with the same name</li> </ol> <p>This allows namespace models to override cluster baselines.</p>"},{"location":"concepts/models/#examples","title":"Examples","text":""},{"location":"concepts/models/#cluster-model-with-discovery","title":"Cluster Model with Discovery","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: qwen-qwen3-32b\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  runtimeConfigName: platform-default\n  discovery:\n    extractMetadata: true\n    createServiceTemplates: true\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n</code></pre>"},{"location":"concepts/models/#namespace-model-without-discovery","title":"Namespace Model Without Discovery","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMModel\nmetadata:\n  name: qwen-qwen3-32b-dev\n  namespace: ml-team\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  runtimeConfigName: ml-team\n  defaultServiceTemplate: custom-template-name\n  discovery:\n    extractMetadata: false  # skip image metadata extraction\n    createServiceTemplates: false\n  resources:\n    limits:\n      cpu: \"6\"\n      memory: 48Gi\n</code></pre>"},{"location":"concepts/models/#enabling-discovery-for-private-container-images","title":"Enabling Discovery for Private Container Images","text":"<pre><code># Secret in namespace\napiVersion: v1\nkind: Secret\nmetadata:\n  name: private-registry\n  namespace: ml-team\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_CONFIG\n---\n# Runtime config in namespace\napiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  serviceAccountName: aim-runtime\n  imagePullSecrets:\n    - name: private-registry\n---\n# Model with discovery\napiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMModel\nmetadata:\n  name: proprietary-model\n  namespace: ml-team\nspec:\n  image: private.registry/models/proprietary:v1\n  runtimeConfigName: default  # uses config above\n  discovery:\n    extractMetadata: true\n    createServiceTemplates: true\n</code></pre>"},{"location":"concepts/models/#troubleshooting","title":"Troubleshooting","text":""},{"location":"concepts/models/#discovery-fails","title":"Discovery Fails","text":"<p>Check the operator logs for registry access errors:</p> <pre><code>kubectl -n aim-system logs -l app.kubernetes.io/name=aim-engine --tail=100 | grep -i \"&lt;model-name&gt;\"\n</code></pre> <p>Common causes: - Missing or invalid imagePullSecrets (secrets must exist in operator namespace for cluster models) - Image doesn't exist or tag is invalid - Network connectivity issues to the registry</p>"},{"location":"concepts/models/#templates-not-auto-created","title":"Templates Not Auto-Created","text":"<p>Check the model status:</p> <pre><code>kubectl get aimclustermodel &lt;name&gt; -o yaml\n# or\nkubectl -n &lt;namespace&gt; get aimmodel &lt;name&gt; -o yaml\n</code></pre> <p>Look for:</p> <ul> <li><code>discovery.extractMetadata: false</code> - metadata extraction is disabled</li> <li><code>discovery.createServiceTemplates: false</code> - auto-template creation is disabled</li> <li>Model condition reasons such as <code>NoTemplatesExpected</code> or <code>CreatingTemplates</code></li> </ul>"},{"location":"concepts/models/#imagemetadataready-condition-false","title":"ImageMetadataReady Condition False","text":"<p>The container image is missing required labels or the discovery job failed. Check:</p> <pre><code>kubectl get aimclustermodel &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"ImageMetadataReady\")]}'\n</code></pre> <p>Inspect the container image labels:</p> <pre><code>docker pull &lt;image&gt;\ndocker inspect &lt;image&gt; --format='{{json .Config.Labels}}'\n</code></pre>"},{"location":"concepts/models/#auto-creation-from-services","title":"Auto-Creation from Services","text":"<p>When a service uses <code>spec.model.image</code> directly (instead of <code>spec.model.name</code>), AIM automatically creates a model resource if one doesn't already exist with that image URI. Auto-created models are namespace-scoped.</p>"},{"location":"concepts/models/#discovery-for-auto-created-models","title":"Discovery for Auto-Created Models","text":"<p>The runtime config's <code>spec.model.autoDiscovery</code> field controls whether auto-created models run discovery:</p> <pre><code>spec:\n  model:\n    autoDiscovery: true  # auto-created models run discovery and create templates\n</code></pre>"},{"location":"concepts/models/#example","title":"Example","text":"<p>Service using direct image reference:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: my-service\n  namespace: ml-team\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  runtimeConfigName: default\n</code></pre> <p>If the runtime config has <code>autoDiscovery: true</code>, AIM creates a namespace-scoped model and discovery runs automatically:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMModel\nmetadata:\n  name: auto-&lt;hash-of-image&gt;\n  namespace: ml-team\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  discovery:\n    extractMetadata: true\n    createServiceTemplates: true\n</code></pre>"},{"location":"concepts/models/#custom-models","title":"Custom Models","text":"<p>Custom models allow you to deploy models from external sources (S3, HuggingFace) without requiring a pre-built AIM container image. The AIM operator uses a generic base container that downloads model weights at runtime.</p>"},{"location":"concepts/models/#overview_1","title":"Overview","text":"<p>Unlike image-based models where model weights are embedded in the container image, custom models:</p> <ul> <li>Download weights from external sources (S3 or HuggingFace)</li> <li>Use the <code>amdenterpriseai/aim-base</code> container for inference</li> <li>Skip discovery (no image metadata extraction needed)</li> <li>Require explicit hardware specifications</li> </ul>"},{"location":"concepts/models/#creating-custom-models","title":"Creating Custom Models","text":"<p>There are two ways to create custom models:</p>"},{"location":"concepts/models/#1-direct-aimmodel-with-modelsources","title":"1. Direct AIMModel with modelSources","text":"<p>Create an AIMModel or AIMClusterModel with <code>modelSources</code> instead of relying on image discovery:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMModel\nmetadata:\n  name: my-custom-qwen\n  namespace: ml-team\nspec:\n  image: amdenterpriseai/aim-base:latest\n  modelSources:\n    - modelId: Qwen/Qwen3-32B\n      sourceUri: s3://my-bucket/models/qwen3-32b\n      # size: 16Gi  # Optional - auto-discovered by download job if omitted\n  custom:\n    hardware:\n      gpu:\n        requests: 1\n        models:\n          - MI300X\n</code></pre>"},{"location":"concepts/models/#2-inline-custom-model-in-aimservice","title":"2. Inline Custom Model in AIMService","text":"<p>Create an AIMService with <code>spec.model.custom</code> to auto-create a custom model:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: my-qwen-service\n  namespace: ml-team\nspec:\n  model:\n    custom:\n      baseImage: amdenterpriseai/aim-base:latest\n      modelSources:\n        - modelId: Qwen/Qwen3-32B\n          sourceUri: hf://Qwen/Qwen3-32B\n          # size is optional - auto-discovered by download job\n      hardware:\n        gpu:\n          requests: 1\n  template:\n    allowUnoptimized: true  # Required - custom models default to unoptimized\n</code></pre> <p>The service automatically creates a namespace-scoped AIMModel. Custom models are shared resources that persist independently of the service, allowing them to be reused by other services or manually managed.</p>"},{"location":"concepts/models/#model-sources","title":"Model Sources","text":"<p>Each model source specifies:</p> Field Required Description <code>modelId</code> Yes Canonical identifier in <code>{org}/{name}</code> format. Determines the cache mount path. <code>sourceUri</code> Yes Download location. Schemes: <code>hf://org/model</code> (HuggingFace) or <code>s3://bucket/key</code> (S3). For S3, use the bucket name directly without the service hostname (e.g., <code>s3://my-bucket/models/qwen3-32b</code>). <code>size</code> No Storage size for PVC provisioning. If omitted, the download job automatically discovers the size. Can be set explicitly to pre-allocate storage. <code>env</code> No Per-source credential overrides (e.g., <code>HF_TOKEN</code>, <code>AWS_ACCESS_KEY_ID</code>)"},{"location":"concepts/models/#hardware-requirements","title":"Hardware Requirements","text":"<p>Custom models require explicit hardware specifications since discovery doesn't run. These go under <code>spec.custom.hardware</code> for AIMModel, or <code>spec.model.custom.hardware</code> for inline AIMService:</p> <pre><code># For AIMModel:\nspec:\n  custom:\n    hardware:\n      gpu:\n        requests: 2          # Number of GPUs required\n        models:              # Optional: specific GPU models for node affinity\n          - MI300X\n          - MI250\n        minVram: 64Gi        # Optional: minimum VRAM per GPU for capacity planning\n      cpu:\n        requests: \"4\"        # Required if cpu field is specified: CPU requests\n        limits: \"8\"          # Optional: CPU limits\n</code></pre> <p>If no <code>models</code> are specified, the workload can run on any available GPU. The <code>minVram</code> field is used for capacity planning when the model size is known.</p>"},{"location":"concepts/models/#template-generation","title":"Template Generation","text":"<p>When <code>modelSources</code> is specified:</p> <ol> <li>Without custom.templates: A single template is auto-generated using <code>custom.hardware</code></li> <li>With custom.templates: Templates are created per entry, each inheriting from <code>custom.hardware</code> unless overridden</li> </ol> <p>Templates also inherit the <code>type</code> field from <code>spec.custom.type</code>, which defaults to <code>unoptimized</code>. This can be overridden per-template via <code>customTemplates[].type</code>.</p> <pre><code>spec:\n  modelSources:\n    - modelId: Qwen/Qwen3-32B\n      sourceUri: s3://bucket/model\n  custom:\n    type: unoptimized  # Default - can be omitted\n    hardware:\n      gpu:\n        requests: 1\n    templates:\n      - name: high-memory  # Generated as {modelName}-custom-[{name}][-{precision}][-{gpu}]-{hash}\n        hardware:\n          gpu:\n            requests: 2  # Override\n        env:\n          - name: VLLM_GPU_MEMORY_UTILIZATION\n            value: \"0.95\"\n      - name: standard\n        # Inherits hardware and type from custom.*\n</code></pre>"},{"location":"concepts/models/#unoptimized-templates-and-allowunoptimized","title":"Unoptimized Templates and allowUnoptimized","text":"<p>Custom models generate templates with <code>type: unoptimized</code> by default because no discovery job runs to validate performance characteristics. This has an important implication:</p> <p>Services will not auto-select unoptimized templates unless explicitly allowed.</p> <p>When creating an AIMService that uses a custom model, you must either:</p> <ol> <li>Set <code>allowUnoptimized: true</code> on the service's template selector:</li> </ol> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: my-service\nspec:\n  model:\n    name: my-custom-model\n  template:\n    allowUnoptimized: true  # Required for custom model templates\n</code></pre> <ol> <li>Explicitly specify the template name to bypass auto-selection:</li> </ol> <pre><code>spec:\n  template:\n    name: my-custom-model-custom-abc123  # Explicit template name\n</code></pre> <p>This safety mechanism prevents accidentally deploying unoptimized configurations in production. See Template Resolution for more details on how templates are selected and the role of optimization levels.</p>"},{"location":"concepts/models/#authentication","title":"Authentication","text":"<p>Configure credentials for private sources:</p>"},{"location":"concepts/models/#huggingface","title":"HuggingFace","text":"<pre><code>spec:\n  modelSources:\n    - modelId: Qwen/Qwen3-32B\n      sourceUri: hf://Qwen/Qwen3-32B\n      size: 16Gi\n      env:\n        - name: HF_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-credentials\n              key: token\n</code></pre>"},{"location":"concepts/models/#s3-compatible-storage","title":"S3-Compatible Storage","text":"<pre><code>spec:\n  modelSources:\n    - modelId: my-org/custom-model\n      sourceUri: s3://my-bucket/models/custom\n      size: 32Gi\n      env:\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: s3-credentials\n              key: access-key\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: s3-credentials\n              key: secret-key\n        - name: AWS_ENDPOINT_URL\n          value: \"https://s3.my-provider.com\"\n</code></pre>"},{"location":"concepts/models/#lifecycle-differences","title":"Lifecycle Differences","text":"Aspect Image-Based Models Custom Models Model weights source URI embedded in image source URI in spec Discovery Runs to extract metadata Skipped Hardware Optional (from discovery) Required Templates Auto-generated from image labels Auto-generated from spec Caching Uses shared template cache Uses dedicated template cache"},{"location":"concepts/models/#status","title":"Status","text":"<p>Custom models report <code>sourceType: Custom</code> in their status:</p> <pre><code>status:\n  status: Ready\n  sourceType: Custom\n  conditions:\n    - type: Ready\n      status: \"True\"\n</code></pre>"},{"location":"concepts/models/#example-full-custom-model-deployment","title":"Example: Full Custom Model Deployment","text":"<pre><code># Secret for HuggingFace access\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-token\n  namespace: ml-team\ntype: Opaque\nstringData:\n  token: hf_xxxxxxxxxxxxx\n---\n# Custom model service\napiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-custom\n  namespace: ml-team\nspec:\n  model:\n    custom:\n      modelSources:\n        - modelId: Qwen/Qwen3-32B\n          sourceUri: hf://Qwen/Qwen3-32B\n          # size is optional - auto-discovered by download job\n          env:\n            - name: HF_TOKEN\n              valueFrom:\n                secretKeyRef:\n                  name: hf-token\n                  key: token\n      hardware:\n        gpu:\n          requests: 1\n          models:\n            - MI300X\n  template:\n    allowUnoptimized: true  # Required - custom models default to unoptimized\n  replicas: 1\n</code></pre>"},{"location":"concepts/models/#related-documentation","title":"Related Documentation","text":"<ul> <li>Templates - Understanding ServiceTemplates and discovery</li> <li>Runtime Config Concepts - Resolution details including model creation</li> <li>Services Usage - Deploying services</li> <li>Caching - Model caching and download architecture</li> </ul>"},{"location":"concepts/models/#note-on-terminology","title":"Note on Terminology","text":"<p>AIM Model resources (<code>AIMModel</code> and <code>AIMClusterModel</code>) define the mapping between model identifiers and container images. While we sometimes refer to the \"model catalog\" conceptually, the Kubernetes resources are always <code>AIMModel</code> and <code>AIMClusterModel</code>.</p>"},{"location":"concepts/resource-lifecycle/","title":"Resource Lifecycle","text":"<p>This page describes how AIM Engine manages resource ownership, status transitions, and cleanup behavior.</p>"},{"location":"concepts/resource-lifecycle/#ownership-model","title":"Ownership Model","text":"<p>AIM Engine uses Kubernetes owner references to express resource relationships. When an owner is deleted, its owned resources are garbage collected automatically.</p> <pre><code>AIMServiceTemplate\n    \u2514\u2500\u2500 AIMTemplateCache (owned by template)\n            \u2514\u2500\u2500 AIMArtifact (owned by template cache)\n                    \u2514\u2500\u2500 PVC + Download Job (owned by artifact)\n\nAIMService\n    \u2514\u2500\u2500 InferenceService (owned by service)\n    \u2514\u2500\u2500 HTTPRoute (owned by service)\n</code></pre> <p>Key behaviors:</p> <ul> <li>Template caches are owned by templates, not services. This allows cache reuse across services.</li> <li>Auto-created models (via <code>model.image</code>) have no owner reference. They persist for reuse by other services.</li> </ul>"},{"location":"concepts/resource-lifecycle/#status-transitions","title":"Status Transitions","text":"<p>All AIM resources follow a common status progression:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Pending\n    Pending --&gt; Starting : Dependencies resolved\n    Starting --&gt; Progressing : Resources created\n    Progressing --&gt; Ready : All conditions met\n    Progressing --&gt; Running : (AIMService only)\n    Ready --&gt; Degraded : Partial failure\n    Running --&gt; Degraded : Partial failure\n    Degraded --&gt; Ready : Recovery\n    Degraded --&gt; Running : Recovery\n    Pending --&gt; Failed : Critical error\n    Starting --&gt; Failed : Critical error\n    Progressing --&gt; Failed : Critical error\n    Pending --&gt; NotAvailable : Infrastructure missing</code></pre> Status Priority Description <code>Running</code> 7 Fully operational (AIMService only) <code>Ready</code> 6 Resource is ready <code>Progressing</code> 5 Creating downstream resources <code>Starting</code> 4 Dependencies resolved, beginning work <code>Pending</code> 3 Waiting for dependencies <code>Degraded</code> 2 Partially functional <code>NotAvailable</code> 1 Required infrastructure not present <code>Failed</code> 0 Critical failure <p>AIMService maps <code>Progressing</code> \u2192 <code>Starting</code> and <code>Ready</code> \u2192 <code>Running</code> for clarity.</p>"},{"location":"concepts/resource-lifecycle/#conditions","title":"Conditions","text":"<p>The reconciliation framework manages a standard set of conditions on every resource:</p> Condition Description <code>DependenciesReachable</code> All upstream dependencies exist and are accessible <code>AuthValid</code> Authentication and authorization are valid <code>ConfigValid</code> Resource configuration is valid <code>Ready</code> Overall readiness <p>AIMService adds component-specific conditions:</p> Condition Description <code>ModelReady</code> Model resolved and ready <code>TemplateReady</code> Template resolved and ready <code>RuntimeConfigReady</code> Runtime config resolved <code>InferenceServiceReady</code> KServe InferenceService is ready <code>InferenceServicePodsReady</code> Inference pods are running <code>CacheReady</code> Model cache is ready <code>HTTPRouteReady</code> HTTPRoute is configured <code>HPAReady</code> KEDA autoscaling is configured"},{"location":"concepts/resource-lifecycle/#finalizers","title":"Finalizers","text":"<p>AIM Engine uses finalizers to handle cleanup that can't be done through owner references alone.</p>"},{"location":"concepts/resource-lifecycle/#aimservice-finalizer","title":"AIMService Finalizer","text":"<p>Finalizer: <code>aim.eai.amd.com/template-cache-cleanup</code></p> <p>When a service is deleted, the finalizer removes non-Ready template caches that were created by this service. Ready caches are preserved for reuse by other services.</p>"},{"location":"concepts/resource-lifecycle/#aimtemplatecache-finalizer","title":"AIMTemplateCache Finalizer","text":"<p>Finalizer: <code>aim.eai.amd.com/artifactcleanup</code></p> <p>When a template cache is deleted, the finalizer removes non-Ready artifacts. Ready artifacts with completed downloads are preserved.</p>"},{"location":"concepts/resource-lifecycle/#namespace-deletion","title":"Namespace Deletion","text":"<p>Finalizers do not block namespace deletion. Kubernetes handles namespace termination by force-removing finalizers on resources within the namespace.</p>"},{"location":"concepts/resource-lifecycle/#validation","title":"Validation","text":"<p>AIM Engine validates resources at two levels: admission time and reconciliation time.</p>"},{"location":"concepts/resource-lifecycle/#admission-validation-immediate","title":"Admission Validation (Immediate)","text":"<p>CRD schemas include CEL validation rules that run when you <code>kubectl apply</code>. Invalid resources are rejected immediately by the API server.</p> <p>Key immutability rules (cannot be changed after creation):</p> CRD Immutable Field Error Message AIMService <code>spec.model</code> Model selection is immutable after creation AIMService <code>spec.template</code> Template selection is immutable after creation AIMService <code>spec.caching</code> Caching mode is immutable after creation AIMArtifact <code>spec.sourceUri</code> sourceUri is immutable AIMServiceTemplate <code>spec.modelName</code> Model name is immutable All templates <code>spec.metric</code>, <code>spec.precision</code>, <code>spec.hardware</code> Immutable after creation <p>Key structural rules:</p> CRD Rule AIMService Exactly one of <code>model.name</code>, <code>model.image</code>, or <code>model.custom</code> must be specified AIMService (custom) At least one model source required Hardware At least one of <code>gpu</code> or <code>cpu</code> must be specified GPU <code>model</code> and <code>minVram</code> are mutually exclusive"},{"location":"concepts/resource-lifecycle/#reconciliation-validation-eventual","title":"Reconciliation Validation (Eventual)","text":"<p>Domain logic validation runs during reconciliation and surfaces as condition updates:</p> <ul> <li>Reference resolution (model not found, template not found)</li> <li>Template selection (ambiguous, no candidates)</li> <li>Image URI validation</li> <li>Path template resolution</li> </ul> <p>These appear as condition changes rather than immediate API errors. Check <code>ConfigValid</code> and component conditions for reconciliation-time validation failures.</p> <p>Note</p> <p>AIM Engine does not use admission webhooks. All immediate validation is via CEL rules in the CRD schema. The webhook flags in the operator binary exist for potential future use.</p>"},{"location":"concepts/resource-lifecycle/#discovery-and-download-jobs","title":"Discovery and Download Jobs","text":"<p>AIM Engine creates short-lived Kubernetes Jobs for template discovery and model artifact operations. These are the transient pods you may see in your namespaces.</p>"},{"location":"concepts/resource-lifecycle/#discovery-jobs","title":"Discovery Jobs","text":"<p>Created when a template needs to discover its runtime profiles from a model container image.</p> Property Value Name pattern <code>discover-{template}-{hash}</code> Container <code>discovery</code> \u2014 runs the model image with <code>dry-run --format=json</code> Created when Template is not Ready and has no inline model sources Duration Varies (depends on image startup time) Cleanup TTL 60 seconds after completion; also garbage-collected when parent template is deleted Retries BackoffLimit 0 (immediate fail); controller retries with exponential backoff (60s base, 3600s max) Concurrency Max 10 concurrent discovery jobs per reconcile Labels <code>aim.eai.amd.com/template</code>, <code>app.kubernetes.io/component: discovery</code> <p>For cluster-scoped templates, discovery jobs run in the operator namespace.</p>"},{"location":"concepts/resource-lifecycle/#check-size-jobs","title":"Check-Size Jobs","text":"<p>Created when an AIMArtifact needs to discover the model size before provisioning a PVC.</p> Property Value Name pattern <code>{artifact}-check-size-{hash}</code> Container <code>check-size</code> \u2014 runs <code>/check-size.sh</code> with the source URI Created when <code>spec.size</code> is not set and size hasn't been discovered yet Duration Seconds (HTTP HEAD request) Cleanup TTL 5 minutes after completion Retries BackoffLimit 2 Labels <code>aim.eai.amd.com/cache.type: artifact</code>, <code>aim.eai.amd.com/component: check-size</code>"},{"location":"concepts/resource-lifecycle/#download-jobs","title":"Download Jobs","text":"<p>Created when an AIMArtifact needs to download model data to a PVC.</p> Property Value Name pattern <code>{artifact}-download-{hash}</code> Container <code>download</code> \u2014 runs the artifact downloader image Created when PVC is bound and download hasn't completed Duration Minutes to hours (depends on model size and protocol) Labels <code>aim.eai.amd.com/cache.type: artifact</code>, <code>aim.eai.amd.com/component: model-storage</code>"},{"location":"concepts/resource-lifecycle/#model-source-scanning","title":"Model Source Scanning","text":"<p><code>AIMClusterModelSource</code> does not create jobs. Registry scanning runs inside the operator process using HTTP calls to container registry APIs.</p>"},{"location":"concepts/resource-lifecycle/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture \u2014 High-level component overview</li> <li>AIM Services \u2014 Service deployment lifecycle</li> <li>Model Caching \u2014 Cache ownership and deletion behavior</li> </ul>"},{"location":"concepts/runtime-config/","title":"Runtime Configuration Architecture","text":"<p>Runtime configurations provide storage defaults and routing parameters. This document explains the resolution algorithm, inheritance model, and status tracking.</p>"},{"location":"concepts/runtime-config/#resolution-model","title":"Resolution Model","text":"<p>The AIM operator resolves runtime settings from two Custom Resource Definitions:</p> <ul> <li><code>AIMClusterRuntimeConfig</code>: Cluster-wide defaults that apply across namespaces, useful for single-tenant clusters</li> <li><code>AIMRuntimeConfig</code>: Namespace-scoped configuration including authentication secrets, useful for multi-tenant clusters</li> </ul>"},{"location":"concepts/runtime-config/#resolution-algorithm","title":"Resolution Algorithm","text":"<p>When a workload references <code>runtimeConfigName: my-config</code>:</p> <ol> <li>The controller first looks for <code>AIMRuntimeConfig</code> named <code>my-config</code> in the workload's namespace</li> <li>If both namespace and cluster configs exist, they are merged (namespace values take precedence). Note also that any runtimeconfig embedded in AIMService takes precedence over namespaced runtimeconfig values.</li> <li>If not found, the controller falls back to <code>AIMClusterRuntimeConfig</code> named <code>my-config</code></li> <li>The resolved configuration is published in the consumer's <code>status.resolvedRuntimeConfig</code></li> </ol> <p>When <code>runtimeConfigName</code> is omitted, the controller resolves a config named <code>default</code>. If this is not found, no error is raised. However, if a config that is not named <code>default</code> is specified, it must exist, otherwise an error is raised.</p>"},{"location":"concepts/runtime-config/#resolved-runtime-config-tracking","title":"Resolved Runtime Config Tracking","text":"<p>The resolved configuration is published in <code>status.resolvedRuntimeConfig</code> with: - Reference to the source object (namespace or cluster scope) - UID of the resolved config for identity tracking</p>"},{"location":"concepts/runtime-config/#namespace-config-status","title":"Namespace Config Status","text":"<pre><code>status:\n  resolvedRuntimeConfig:\n    kind: AIMRuntimeConfig\n    name: default\n    namespace: ml-team\n    scope: Namespace\n    uid: abc123-def456-...\n</code></pre>"},{"location":"concepts/runtime-config/#cluster-config-status","title":"Cluster Config Status","text":"<pre><code>status:\n  resolvedRuntimeConfig:\n    kind: AIMClusterRuntimeConfig\n    name: default\n    namespace: \"\"\n    scope: Cluster\n    uid: xyz123-uvw123-...\n</code></pre> <p>Only one ref (namespace or cluster) is present, never both.</p>"},{"location":"concepts/runtime-config/#resources-supporting-runtime-config","title":"Resources Supporting Runtime Config","text":"<p>The following AIM resources accept <code>runtimeConfigName</code>:</p> <ul> <li><code>AIMModel</code> / <code>AIMClusterModel</code></li> <li><code>AIMServiceTemplate</code> / <code>AIMClusterServiceTemplate</code></li> <li><code>AIMService</code></li> <li><code>AIMTemplateCache</code></li> </ul> <p>Each resource independently resolves its runtime config and publishes the result in status.</p>"},{"location":"concepts/runtime-config/#configuration-scoping","title":"Configuration Scoping","text":""},{"location":"concepts/runtime-config/#cluster-runtime-configuration","title":"Cluster Runtime Configuration","text":"<p><code>AIMClusterRuntimeConfig</code> captures non-secret defaults shared across namespaces:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  defaultStorageClassName: fast-nvme\n</code></pre> <p>Use cases: - Platform-wide storage class defaults - Shared routing configurations for clusters without multi-tenancy</p> <p>Limitations: - Cannot enforce namespace-specific policies</p>"},{"location":"concepts/runtime-config/#namespace-runtime-configuration","title":"Namespace Runtime Configuration","text":"<p><code>AIMRuntimeConfig</code> provides namespace-specific configuration including authentication:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  defaultStorageClassName: team-ssd\n  routing:\n    enabled: true\n    gatewayRef:\n      name: kserve-gateway\n      namespace: kgateway-system\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.labels['team']}\"\n</code></pre> <p>Use cases: - Namespace-level routing policies - Custom storage classes per team</p>"},{"location":"concepts/runtime-config/#routing-templates","title":"Routing Templates","text":"<p>Runtime configs can supply a reusable HTTP route template via <code>spec.routing.pathTemplate</code>. The template is rendered against the <code>AIMService</code> object using JSONPath expressions.</p>"},{"location":"concepts/runtime-config/#template-syntax","title":"Template Syntax","text":"<pre><code>spec:\n  routing:\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.labels['team']}/{.spec.aimImageName}/\"\n</code></pre>"},{"location":"concepts/runtime-config/#rendering-process","title":"Rendering Process","text":"<p>During reconciliation:</p> <ol> <li>Evaluation: Each placeholder (e.g., <code>{.metadata.namespace}</code>) is evaluated with JSONPath</li> <li>Validation: Missing fields, invalid expressions, or multi-value results fail the render</li> <li>Normalization: Each path segment is:</li> <li>Lowercased</li> <li>RFC 3986 encoded</li> <li>De-duplicated (multiple slashes collapsed)</li> <li>Length Check: Final path must be \u2264 200 characters</li> <li>Trailing Slash: Removed</li> </ol>"},{"location":"concepts/runtime-config/#rendering-failures","title":"Rendering Failures","text":"<p>A rendered path that:</p> <ul> <li>Exceeds 200 characters</li> <li>Contains invalid JSONPath</li> <li>References missing labels/fields</li> </ul> <p>...degrades the <code>AIMService</code> with reason <code>PathTemplateInvalid</code> and skips HTTPRoute creation. The InferenceService remains intact.</p>"},{"location":"concepts/runtime-config/#precedence","title":"Precedence","text":"<p>Services evaluate path templates in this order:</p> <ol> <li><code>AIMService.spec.routing.pathTemplate</code> (highest precedence)</li> <li>Runtime config's <code>spec.routing.pathTemplate</code></li> <li>Default: <code>/&lt;namespace&gt;/&lt;service-uid&gt;</code></li> </ol> <p>This allows:</p> <ul> <li>Runtime configs: Set namespace-wide path conventions</li> <li>Services: Override with specific paths when needed</li> </ul>"},{"location":"concepts/runtime-config/#example","title":"Example","text":"<p>Runtime config with path template:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/ml/{.metadata.namespace}/{.metadata.labels['project']}\"\n</code></pre> <p>Service using template:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\n  labels:\n    project: conversational-ai\nspec:\n  model:\n    name: qwen-qwen3-32b\n  # routing.pathTemplate omitted - uses runtime config template\n</code></pre> <p>Rendered path: <code>/ml/ml-team/conversational-ai</code></p> <p>Service with override:</p> <pre><code>spec:\n  model:\n    ref: qwen-qwen3-32b\n  routing:\n    pathTemplate: \"/custom/{.metadata.name}\"\n</code></pre> <p>Rendered path: <code>/custom/qwen-chat</code> (runtime config template ignored)</p>"},{"location":"concepts/runtime-config/#error-and-warning-behavior","title":"Error and Warning Behavior","text":""},{"location":"concepts/runtime-config/#missing-explicit-config","title":"Missing Explicit Config","text":"<p>When a workload explicitly references a non-existent config:</p> <pre><code>spec:\n  runtimeConfigName: non-existent\n</code></pre> <p>Result: - Reconciliation fails - Workload enters <code>Failed</code> or <code>Degraded</code> state with reason <code>ConfigNotFound</code> - Reconciliation retries until the config appears</p>"},{"location":"concepts/runtime-config/#missing-default-config","title":"Missing Default Config","text":"<p>When the implicit <code>default</code> config doesn't exist:</p> <ul> <li>A <code>RuntimeConfigReady</code> condition is set to <code>True</code> with reason <code>DefaultConfigNotFound</code></li> <li>A Normal event is emitted on the first reconcile with reason <code>DefaultConfigNotFound</code></li> <li>Reconciliation continues without runtime config overrides</li> <li>Workloads relying on private registries may fail later unless a namespace config supplies credentials This allows workloads without special requirements to proceed even when no default config exists.</li> </ul>"},{"location":"concepts/runtime-config/#label-propagation","title":"Label Propagation","text":"<p>Runtime configurations support automatic label propagation from parent AIM resources to their child Kubernetes resources. This feature helps maintain consistent metadata across the resource hierarchy for tracking, cost allocation, and compliance purposes.</p>"},{"location":"concepts/runtime-config/#configuration","title":"Configuration","text":"<p>Label propagation is configured in the runtime config's <code>labelPropagation</code> section:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  labelPropagation:\n    enabled: true\n    match:\n      - \"org.example/cost-center\"\n      - \"org.example/team\"\n      - \"compliance.example/*\"  # Wildcard matches any label with this prefix\n</code></pre>"},{"location":"concepts/runtime-config/#propagation-behavior","title":"Propagation Behavior","text":"<p>When enabled, labels matching the specified patterns are automatically copied from parent resources to child resources:</p> <ul> <li>AIMService \u2192 InferenceService, HTTPRoute, PVCs, auto-created AIMModel</li> <li>AIMTemplateCache \u2192 AIMArtifact resources</li> <li>AIMArtifact \u2192 PVCs, download Jobs</li> <li>AIMModel/AIMClusterModel \u2192 auto-created AIMServiceTemplates</li> <li>AIMServiceTemplate \u2192 AIMTemplateCache</li> <li>AIMClusterModelSource \u2192 auto-created AIMClusterModel resources</li> </ul>"},{"location":"concepts/runtime-config/#pattern-matching","title":"Pattern Matching","text":"<p>The <code>match</code> field accepts exact label keys or wildcard patterns:</p> <ul> <li><code>\"org.example/team\"</code> - Matches exactly this label key</li> <li><code>\"org.example/*\"</code> - Matches any label with the prefix <code>org.example/</code></li> <li><code>\"compliance.*/severity\"</code> - Matches labels like <code>compliance.sec/severity</code>, <code>compliance.audit/severity</code></li> </ul>"},{"location":"concepts/runtime-config/#special-handling","title":"Special Handling","text":"<p>For Job resources, propagated labels are applied to both: 1. The Job's metadata labels 2. The Job's PodTemplateSpec labels (enabling pod-level tracking)</p>"},{"location":"concepts/runtime-config/#example-use-case","title":"Example Use Case","text":"<p>A typical configuration for multi-tenant cost tracking:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  labelPropagation:\n    enabled: true\n    match:\n      - \"org.example/cost-center\"\n      - \"org.example/department\"\n      - \"org.example/project\"\n</code></pre> <p>When users create an AIMService with these labels:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\n  labels:\n    org.example/cost-center: \"eng-ml\"\n    org.example/department: \"engineering\"\n    org.example/project: \"chatbot-v2\"\nspec:\n  model:\n    ref: qwen-qwen3-32b\n</code></pre> <p>The operator propagates these labels to the InferenceService, HTTPRoute, and any PVCs created for the service, enabling cost tracking and chargeback at the infrastructure level.</p>"},{"location":"concepts/runtime-config/#environment-variable-overrides","title":"Environment Variable Overrides","text":"<p>Runtime configurations can inject environment variables into managed workloads via <code>spec.env</code>. This is useful for setting defaults across an entire namespace or cluster, such as the download protocol strategy for model artifacts.</p>"},{"location":"concepts/runtime-config/#download-protocol-strategy","title":"Download Protocol Strategy","text":"<p>The <code>AIM_DOWNLOADER_PROTOCOL</code> environment variable controls the sequence of protocols tried when downloading HuggingFace models. See Model Caching \u2013 Download Protocol Strategy for full details.</p>"},{"location":"concepts/runtime-config/#example-cluster-default-for-environments-where-xet-is-unreliable","title":"Example: Cluster default for environments where XET is unreliable","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  env:\n    - name: AIM_DOWNLOADER_PROTOCOL\n      value: \"HTTP,XET\"\n</code></pre>"},{"location":"concepts/runtime-config/#example-namespace-override-preferring-plain-http","title":"Example: Namespace override preferring plain HTTP","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  env:\n    - name: AIM_DOWNLOADER_PROTOCOL\n      value: \"HTTP\"\n</code></pre>"},{"location":"concepts/runtime-config/#merge-precedence","title":"Merge Precedence","text":"<p>Environment variables are merged with the following precedence (highest first):</p> <ol> <li><code>AIMArtifact.spec.env</code> (per-artifact)</li> <li><code>AIMRuntimeConfig.spec.env</code> (namespace-scoped)</li> <li><code>AIMClusterRuntimeConfig.spec.env</code> (cluster-scoped)</li> <li>Operator defaults (e.g., <code>AIM_DOWNLOADER_PROTOCOL=XET,HF_TRANSFER</code>)</li> </ol> <p>This means an individual artifact can always override any runtime config setting when needed.</p>"},{"location":"concepts/runtime-config/#operator-namespace","title":"Operator Namespace","text":"<p>The AIM controllers determine the operator namespace from the <code>AIM_SYSTEM_NAMESPACE</code> environment variable (default: <code>aim-system</code>).</p> <p>Cluster-scoped workflows such as: - Cluster template discovery - Cluster image inspection - Auto-generated cluster templates</p> <p>...run auxiliary pods in this namespace and resolve namespaced runtime configs there.</p>"},{"location":"concepts/runtime-config/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - How models use runtime configs for discovery and auto-creation</li> <li>Templates - Template discovery and runtime config resolution</li> <li>Services Usage - Practical service configuration</li> <li>Model Caching - Download protocol strategy and cache architecture</li> </ul>"},{"location":"concepts/services/","title":"Services","text":"<p>An AIMService is the primary resource for deploying AI/ML models as inference endpoints on Kubernetes. It brings together a Model and a ServiceTemplate to create a running KServe InferenceService.</p>"},{"location":"concepts/services/#overview","title":"Overview","text":"<p>When you create an AIMService, the operator:</p> <ol> <li>Resolves the model (by name reference or image URI), creating an AIMModel if needed</li> <li>Resolves the template (explicit reference or auto-selection)</li> <li>Configures caching if enabled (creates AIMTemplateCache and AIMArtifact resources)</li> <li>Creates a KServe InferenceService with the appropriate configuration</li> <li>Optionally configures routing via Gateway API</li> </ol>"},{"location":"concepts/services/#basic-examples","title":"Basic Examples","text":""},{"location":"concepts/services/#deploy-by-model-name","title":"Deploy by Model Name","text":"<p>Reference an existing model and let AIM Engine auto-select the best template:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-service\n  namespace: ml-team\nspec:\n  model:\n    name: qwen-qwen3-32b\n</code></pre>"},{"location":"concepts/services/#deploy-by-image-uri","title":"Deploy by Image URI","text":"<p>Specify a container image directly. AIM Engine will find or create a matching AIMModel:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-service\n  namespace: ml-team\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <p>When using <code>model.image</code>, AIM Engine searches for existing models with that image URI. If none exist, it creates an AIMModel automatically (without owner references, so it persists for reuse by other services).</p>"},{"location":"concepts/services/#deploy-with-explicit-template","title":"Deploy with Explicit Template","text":"<p>Specify both the model and template explicitly:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-service\n  namespace: ml-team\nspec:\n  model:\n    name: qwen-qwen3-32b\n  template:\n    name: qwen3-32b-mi300x-fp16-latency\n</code></pre>"},{"location":"concepts/services/#model-resolution","title":"Model Resolution","text":"<p>AIMService supports three ways to specify the model:</p> Mode Spec Field Behavior Reference <code>model.name</code> Looks up existing AIMModel or AIMClusterModel by name Image <code>model.image</code> Finds or creates a model matching the image URI Custom <code>model.custom</code> Creates or reuses a namespace-scoped custom AIMModel from inline model sources and hardware requirements"},{"location":"concepts/services/#resolution-order","title":"Resolution Order","text":"<p>When resolving by name, AIM Engine checks:</p> <ol> <li>Namespace-scoped <code>AIMModel</code> with that name</li> <li>Cluster-scoped <code>AIMClusterModel</code> with that name</li> </ol> <p>Namespace-scoped resources take precedence.</p> <p>When resolving by image URI, AIM Engine searches both namespace and cluster-scoped models for a matching <code>spec.image</code>. If no match exists, AIM Engine creates an AIMModel automatically. If multiple matches exist, resolution fails with an error to prevent ambiguity.</p>"},{"location":"concepts/services/#template-resolution","title":"Template Resolution","text":"<p>Templates define how to run a model: GPU requirements, precision, optimization metric, environment variables, and more.</p>"},{"location":"concepts/services/#explicit-template","title":"Explicit Template","text":"<p>When you specify <code>template.name</code>, AIM Engine looks up that template directly:</p> <pre><code>spec:\n  template:\n    name: my-template\n</code></pre> <p>Resolution order: 1. Namespace-scoped <code>AIMServiceTemplate</code> 2. Cluster-scoped <code>AIMClusterServiceTemplate</code></p>"},{"location":"concepts/services/#auto-selection","title":"Auto-Selection","text":"<p>When no template name is specified, AIM Engine automatically selects the best template for the model. This is the recommended approach for most deployments.</p> <p>Auto-selection uses a multi-stage filtering and scoring algorithm:</p>"},{"location":"concepts/services/#stage-1-availability-filter","title":"Stage 1: Availability Filter","text":"<p>Only templates with <code>status: Ready</code> are considered. Templates that are <code>Pending</code>, <code>Progressing</code>, <code>Failed</code>, or <code>NotAvailable</code> are excluded.</p>"},{"location":"concepts/services/#stage-2-optimization-filter","title":"Stage 2: Optimization Filter","text":"<p>By default, only optimized templates are considered. Templates with profile type <code>unoptimized</code> or <code>preview</code> are excluded unless you explicitly allow them:</p> <pre><code>spec:\n  template:\n    allowUnoptimized: true\n</code></pre> <p>This prevents accidentally deploying unoptimized configurations in production. Set <code>allowUnoptimized: true</code> during development or when optimized templates aren't available for your hardware.</p>"},{"location":"concepts/services/#stage-3-gpu-availability","title":"Stage 3: GPU Availability","text":"<p>Templates are filtered to only those whose required GPU is available in the cluster. GPU availability is detected via node labels (based on GPU product ID).</p> <p>If a template requires MI300X GPUs but none are available in the cluster, that template is excluded.</p>"},{"location":"concepts/services/#stage-4-scope-preference","title":"Stage 4: Scope Preference","text":"<p>When both namespace-scoped and cluster-scoped templates match, namespace-scoped templates take precedence. This allows teams to customize model deployments without affecting other namespaces.</p>"},{"location":"concepts/services/#stage-5-preference-scoring","title":"Stage 5: Preference Scoring","text":"<p>If multiple templates remain after filtering, AIM Engine scores them using this preference hierarchy (highest to lowest priority):</p> <ol> <li>Profile Type: optimized &gt; preview &gt; unoptimized</li> <li>GPU Tier: MI325X &gt; MI300X &gt; MI250X &gt; MI210</li> <li>Metric: latency &gt; throughput</li> <li>Precision: Primary ordering by bit-width (smaller preferred). Secondary ordering by type: fp &gt; bf &gt; int. Full order: fp4 &gt; int4 &gt; fp8 &gt; int8 &gt; fp16 &gt; bf16 &gt; fp32</li> </ol> <p>The template with the best score is selected.</p>"},{"location":"concepts/services/#ambiguous-selection","title":"Ambiguous Selection","text":"<p>If multiple templates have identical scores after all filtering and scoring, AIM Engine reports an ambiguous selection error. Resolve this by:</p> <ul> <li>Specifying <code>template.name</code> explicitly</li> <li>Removing duplicate templates</li> </ul>"},{"location":"concepts/services/#caching","title":"Caching","text":"<p>AIMService supports model caching to avoid downloading model weights on every pod startup. Caching is configured via <code>spec.caching.mode</code>.</p>"},{"location":"concepts/services/#caching-modes","title":"Caching Modes","text":"Mode Behavior <code>Shared</code> (default) Reuses or creates shared cache assets. The template cache and artifacts persist independently of the service and can be reused by other services referencing the same template. <code>Dedicated</code> Creates service-owned cache assets. The template cache and artifacts are owned by the service and garbage-collected when the service is deleted. <pre><code>spec:\n  caching:\n    mode: Shared  # default; use Dedicated for service-owned caches\n</code></pre> <p>When <code>caching</code> is omitted, mode defaults to <code>Shared</code>.</p>"},{"location":"concepts/services/#how-caching-works","title":"How Caching Works","text":"<ol> <li>Template Cache: An <code>AIMTemplateCache</code> pre-downloads all model sources for a template to PVCs</li> <li>Model Caches: Individual <code>AIMArtifact</code> resources manage per-model downloads</li> <li>Cache ownership: In <code>Shared</code> mode, the template cache has no owner references and persists after the service is deleted, available for reuse. In <code>Dedicated</code> mode, the cache is owned by the service and deleted with it.</li> </ol>"},{"location":"concepts/services/#resource-configuration","title":"Resource Configuration","text":"<p>Configure compute resources for the inference container:</p> <pre><code>spec:\n  resources:\n    requests:\n      memory: \"64Gi\"\n      cpu: \"16\"\n    limits:\n      memory: \"128Gi\"\n      amd.com/gpu: \"4\"\n</code></pre>"},{"location":"concepts/services/#image-pull-secrets","title":"Image Pull Secrets","text":"<p>For private registries:</p> <pre><code>spec:\n  imagePullSecrets:\n    - name: registry-credentials\n</code></pre>"},{"location":"concepts/services/#status","title":"Status","text":"<p>Service status reflects the health of all components:</p> Status Meaning <code>Pending</code> Waiting for upstream dependencies (model, template) <code>Starting</code> Creating downstream resources (InferenceService, cache) <code>Running</code> InferenceService is ready and serving traffic <code>Degraded</code> Partially functional (e.g., cache failed but service running) <code>Failed</code> Critical failure preventing deployment"},{"location":"concepts/services/#component-health","title":"Component Health","text":"<p>The status includes health for each component:</p> <ul> <li>Model: Resolution and readiness of the AIMModel</li> <li>Template: Resolution and readiness of the AIMServiceTemplate</li> <li>InferenceService: KServe InferenceService status</li> <li>Cache: Template cache or service PVC status</li> </ul> <p>Check conditions for detailed diagnostics:</p> <pre><code>kubectl get aimservice &lt;name&gt; -o jsonpath='{.status.conditions}' | jq\n</code></pre>"},{"location":"concepts/services/#troubleshooting","title":"Troubleshooting","text":""},{"location":"concepts/services/#service-stuck-in-pending","title":"Service stuck in \"Pending\"","text":"<p>The service is waiting for upstream dependencies:</p> <pre><code># Check which component is blocking\nkubectl get aimservice &lt;name&gt; -o jsonpath='{.status.conditions}' | jq\n</code></pre> <p>Common causes: - Model not found: Check <code>model.name</code> spelling, or ensure <code>model.image</code> is accessible - Template not found: Check <code>template.name</code> or verify templates exist for the model - Template not ready: The template's model sources may still be resolving</p>"},{"location":"concepts/services/#service-stuck-in-starting","title":"Service stuck in \"Starting\"","text":"<p>Downstream resources are being created:</p> <pre><code># Check InferenceService status\nkubectl get inferenceservice -l aim.eai.amd.com/service.name=&lt;name&gt; -n &lt;namespace&gt;\n\n# Check pod status\nkubectl get pods -l serving.kserve.io/inferenceservice=&lt;isvc-name&gt; -n &lt;namespace&gt;\n</code></pre> <p>Use the InferenceService name returned by the first command as <code>&lt;isvc-name&gt;</code>.</p> <p>Common causes: - Image pull errors: Check imagePullSecrets - Resource constraints: Insufficient GPU, memory, or CPU - PVC not binding: Check storage class availability</p>"},{"location":"concepts/services/#template-selection-fails-with-no-templates-found","title":"Template selection fails with \"no templates found\"","text":"<pre><code># List templates for the model\nkubectl get aimservicetemplates -l aim.eai.amd.com/model=&lt;model-name&gt;\n\n# Check if templates are Ready\nkubectl get aimservicetemplates -o custom-columns=NAME:.metadata.name,STATUS:.status.status\n</code></pre> <p>If templates exist but aren't selected: - Templates may be <code>NotAvailable</code> (GPU not in cluster) - Templates may be unoptimized (set <code>allowUnoptimized: true</code>)</p>"},{"location":"concepts/services/#template-selection-is-ambiguous","title":"Template selection is ambiguous","text":"<p>Multiple templates have identical preference scores:</p> <pre><code>kubectl get aimservice &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"Ready\")].message}'\n</code></pre> <p>Resolution: - Specify <code>template.name</code> explicitly - Remove duplicate templates</p>"},{"location":"concepts/services/#cache-errors","title":"Cache errors","text":"<pre><code># Check template cache status\nkubectl get aimtemplatecache -l aim.eai.amd.com/service.name=&lt;name&gt;\n\n# Check artifact status\nkubectl get aimartifact -l aim.eai.amd.com/template=&lt;template-name&gt;\n</code></pre> <p>If cache is failing: - Check storage class supports ReadWriteMany - Verify PVC headroom is sufficient for model size - Check model source URLs are accessible</p>"},{"location":"concepts/services/#storage-size-error","title":"Storage size error","text":"<p>If you see <code>StorageSizeError</code> in the cache health, the template's model sources don't have size information yet. This typically resolves automatically as the template controller discovers model sizes. If it persists, check the template's model source configuration.</p>"},{"location":"concepts/templates/","title":"Service Templates","text":"<p>Service Templates define runtime configurations for models and serve as a discovery cache. This document explains the template architecture, discovery mechanism, and lifecycle management.</p>"},{"location":"concepts/templates/#overview","title":"Overview","text":"<p>Templates fulfill two roles:</p> <ol> <li>Runtime Configuration: Define optimization goals (latency vs throughput), numeric precision, and GPU requirements</li> <li>Discovery Cache: Store model artifact metadata to avoid repeated discovery operations</li> </ol> <p>The discovery cache function is critical. When a template is created, the operator runs the container with dry-run argument and inspects the result to determine which model artifacts must be downloaded. This information is stored in <code>status.modelSources[]</code> and reused by services and caching mechanisms.</p>"},{"location":"concepts/templates/#cluster-vs-namespace-scope","title":"Cluster vs Namespace Scope","text":""},{"location":"concepts/templates/#aimclusterservicetemplate","title":"AIMClusterServiceTemplate","text":"<p>Cluster-scoped templates are typically installed by administrators as part of model catalog bundles. They arrive through GitOps workflows, Helm installations, or operator bundles.</p> <p>Key characteristics:</p> <ul> <li>Cannot enable caching directly (caching is namespace-specific)</li> <li>Can be cached into namespaces using <code>AIMTemplateCache</code> resources</li> <li>Discovery runs in the operator namespace (default: <code>aim-system</code>)</li> <li>Provide baseline runtime profiles maintained by platform teams</li> </ul>"},{"location":"concepts/templates/#aimservicetemplate","title":"AIMServiceTemplate","text":"<p>Namespace-scoped templates are created by ML engineers and data scientists for custom runtime profiles.</p> <p>Key characteristics:</p> <ul> <li>Can enable model caching via <code>spec.caching.enabled</code></li> <li>Support namespace-specific secrets and authentication</li> <li>Discovery runs in the template's namespace</li> <li>Allow teams to customize configurations beyond cluster baselines</li> </ul>"},{"location":"concepts/templates/#template-specification","title":"Template Specification","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: qwen3-32b-throughput\n  namespace: ml-research\nspec:\n  modelName: qwen-qwen3-32b\n  runtimeConfigName: ml-research\n  metric: throughput\n  precision: fp8\n  hardware:\n    gpu:\n      requests: 2\n      model: MI300X\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n  imagePullSecrets:\n    - name: registry-credentials\n</code></pre>"},{"location":"concepts/templates/#common-fields","title":"Common Fields","text":"Field Description <code>modelName</code> Model identifier referencing an <code>AIMModel</code> or <code>AIMClusterModel</code> by <code>metadata.name</code>. Immutable after creation. <code>runtimeConfigName</code> Runtime configuration for storage defaults and discovery settings. Defaults to <code>default</code>. <code>metric</code> Optimization goal: <code>latency</code> (interactive) or <code>throughput</code> (batch processing). Immutable after creation. <code>precision</code> Numeric precision: <code>auto</code>, <code>fp4</code>, <code>fp8</code>, <code>fp16</code>, <code>fp32</code>, <code>bf16</code>, <code>int4</code>, <code>int8</code>. Immutable after creation. <code>hardware.gpu.requests</code> Number of GPUs per replica. Immutable after creation. <code>hardware.gpu.model</code> GPU type (e.g., <code>MI300X</code>, <code>MI325X</code>). Immutable after creation. <code>hardware.cpu</code> CPU requirements (optional). For CPU-only models, use <code>hardware.cpu</code> without <code>hardware.gpu</code>. Immutable after creation. <code>imagePullSecrets</code> Secrets for pulling container images during discovery and inference. Must exist in the same namespace (or operator namespace for cluster templates). <code>serviceAccountName</code> Service account for discovery jobs and inference pods. If empty, uses the default service account. <code>resources</code> Container resource requirements. These override model defaults. <code>modelSources</code> Static model sources (optional). When provided, discovery is skipped and these sources are used directly. See Static Model Sources below."},{"location":"concepts/templates/#hardware-propagation-and-node-affinity","title":"Hardware propagation and node affinity","text":"<p>The <code>hardware</code> field specifies GPU and CPU requirements. It is part of the shared runtime parameters (<code>AIMRuntimeParameters</code>) and flows as follows:</p> <ul> <li>AIMModel: For custom models, <code>spec.custom.hardware</code> defines default requirements; <code>spec.customTemplates[].hardware</code> can override per template. The model controller merges these when creating or updating templates.</li> <li>AIMServiceTemplate / AIMClusterServiceTemplate: <code>spec.hardware</code> is the source of truth for the template. The template controller resolves it (with discovery when applicable) and writes <code>status.resolvedHardware</code>, which is used by the service controller when creating the inference workload.</li> </ul> <p>Node affinity: From <code>spec.hardware.gpu</code> (or <code>status.resolvedHardware.gpu</code>), the operator builds node affinity rules so that inference pods schedule only on nodes that have the required GPU type (and, when specified, sufficient VRAM). GPU availability is detected via node labels (e.g. GPU product ID). If the required GPU is not present in the cluster, the template status becomes <code>NotAvailable</code>.</p>"},{"location":"concepts/templates/#namespace-specific-fields","title":"Namespace-Specific Fields","text":"Field Description <code>env</code> Environment variables for model downloads (typically authentication tokens). <code>caching</code> Caching configuration for namespace-scoped templates. When enabled, models are cached on startup."},{"location":"concepts/templates/#discovery-process","title":"Discovery Process","text":"<p>When a template is created or its spec changes:</p> <ol> <li> <p>Job Creation: The controller creates a Kubernetes Job using the container image referenced by <code>modelName</code> (resolved via <code>AIMModel</code> or <code>AIMClusterModel</code>)</p> </li> <li> <p>Dry-Run Inspection: The job runs the container in dry-run mode, examining model requirements without downloading large files</p> </li> <li> <p>Metadata Extraction: The job outputs:</p> <ul> <li>Model source URIs (often Hugging Face Hub references)</li> <li>Expected sizes in bytes</li> <li>Engine arguments and environment variables</li> </ul> </li> <li> <p>Status Update: Discovered information is written to <code>status.modelSources[]</code> and <code>status.profile</code></p> </li> </ol> <p>Discovery completes in seconds. The cached metadata remains available for all services referencing this template.</p>"},{"location":"concepts/templates/#discovery-location","title":"Discovery Location","text":"<ul> <li>Cluster templates: Discovery runs in the operator namespace (default: <code>aim-system</code>)</li> <li>Namespace templates: Discovery runs in the template's namespace</li> </ul> <p>This allows namespace templates to access namespace-specific secrets during discovery.</p>"},{"location":"concepts/templates/#model-sources","title":"Model Sources","text":"<p>The <code>status.modelSources[]</code> array is the primary discovery output:</p> <pre><code>status:\n  modelSources:\n    - name: Qwen/Qwen3-32B\n      source: hf://Qwen/Qwen3-32B\n      sizeBytes: 17179869184\n    - name: tokenizer\n      source: hf://Qwen/Qwen3-32B/tokenizer.json\n      sizeBytes: 2097152\n</code></pre> <p>Services reference this array when determining runtime requirements.</p>"},{"location":"concepts/templates/#static-model-sources","title":"Static Model Sources","text":"<p>Templates can optionally provide static model sources in <code>spec.modelSources</code> instead of relying on discovery. When static sources are provided:</p> <ol> <li>Discovery is skipped: No discovery job is created</li> <li>Sources are used directly: The provided sources are copied to <code>status.modelSources[]</code></li> <li>Faster startup: Templates become <code>Ready</code> immediately without waiting for discovery</li> <li>Manual maintenance: Sources must be updated manually when the model changes</li> </ol> <p>This is useful when:</p> <ul> <li>Discovery is not available or not needed</li> <li>Model sources are already known and stable</li> <li>You want to avoid the discovery job overhead</li> <li>Working with custom or non-standard container images</li> </ul> <p>Example with static sources:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: qwen3-32b-static\n  namespace: ml-research\nspec:\n  modelName: qwen-qwen3-32b\n  metric: latency\n  precision: fp16\n  hardware:\n    gpu:\n      requests: 1\n      model: MI300X\n  modelSources:\n    - name: Qwen/Qwen3-32B\n      sourceURI: hf://Qwen/Qwen3-32B\n      size: 16Gi\n    - name: tokenizer\n      sourceURI: hf://Qwen/Qwen3-32B/tokenizer.json\n      size: 2Mi\n</code></pre> <p>When <code>spec.modelSources</code> is provided, the template moves directly to <code>Ready</code> status without running a discovery job.</p>"},{"location":"concepts/templates/#discovery-job-limits","title":"Discovery Job Limits","text":"<p>The AIM operator enforces a global limit of 10 concurrent discovery jobs across the entire cluster. This prevents resource exhaustion when many templates are created simultaneously.</p> <p>When this limit is reached:</p> <ul> <li>New templates wait in <code>Pending</code> status with reason <code>AwaitingDiscovery</code></li> <li>Discovery jobs are queued and run as existing jobs complete</li> <li>Services referencing waiting templates remain in <code>Starting</code> status</li> </ul> <p>To avoid delays:</p> <ul> <li>Use static model sources when discovery is not needed</li> <li>Stagger template creation when deploying many models at once</li> <li>Consider whether cluster-scoped templates can be shared across namespaces</li> </ul>"},{"location":"concepts/templates/#template-status","title":"Template Status","text":""},{"location":"concepts/templates/#status-fields","title":"Status Fields","text":"Field Type Description <code>observedGeneration</code> int64 Most recent generation observed <code>status</code> enum <code>Pending</code>, <code>Progressing</code>, <code>NotAvailable</code>, <code>Ready</code>, <code>Degraded</code>, <code>Failed</code> <code>conditions</code> []Condition Detailed conditions: <code>Discovered</code>, <code>CacheReady</code>, <code>RuntimeConfigReady</code>, <code>ModelFound</code>, <code>Ready</code> <code>resolvedRuntimeConfig</code> object Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>resolvedModel</code> object Metadata about the model image that was resolved (name, namespace, scope, UID) <code>resolvedHardware</code> object Resolved GPU/CPU requirements (from discovery + spec). Used by the service controller for resource requests and node affinity. <code>hardwareSummary</code> string Human-readable summary of the hardware requirements (e.g. GPU model and count). <code>modelSources</code> []ModelSource Discovered or static model artifacts with URIs and sizes <code>profile</code> JSON Complete discovery result with engine arguments and metadata"},{"location":"concepts/templates/#status-lifecycle","title":"Status Lifecycle","text":"<ul> <li>Pending: Template created, discovery not yet started</li> <li>Progressing: Discovery job running or cache warming in progress</li> <li>NotAvailable: Template cannot run because required GPU resources are not present in the cluster</li> <li>Ready: Discovery succeeded (or static sources provided), template ready for use</li> <li>Degraded: Template is partially functional but has issues</li> <li>Failed: Discovery encountered terminal errors</li> </ul> <p>Services wait for templates to reach <code>Ready</code> before deploying.</p>"},{"location":"concepts/templates/#conditions","title":"Conditions","text":"<p>Discovered: Reports discovery status. Reasons:</p> <ul> <li><code>DiscoveryComplete</code>: Discovery completed successfully and runtime profiles were extracted</li> <li><code>InlineModelSources</code>: Template defines inline model sources, so no discovery job is needed</li> <li><code>AwaitingDiscovery</code>: Discovery job has been created and is waiting to run</li> <li><code>DiscoveryFailed</code>: Discovery job failed (check job logs for details)</li> </ul> <p>CacheReady: Reports caching status (namespace-scoped templates only). Reasons:</p> <ul> <li><code>Ready</code>: All model sources have been cached successfully</li> <li><code>WaitingForCache</code>: Caching has been requested but cache is not yet ready</li> <li><code>CacheDegraded</code>: Cache is partially available but has issues</li> <li><code>CacheFailed</code>: Cache warming failed</li> </ul> <p>Note: The underlying <code>AIMTemplateCache</code> resource uses different reasons (<code>Warm</code>, <code>Warming</code>, <code>Failed</code>) which are translated to the above reasons at the template level.</p> <p>Ready: Reports overall readiness based on all template components.</p>"},{"location":"concepts/templates/#auto-creation-from-model-discovery","title":"Auto-Creation from Model Discovery","text":"<p>When AIM Models have <code>spec.discovery.extractMetadata: true</code> and <code>spec.discovery.createServiceTemplates: true</code>, the controller creates templates from the model's recommended deployments.</p> <p>These auto-created templates:</p> <ul> <li>Use naming from the recommended deployment metadata</li> <li>Include preset metric, precision, and GPU requirements</li> <li>Undergo discovery like manually created templates</li> <li>Are managed by the model controller</li> </ul>"},{"location":"concepts/templates/#template-selection","title":"Template Selection","text":"<p>When <code>AIMService.spec.template.name</code> is omitted, the controller automatically selects a template:</p> <ol> <li>Enumeration: Find all templates referencing the model (either by <code>spec.model.name</code> or matching the auto-created model from <code>spec.model.image</code>)</li> <li>Filtering: Exclude templates not in <code>Ready</code> status</li> <li>GPU Filtering: Exclude templates requiring GPUs not present in the cluster</li> <li>Selection: If exactly one candidate remains, select it</li> </ol> <p>If zero or multiple candidates remain, the service reports a failure condition explaining the issue.</p>"},{"location":"concepts/templates/#examples","title":"Examples","text":""},{"location":"concepts/templates/#cluster-template-latency-optimized","title":"Cluster Template - Latency Optimized","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterServiceTemplate\nmetadata:\n  name: qwen3-32b-latency\nspec:\n  modelName: qwen-qwen3-32b\n  runtimeConfigName: platform-default\n  metric: latency\n  precision: fp16\n  hardware:\n    gpu:\n      requests: 1\n      model: MI300X\n</code></pre>"},{"location":"concepts/templates/#namespace-template","title":"Namespace Template","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: qwen3-32b-throughput\n  namespace: ml-research\nspec:\n  modelName: qwen-qwen3-32b\n  runtimeConfigName: ml-research\n  metric: throughput\n  precision: fp8\n  hardware:\n    gpu:\n      requests: 2\n      model: MI300X\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: hf-creds\n          key: token\n</code></pre>"},{"location":"concepts/templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"concepts/templates/#template-stuck-in-progressing","title":"Template Stuck in Progressing","text":"<p>Check discovery job status:</p> <pre><code># Cluster template\nkubectl -n aim-system get job -l aim.eai.amd.com/template=&lt;template-name&gt;\n\n# Namespace template\nkubectl -n &lt;namespace&gt; get job -l aim.eai.amd.com/template=&lt;template-name&gt;\n</code></pre> <p>View job logs:</p> <pre><code>kubectl -n &lt;namespace&gt; logs job/&lt;job-name&gt;\n</code></pre> <p>Common issues:</p> <ul> <li>Image pull failures (missing/invalid imagePullSecrets)</li> <li>Container crashes during dry-run</li> <li>Runtime config missing</li> </ul>"},{"location":"concepts/templates/#modelsources-empty-after-discovery","title":"ModelSources Empty After Discovery","text":"<p>Check the template status conditions:</p> <pre><code>kubectl -n &lt;namespace&gt; get aimservicetemplate &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"Discovered\")]}'\n</code></pre> <p>The container image may not be a valid AIM container image or may not publish model sources correctly.</p>"},{"location":"concepts/templates/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - Understanding the model catalog and discovery</li> <li>Runtime Config Concepts - Resolution algorithm</li> <li>Model Caching - Cache lifecycle and deletion behavior</li> <li>Services Usage - Deploying services with templates</li> </ul>"},{"location":"contributing/controller-patterns/","title":"Controller Patterns","text":"<p>This guide explains how to implement controllers in AIM Engine using our standardized reconciliation pattern.</p>"},{"location":"contributing/controller-patterns/#quick-start","title":"Quick Start","text":"<p>TL;DR: Implement these methods and you're done:</p> <pre><code>// 1. Fetch resources and implement GetComponentHealth\nfunc (r *Reconciler) FetchRemoteState(\n    ctx context.Context,\n    c client.Client,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n) MyFetchResult {\n    pvc := &amp;corev1.PersistentVolumeClaim{}\n\n    return MyFetchResult{\n        object:              reconcileCtx.Object,\n        // The runtime config is fetched by the pipeline automatically\n        mergedRuntimeConfig: reconcileCtx.MergedRuntimeConfig,\n\n        // Use the utility Fetch function to fetch a Kubernetes resource, automatically wrapping any errors\n        pvc: controllerutils.Fetch(\n            ctx, c,\n            client.ObjectKey{Name: getPvcName(reconcileCtx.Object), Namespace: reconcileCtx.Object.Namespace},\n            pvc,\n        ),\n    }\n}\n\n// Implement GetComponentHealth directly on the fetch result.\n// For standard components you can use an existing health fetcher, or create a new one yourself\nfunc (result MyFetchResult) GetComponentHealth(ctx context.Context, clientset kubernetes.Interface) []controllerutils.ComponentHealth {\n    return []controllerutils.ComponentHealth{\n        result.mergedRuntimeConfig.ToComponentHealth(\"RuntimeConfig\", aimruntimeconfig.GetRuntimeConfigHealth),\n        result.pvc.ToComponentHealth(\"Storage\", controllerutils.GetPvcHealth),\n    }\n}\n\n// 2. ComposeState is a thin passthrough (might be removed in the future)\ntype MyObservation struct {\n    MyFetchResult\n}\n\nfunc (r *Reconciler) ComposeState(\n    ctx context.Context,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n    fetch MyFetchResult,\n) MyObservation {\n    return MyObservation{MyFetchResult: fetch}\n}\n\n// 3. Plan desired state\nfunc (r *Reconciler) PlanResources(\n    ctx context.Context,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n    obs MyObservation,\n) controllerutils.PlanResult {\n    result := controllerutils.PlanResult{}\n\n    // Add a resource to the list of resource to apply\n    result.Apply(buildInferenceService(reconcileCtx.Object))\n    return result\n}\n</code></pre> <p>That's it. The state engine handles the rest automatically.</p> <p>Note on ComposeState/Observation: ComposeState currently just wraps the fetch result in an observation struct. This is a thin passthrough that keeps the door open for more complex observation logic in the future, but it may be removed if this structure proves sufficient. The real work happens in FetchRemoteState and GetComponentHealth.</p>"},{"location":"contributing/controller-patterns/#what-you-get-automatically","title":"What You Get Automatically","text":"<p>When you implement <code>GetComponentHealth()</code>, the state engine automatically:</p> <ul> <li>\u2705 Creates component conditions (ModelReady, TemplateReady, etc.)</li> <li>\u2705 Creates parent conditions when needed (AuthValid, ConfigValid, DependenciesReachable) based on any errors encountered</li> <li>\u2705 Sets Ready condition and status field</li> <li>\u2705 Categorizes errors and decides requeue behavior</li> <li>\u2705 Applies 10-second grace period for transient errors</li> <li>\u2705 Emits events and logs when conditions change (and recurring ones for errors)</li> </ul>"},{"location":"contributing/controller-patterns/#three-approaches","title":"Three Approaches","text":"<p>Choose based on how much control you need:</p>"},{"location":"contributing/controller-patterns/#1-fully-automatic-recommended","title":"1. Fully Automatic (Recommended)","text":"<p>Just implement <code>GetComponentHealth()</code>.</p> <p>Use when: Standard component tracking is all you need.</p>"},{"location":"contributing/controller-patterns/#2-automatic-decorator","title":"2. Automatic + Decorator","text":"<p>Implement <code>GetComponentHealth()</code> + <code>DecorateStatus()</code> to add custom fields.</p> <p>Use when: You need automatic state management but want to add domain-specific status fields like <code>ResolvedTemplate</code>.</p> <pre><code>func (r *Reconciler) DecorateStatus(status *MyStatus, cm *ConditionManager, obs MyObservation) {\n    // State engine already set ModelReady, Ready, status.Status\n    // Just add your custom fields\n    if obs.template != nil {\n        status.ResolvedTemplate = &amp;ResolvedReference{Name: obs.template.Name}\n    }\n}\n</code></pre>"},{"location":"contributing/controller-patterns/#3-fully-manual","title":"3. Fully Manual","text":"<p>Implement <code>SetStatus()</code> to control everything yourself.</p> <p>Use when: Your status logic doesn't fit the component health model.</p> <pre><code>func (r *Reconciler) SetStatus(status *MyStatus, cm *ConditionManager, obs MyObservation) {\n    // You set ALL conditions and status.Status yourself\n    h := controllerutils.NewStatusHelper(status, cm)\n    h.Ready(\"AllGood\", \"Everything is working\")\n    cm.MarkTrue(\"CustomCondition\", \"Reason\", \"Message\", controllerutils.AsInfo())\n}\n</code></pre>"},{"location":"contributing/controller-patterns/#the-four-phases","title":"The Four Phases","text":"<p>Every reconciliation follows this pattern:</p>"},{"location":"contributing/controller-patterns/#1-fetchremotestate","title":"1. FetchRemoteState","text":"<p>Fetch resources from Kubernetes. Use <code>FetchResult[T]</code> wrapper:</p> <pre><code>type MyFetch struct {\n    Model    controllerutils.FetchResult[*aimv1.AIMModel]\n    Template controllerutils.FetchResult[*aimv1.AIMServiceTemplate]\n    Pods     controllerutils.FetchResult[*corev1.PodList]\n}\n\nfunc (r *Reconciler) FetchRemoteState(\n    ctx context.Context,\n    c client.Client,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n) MyFetch {\n    return MyFetch{\n        Model:    controllerutils.Fetch(ctx, c, modelKey, &amp;aimv1.AIMModel{}),\n        Template: controllerutils.Fetch(ctx, c, templateKey, &amp;aimv1.AIMServiceTemplate{}),\n        Pods:     controllerutils.FetchList(ctx, c, &amp;corev1.PodList{}, client.InNamespace(reconcileCtx.Object.Namespace)),\n    }\n}\n</code></pre> <p>Key points: - Use <code>FetchResult[T]</code> wrapper for convenient error handling and component health conversion - All remote API calls should happen here (no client calls in ComposeState or PlanResources) - The <code>reconcileCtx</code> parameter provides access to the object and merged runtime config - This separation enables easy mocking for testing</p>"},{"location":"contributing/controller-patterns/#2-composestate","title":"2. ComposeState","text":"<p>Current pattern: This is a thin passthrough that wraps the fetch result. This keeps the door open for more complex observation logic in the future, but may be removed if this structure proves sufficient.</p> <pre><code>type MyObservation struct {\n    MyFetchResult  // Embed the fetch result\n}\n\nfunc (r *Reconciler) ComposeState(\n    ctx context.Context,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n    fetch MyFetchResult,\n) MyObservation {\n    return MyObservation{MyFetchResult: fetch}\n}\n</code></pre> <p>The real work happens in GetComponentHealth, which you implement on the fetch result:</p> <pre><code>func (result MyFetchResult) GetComponentHealth(ctx context.Context, clientset kubernetes.Interface) []controllerutils.ComponentHealth {\n    health := []controllerutils.ComponentHealth{\n        result.mergedRuntimeConfig.ToComponentHealth(\"RuntimeConfig\", aimruntimeconfig.GetRuntimeConfigHealth),\n        result.pvc.ToComponentHealth(\"Storage\", controllerutils.GetPvcHealth),\n    }\n\n    // Conditional health checking based on status\n    if result.object.Status.Status != constants.AIMStatusReady {\n        if result.downloadJob != nil {\n            health = append(health, result.downloadJob.ToComponentHealth(\"DownloadJob\", controllerutils.GetJobHealth))\n        }\n        if result.downloadJobPods != nil {\n            health = append(health, result.downloadJobPods.ToComponentHealthWithContext(ctx, clientset, \"Pods\", controllerutils.GetPodsHealth))\n        }\n    }\n\n    return health\n}\n</code></pre> <p>Health Inspection Utilities:</p> <p>The framework provides ready-to-use health inspectors for common Kubernetes resources:</p> <pre><code>// For Jobs\nresult.Job.ToComponentHealth(\"DownloadJob\", controllerutils.GetJobHealth)\n\n// For PVCs\nresult.PVC.ToComponentHealth(\"Storage\", controllerutils.GetPvcHealth)\n\n// For Pods (requires context and clientset for log inspection)\nresult.Pods.ToComponentHealthWithContext(ctx, clientset, \"Workload\", controllerutils.GetPodsHealth)\n</code></pre> <p>These utilities automatically categorize errors (auth failures, storage exhaustion, etc.) and set appropriate states.</p> <p>Custom inspection logic:</p> <pre><code>result.Model.ToComponentHealth(\"Model\", func(m *aimv1.AIMModel) controllerutils.ComponentHealth {\n    if m.Status.Status == constants.AIMStatusReady {\n        return controllerutils.ComponentHealth{\n            State: constants.AIMStatusReady,\n            Reason: \"ModelReady\",\n            Message: \"Model is ready\"\n        }\n    }\n    return controllerutils.ComponentHealth{\n        State: constants.AIMStatusProgressing,\n        Reason: \"ModelNotReady\",\n        Message: \"Waiting for model\"\n    }\n})\n</code></pre>"},{"location":"contributing/controller-patterns/#3-planresources","title":"3. PlanResources","text":"<p>Decide what to create/update/delete. This is a pure function - no client calls, just derive desired state based on observations.</p> <pre><code>func (r *Reconciler) PlanResources(\n    ctx context.Context,\n    reconcileCtx controllerutils.ReconcileContext[*aimv1.MyResource],\n    obs MyObservation,\n) controllerutils.PlanResult {\n    obj := reconcileCtx.Object\n    runtimeConfig := reconcileCtx.MergedRuntimeConfig.Value\n\n    result := controllerutils.PlanResult{}\n\n    // Only create resources when dependencies are ready\n    if obs.Model.OK() &amp;&amp; obs.Model.Value.Status.Status == constants.AIMStatusReady {\n        inferenceService := buildInferenceService(obj, runtimeConfig)\n        result.Apply(inferenceService)  // Creates/updates with owner reference\n    }\n\n    // Conditional resource creation\n    if obj.Status.Status != constants.AIMStatusReady &amp;&amp; obs.Job.IsNotFound() {\n        job := buildDownloadJob(obj, runtimeConfig)\n        result.Apply(job)\n    }\n\n    // Shared resources (no owner reference)\n    configMap := buildSharedConfig(obj)\n    result.ApplyWithoutOwnerRef(configMap)\n\n    // Cleanup\n    if shouldCleanup(obs) {\n        oldResource := getOldResource(obj)\n        result.Delete(oldResource)\n    }\n\n    return result\n}\n</code></pre> <p>Key methods: - <code>result.Apply(obj)</code> - Creates/updates with owner reference (garbage collected when owner deleted) - <code>result.ApplyWithoutOwnerRef(obj)</code> - Creates/updates without owner reference (survives owner deletion) - <code>result.Delete(obj)</code> - Deletes the resource</p>"},{"location":"contributing/controller-patterns/#4-optional-decoratestatus","title":"4. (Optional) DecorateStatus","text":"<p>Add custom status fields:</p> <pre><code>func (r *Reconciler) DecorateStatus(status *MyStatus, cm *ConditionManager, obs MyObservation) {\n    // Add domain-specific fields here\n}\n</code></pre>"},{"location":"contributing/controller-patterns/#context-aware-health-inspection","title":"Context-Aware Health Inspection","text":"<p>For advanced health checks that need to inspect logs or additional resources, use the context-aware pattern:</p> <pre><code>// Implement GetComponentHealth with context and clientset parameters\nfunc (fetch MyFetch) GetComponentHealth(ctx context.Context, clientset kubernetes.Interface) []controllerutils.ComponentHealth {\n    health := []controllerutils.ComponentHealth{\n        fetch.RuntimeConfig.ToComponentHealth(\"RuntimeConfig\", getRuntimeConfigHealth),\n        fetch.PVC.ToComponentHealth(\"Storage\", controllerutils.GetPvcHealth),\n    }\n\n    // Conditionally check job/pods based on status\n    if fetch.Object.Status.Status != constants.AIMStatusReady {\n        health = append(health,\n            fetch.Job.ToComponentHealth(\"DownloadJob\", controllerutils.GetJobHealth),\n            fetch.Pods.ToComponentHealthWithContext(ctx, clientset, \"Pods\", controllerutils.GetPodsHealth),\n        )\n    }\n\n    return health\n}\n</code></pre> <p>The pipeline will detect and call this signature automatically, passing context and clientset from the Pipeline configuration.</p> <p>Pod Health Inspection: The <code>GetPodsHealth</code> utility inspects pod logs to categorize failures: - Auth errors (S3 credentials, HuggingFace tokens) - Storage exhaustion (disk full, quota exceeded) - Resource not found (404, missing models) - OOM kills and other termination reasons</p>"},{"location":"contributing/controller-patterns/#error-handling","title":"Error Handling","text":"<p>The state engine automatically categorizes errors:</p> Error Type Behavior Sets Condition Example Infrastructure Requeue with backoff, 10s grace period <code>DependenciesReachable=False</code> Network timeout, API server down Auth Stop apply, fail resource <code>AuthValid=False</code> Forbidden (403), invalid credentials InvalidSpec Stop apply, fail resource <code>ConfigValid=False</code> Invalid configuration, conflicts MissingUpstreamDependency Stop apply, fail resource <code>ConfigValid=False</code> User-referenced config/secret not found MissingDownstreamDependency Mark Progressing, continue Component condition Internal resource not ready yet ResourceExhaustion Stop apply, fail resource Component condition OOM, disk full, quota exceeded <p>Just return errors in <code>ComponentHealth.Errors</code> - categorization is automatic.</p> <p>Distinction: - MissingDownstreamDependency: Resources the controller is creating (pods starting, jobs running) - transient, expected to self-heal - MissingUpstreamDependency: User-referenced resources (configs, secrets) - requires user intervention</p>"},{"location":"contributing/controller-patterns/#observability","title":"Observability","text":"<p>If you need to report custom conditions in the status update methods, you can use the ConditionManager helper.</p> <p>Control event and log emission per condition:</p> <pre><code>// Info log + Normal event on transition (default)\ncm.MarkTrue(condType, reason, msg)\n\n// Silent\ncm.MarkTrue(condType, reason, msg, controllerutils.Silent())\n\n// Error log + Warning event on transition\ncm.MarkFalse(condType, reason, msg, controllerutils.AsWarning())\n\n// Error log + Warning event EVERY reconcile (for critical errors)\ncm.MarkFalse(condType, reason, msg, controllerutils.AsError())\n</code></pre>"},{"location":"contributing/controller-patterns/#quick-reference","title":"Quick Reference","text":"<p>Interfaces to implement:</p> <pre><code>// Required - always implement\ntype DomainReconciler[T, S, F, Obs] interface {\n    FetchRemoteState(ctx, client, obj) F\n    ComposeState(ctx, obj, fetched) Obs\n    PlanResources(ctx, obj, obs) PlanResult\n}\n\n// Automatic mode - implement in observation type\ntype ComponentHealthProvider interface {\n    GetComponentHealth() []ComponentHealth\n}\n\n// Optional - extend automatic status\ntype StatusDecorator[T, S, Obs] interface {\n    DecorateStatus(status, cm, obs)\n}\n\n// Manual mode - full control\ntype ManualStatusController[T, S, Obs] interface {\n    SetStatus(status, cm, obs)\n}\n</code></pre> <p>When to use what:</p> Need Use Standard component tracking Approach 1: GetComponentHealth() Custom status fields Approach 2: GetComponentHealth() + DecorateStatus() Full control Approach 3: SetStatus()"},{"location":"contributing/controller-patterns/#resolved-reference-pattern","title":"Resolved Reference Pattern","text":"<p>When a controller depends on upstream resources (e.g., AIMService \u2192 AIMModel \u2192 AIMServiceTemplate \u2192 AIMTemplateCache), use the resolved reference pattern to optimize fetching while maintaining health visibility.</p>"},{"location":"contributing/controller-patterns/#core-principles","title":"Core Principles","text":"<ol> <li> <p>Only \"lock in\" references when Ready: Store resolved references in status only when the upstream resource is in <code>Ready</code> state. This prevents committing to a resource that may never become usable.</p> </li> <li> <p>Re-search if not Ready or deleted: If a resolved reference exists but the resource is not Ready (or was deleted), fall through to normal resolution logic to find a better alternative.</p> </li> <li> <p>Always return something for health visibility: Even if no Ready resource is found, return the best available match so component health can reflect the current state.</p> </li> <li> <p>Gate fetching on downstream existence: For resources only needed during initial creation (e.g., Model/Template for InferenceService), skip fetching if the downstream resource already exists.</p> </li> </ol>"},{"location":"contributing/controller-patterns/#implementation-pattern","title":"Implementation Pattern","text":"<pre><code>// In fetch function:\nfunc fetchUpstreamResource(ctx context.Context, c client.Client, service *MyService) FetchResult[*UpstreamType] {\n    logger := log.FromContext(ctx)\n\n    // 1. Check if we have a resolved reference AND it's Ready\n    if service.Status.ResolvedUpstream != nil {\n        ref := service.Status.ResolvedUpstream\n        result := controllerutils.Fetch(ctx, c, ref.NamespacedName(), &amp;UpstreamType{})\n\n        if result.OK() &amp;&amp; result.Value.Status.Status == constants.AIMStatusReady {\n            logger.V(1).Info(\"using resolved upstream\", \"name\", ref.Name)\n            return result\n        }\n\n        // Not Ready or deleted - log and fall through to search\n        if result.OK() {\n            logger.V(1).Info(\"resolved upstream not ready, searching for alternatives\",\n                \"name\", ref.Name, \"status\", result.Value.Status.Status)\n        } else if result.IsNotFound() {\n            logger.V(1).Info(\"resolved upstream deleted, searching for alternatives\", \"name\", ref.Name)\n        } else {\n            return result // Real error\n        }\n    }\n\n    // 2. Normal resolution logic (search, list, select best, etc.)\n    // ...\n\n    // 3. Return best match for health visibility (even if not Ready)\n    return bestMatch\n}\n</code></pre> <pre><code>// In DecorateStatus:\nfunc (r *Reconciler) DecorateStatus(status *MyStatus, cm *ConditionManager, obs MyObservation) {\n    // Only set resolved reference if Ready\n    if obs.upstream.Value != nil &amp;&amp; obs.upstream.Value.Status.Status == constants.AIMStatusReady {\n        status.ResolvedUpstream = &amp;AIMResolvedReference{\n            Name: obs.upstream.Value.Name,\n            UID:  obs.upstream.Value.UID,\n            // ...\n        }\n    }\n    // If not Ready, don't update the reference - let fetch re-search next time\n}\n</code></pre>"},{"location":"contributing/controller-patterns/#when-to-apply-this-pattern","title":"When to Apply This Pattern","text":"Scenario Behavior Multiple caches exist for same template Select the healthiest (Ready) one Resolved cache becomes Failed Re-search for a Ready alternative Resolved template deleted Fall through to re-select ISVC exists, template deleted Don't fetch template (config baked into ISVC) ISVC deleted, need to recreate Fetch and resolve dependencies again"},{"location":"contributing/controller-patterns/#gating-fetch-on-downstream-existence","title":"Gating Fetch on Downstream Existence","text":"<p>For upstream resources only needed during creation:</p> <pre><code>func (r *Reconciler) FetchRemoteState(ctx, c, reconcileCtx) FetchResult {\n    result := FetchResult{...}\n\n    // Always fetch downstream resources (we own these)\n    result.inferenceService = fetchInferenceService(ctx, c, service)\n    result.httpRoute = fetchHTTPRoute(ctx, c, service)\n\n    // Always fetch resources that cascade health (e.g., cache chain)\n    result.templateCache = fetchTemplateCache(ctx, c, service)\n\n    // Only fetch upstream if downstream needs (re)creation\n    if !result.inferenceService.OK() {\n        result.model = fetchModel(ctx, c, service)\n        result.template = fetchTemplate(ctx, c, service, result.model)\n    }\n\n    return result\n}\n</code></pre> <p>This optimization: - Avoids false errors when upstream resources are deleted after successful creation - Reduces API calls for running services - Still catches cache health issues proactively (TemplateCache \u2192 Artifact \u2192 PVC chain)</p>"},{"location":"contributing/development-setup/","title":"Development Setup","text":"<p>Set up a local development environment for AIM Engine.</p>"},{"location":"contributing/development-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker or Podman \u2014 For building images and running Kind clusters</li> <li><code>kubectl</code> \u2014 Kubernetes CLI</li> <li>Go 1.24+, controller-gen, golangci-lint, chainsaw \u2014 See Tool Management below</li> </ul>"},{"location":"contributing/development-setup/#tool-management","title":"Tool Management","text":"<p>This project uses mise to pin exact tool versions (Go, controller-gen, chainsaw, golangci-lint, etc.). This is the recommended approach to ensure you have compatible versions:</p> <pre><code># Install mise\ncurl https://mise.run | sh\n\n# Activate mise in your shell (adds tools to PATH)\necho 'eval \"$(mise activate bash)\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Install all project tools\nmise install\n</code></pre> <p>After activation, all tools are available directly on your PATH \u2014 no <code>mise exec --</code> prefix needed.</p> <p>If you prefer to manage tools yourself, check <code>mise.toml</code> for the required versions.</p>"},{"location":"contributing/development-setup/#getting-started","title":"Getting Started","text":"<pre><code>git clone https://github.com/amd-enterprise-ai/aim-engine.git\ncd aim-engine\n</code></pre>"},{"location":"contributing/development-setup/#building","title":"Building","text":"<pre><code>make build        # Build binary to bin/manager\nmake generate     # Generate DeepCopy methods\nmake manifests    # Generate CRDs and RBAC\nmake fmt          # Format code\nmake vet          # Vet code\nmake lint         # Run golangci-lint\n</code></pre>"},{"location":"contributing/development-setup/#local-cluster","title":"Local Cluster","text":"<p>Create a local Kind cluster with dependencies:</p> <pre><code>make kind-create  # Create Kind cluster\nmake install      # Install CRDs\n</code></pre>"},{"location":"contributing/development-setup/#running-the-operator","title":"Running the Operator","text":""},{"location":"contributing/development-setup/#standard-mode","title":"Standard Mode","text":"<pre><code>make run          # Run controller against kubeconfig\nmake run-debug    # Run with debug logging\n</code></pre>"},{"location":"contributing/development-setup/#live-reload-recommended-for-development","title":"Live Reload (Recommended for Development)","text":"<pre><code>make watch        # Rebuild and restart on file changes\n</code></pre> <p>This uses air for live reload. Operator logs are written to timestamped files in <code>.tmp/logs/</code>:</p> <pre><code># Tail the latest log\ntail -f \"$(ls -t .tmp/logs/air-*.log | head -1)\"\n\n# Search for errors\ngrep -E '\"level\":\"error\"' \"$(ls -t .tmp/logs/air-*.log | head -1)\"\n</code></pre>"},{"location":"contributing/development-setup/#readiness-check","title":"Readiness Check","text":"<p>Wait for the operator to be ready before running tests:</p> <pre><code>make wait-ready   # Polls localhost:8081/readyz\n</code></pre>"},{"location":"contributing/development-setup/#environment-switching","title":"Environment Switching","text":"<p>Switch between local (Kind) and remote (GPU vcluster) environments:</p> <pre><code># Kind environment (default)\nmake watch\n\n# GPU environment\nexport KUBE_CONTEXT_GPU=my-vcluster-context\nexport ENV=gpu\nmake watch\n\n# Check current environment\nmake env-info\n</code></pre> <p>The current environment is persisted to <code>.tmp/current-env</code> and shared across terminals.</p>"},{"location":"contributing/development-setup/#code-generation","title":"Code Generation","text":"<p>Pre-commit hooks auto-run <code>make generate</code> and <code>make manifests</code> when <code>api/</code> files change.</p> <p>Generated files (don't edit manually):</p> <ul> <li><code>api/v1alpha1/zz_generated.deepcopy.go</code></li> <li><code>config/crd/bases/*.yaml</code></li> <li><code>config/rbac/role.yaml</code></li> </ul>"},{"location":"contributing/development-setup/#documentation","title":"Documentation","text":"<pre><code>make generate-docs    # Generate CRD and Helm values reference\nmake docs-serve       # Start local docs server\n</code></pre>"},{"location":"contributing/development-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Testing \u2014 Running unit and e2e tests</li> <li>Controller Patterns \u2014 Architecture and implementation patterns</li> </ul>"},{"location":"contributing/observation-design/","title":"Observation Design","text":"<p>Guidelines for structuring your observation types.</p>"},{"location":"contributing/observation-design/#the-observation-step-is-often-optional","title":"The Observation Step is Often Optional","text":"<p>For many controllers, the observation struct can be a thin wrapper around the fetch result. In the future it may be made option, allowing you to implement <code>GetComponentHealth()</code> directly on the fetch result.</p> <pre><code>// Option 1: Thin wrapper (embed fetch result)\ntype MyObservation struct {\n    MyFetch\n}\n\nfunc (r *Reconciler) ComposeState(ctx, reconcileCtx, fetch) MyObservation {\n    return MyObservation{MyFetch: fetch}\n}\n\n// Option 2: Implement directly on fetch result (skip observation entirely)\nfunc (fetch MyFetch) GetComponentHealth() []controllerutils.ComponentHealth {\n    return []controllerutils.ComponentHealth{\n        fetch.Model.ToComponentHealth(\"Model\", inspectModel),\n    }\n}\n</code></pre> <p>Use a separate observation struct only when you need to: - Perform expensive computations once and cache results - Add derived state or boolean checks - Encapsulate complex domain logic</p>"},{"location":"contributing/observation-design/#fields-vs-methods","title":"Fields vs Methods","text":"<p>Rule of thumb: Prefer methods to fields for derived state.</p>"},{"location":"contributing/observation-design/#use-fields-for","title":"Use Fields For","text":"<ul> <li>Raw fetched resources you'll need in PlanResources</li> <li>Expensive computations you want to cache</li> <li>State that comes directly from fetch results</li> </ul> <pre><code>type MyObservation struct {\n    // Store for use in PlanResources\n    template *Template\n\n    // ComponentHealth from fetches\n    modelHealth    ComponentHealth\n    templateHealth ComponentHealth\n}\n</code></pre>"},{"location":"contributing/observation-design/#use-methods-for","title":"Use Methods For","text":"<ul> <li>Derived boolean checks</li> <li>Logic that encapsulates domain knowledge</li> <li>Anything computed from existing fields</li> </ul> <pre><code>func (obs MyObservation) AllDependenciesReady() bool {\n    return obs.modelHealth.GetState() == Ready &amp;&amp;\n           obs.templateHealth.GetState() == Ready\n}\n\nfunc (obs MyObservation) NeedsScaleUp(desired int32) bool {\n    return obs.currentReplicas &lt; desired\n}\n</code></pre> <p>Benefits: - Clear, self-documenting code in PlanResources - Easy to test logic in isolation - No struct bloat with one-off booleans</p>"},{"location":"contributing/observation-design/#decision-checklist","title":"Decision Checklist","text":"<p>When adding to your observation, ask:</p>"},{"location":"contributing/observation-design/#1-is-this-describing-the-current-world-or-a-future-action","title":"1. Is this describing the current world or a future action?","text":"<ul> <li>Current world \u2192 Observation</li> <li>Future action \u2192 PlanResources</li> </ul>"},{"location":"contributing/observation-design/#2-will-this-be-used-in-multiple-places","title":"2. Will this be used in multiple places?","text":"<ul> <li>Yes \u2192 Field or method</li> <li>No \u2192 Compute inline in PlanResources</li> </ul>"},{"location":"contributing/observation-design/#3-does-this-encapsulate-non-trivial-logic","title":"3. Does this encapsulate non-trivial logic?","text":"<ul> <li>Yes \u2192 Method with clear name</li> <li>No \u2192 Maybe inline</li> </ul>"},{"location":"contributing/observation-design/#4-is-it-expensive-to-compute","title":"4. Is it expensive to compute?","text":"<ul> <li>Yes \u2192 Store in field</li> <li>No \u2192 Use a method</li> </ul>"},{"location":"contributing/observation-design/#5-would-a-teammate-understand-without-reading-internals","title":"5. Would a teammate understand without reading internals?","text":"<ul> <li>No \u2192 Reconsider or use a well-named method</li> </ul>"},{"location":"contributing/observation-design/#example-good-observation-design","title":"Example: Good Observation Design","text":"<pre><code>type ServiceObservation struct {\n    // Fields: Raw state and component health\n    modelHealth    ComponentHealth\n    templateHealth ComponentHealth\n    workloadHealth ComponentHealth\n    template       *Template  // Stored for PlanResources\n\n    currentReplicas int32\n    desiredReplicas int32\n}\n\n// Methods: Derived state\nfunc (obs ServiceObservation) GetComponentHealth() []ComponentHealth {\n    return []ComponentHealth{\n        obs.modelHealth,\n        obs.templateHealth,\n        obs.workloadHealth,\n    }\n}\n\nfunc (obs ServiceObservation) AllDependenciesReady() bool {\n    return obs.modelHealth.GetState() == Ready &amp;&amp;\n           obs.templateHealth.GetState() == Ready\n}\n\nfunc (obs ServiceObservation) NeedsScaling() bool {\n    return obs.currentReplicas != obs.desiredReplicas\n}\n\nfunc (obs ServiceObservation) CanDeploy() bool {\n    return obs.AllDependenciesReady() &amp;&amp; !obs.NeedsScaling()\n}\n</code></pre> <p>Then in PlanResources:</p> <pre><code>func (r *Reconciler) PlanResources(ctx, obj, obs) PlanResult {\n    var apply []client.Object\n\n    if obs.CanDeploy() {\n        apply = append(apply, buildWorkload(obj, obs.template))\n    }\n\n    return PlanResult{Apply: apply}\n}\n</code></pre> <p>Clean, readable, testable.</p>"},{"location":"contributing/observation-design/#context-aware-health-inspection","title":"Context-Aware Health Inspection","text":"<p>For advanced health checks that need to inspect pod logs or fetch additional resources, implement <code>GetComponentHealth</code> with context and clientset parameters:</p> <pre><code>// Standard signature (no context)\nfunc (obs MyObservation) GetComponentHealth() []controllerutils.ComponentHealth {\n    return []controllerutils.ComponentHealth{\n        obs.Job.ToComponentHealth(\"Job\", controllerutils.GetJobHealth),\n    }\n}\n\n// Context-aware signature (with clientset for log inspection)\nfunc (obs MyObservation) GetComponentHealth(ctx context.Context, clientset kubernetes.Interface) []controllerutils.ComponentHealth {\n    return []controllerutils.ComponentHealth{\n        obs.Job.ToComponentHealth(\"Job\", controllerutils.GetJobHealth),\n        obs.Pods.ToComponentHealthWithContext(ctx, clientset, \"Pods\", controllerutils.GetPodsHealth),\n    }\n}\n</code></pre> <p>The pipeline automatically detects which signature you've implemented and calls it with the appropriate parameters.</p>"},{"location":"contributing/observation-design/#when-to-use-context-aware-pattern","title":"When to Use Context-Aware Pattern","text":"<p>Use the context-aware signature when you need: - Pod log inspection: Categorize failures from log patterns (auth errors, storage exhaustion) - Additional API calls: Fetch related resources not available in the initial fetch - Complex health checks: PVC usage, service endpoint readiness, etc.</p>"},{"location":"contributing/observation-design/#example-conditional-health-checking","title":"Example: Conditional Health Checking","text":"<pre><code>func (fetch ArtifactFetch) GetComponentHealth(ctx context.Context, clientset kubernetes.Interface) []controllerutils.ComponentHealth {\n    health := []controllerutils.ComponentHealth{\n        fetch.RuntimeConfig.ToComponentHealth(\"RuntimeConfig\", getRuntimeConfigHealth),\n        fetch.PVC.ToComponentHealth(\"Storage\", controllerutils.GetPvcHealth),\n    }\n\n    // Only check job/pods while download is in progress\n    // Once Ready, job may be cleaned up by TTL - don't let its absence affect status\n    if fetch.Object.Status.Status != constants.AIMStatusReady {\n        health = append(health,\n            fetch.Job.ToComponentHealth(\"DownloadJob\", controllerutils.GetJobHealth),\n            fetch.Pods.ToComponentHealthWithContext(ctx, clientset, \"Pods\", controllerutils.GetPodsHealth),\n        )\n    }\n\n    return health\n}\n</code></pre> <p>This pattern: - Avoids spurious failures when cleanup happens - Surfaces detailed error info during active operations - Stops tracking ephemeral resources after success</p>"},{"location":"contributing/observation-design/#health-inspector-utilities","title":"Health Inspector Utilities","text":"<p>The framework provides ready-to-use inspectors:</p> Utility Use For Log Inspection Detects <code>GetJobHealth</code> Batch jobs No BackoffLimitExceeded, DeadlineExceeded, Evicted <code>GetPodsHealth</code> Pod lists Yes (requires clientset) Auth errors, storage exhaustion, OOM, image pull failures <code>GetPvcHealth</code> PVCs No Lost volumes, provisioning failures <p>Pod log inspection categories: - Auth errors: S3 credentials, HuggingFace tokens, registry auth - Storage exhaustion: Disk full, quota exceeded, ENOSPC - Resource not found: 404, Repository Not Found (HuggingFace) - OOM kills: Memory limit exceeded</p> <p>These inspectors return properly categorized errors that the state engine uses to set conditions (<code>AuthValid</code>, <code>ConfigValid</code>, etc.).</p>"},{"location":"contributing/release-process/","title":"Release Process","text":"<p>Overview of the AIM Engine release workflow.</p>"},{"location":"contributing/release-process/#versioning","title":"Versioning","text":"<p>AIM Engine follows semantic versioning. The version is derived from git tags:</p> <pre><code>git describe --tags --abbrev=0  # e.g., v0.8.5\n</code></pre>"},{"location":"contributing/release-process/#build-artifacts","title":"Build Artifacts","text":""},{"location":"contributing/release-process/#crds","title":"CRDs","text":"<p>Generate a consolidated CRDs file:</p> <pre><code>make crds\n# Output: dist/crds.yaml\n</code></pre>"},{"location":"contributing/release-process/#helm-chart","title":"Helm Chart","text":"<p>Generate the Helm chart from kustomize output:</p> <pre><code>make helm\n# Output: dist/chart/\n</code></pre> <p>Package for distribution:</p> <pre><code>make helm-package\n# Output: dist/aim-engine-&lt;version&gt;.tgz\n</code></pre>"},{"location":"contributing/release-process/#container-image","title":"Container Image","text":"<pre><code>make docker-build IMG=docker.io/amdenterpriseai/aim-engine:v0.8.5\nmake docker-push IMG=docker.io/amdenterpriseai/aim-engine:v0.8.5\n</code></pre>"},{"location":"contributing/release-process/#distribution","title":"Distribution","text":"<p>The <code>publish-main</code> branch contains pre-built release artifacts:</p> <ul> <li><code>crds.yaml</code> \u2014 Consolidated CRDs</li> <li><code>chart/</code> \u2014 Helm chart ready for <code>helm install</code></li> </ul>"},{"location":"contributing/release-process/#oci-registry","title":"OCI Registry","text":"<p>Push Helm charts to an OCI registry:</p> <pre><code>make helm-push-oci\n</code></pre>"},{"location":"contributing/release-process/#third-party-licenses","title":"Third-Party Licenses","text":"<p>Generate license information for all dependencies:</p> <pre><code>make generate-licenses\n# Output: third-party-licenses/\n</code></pre>"},{"location":"contributing/release-process/#documentation","title":"Documentation","text":"<p>Regenerate all documentation:</p> <pre><code>make generate-docs  # CRD API reference + Helm values reference\n</code></pre>"},{"location":"contributing/release-process/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup \u2014 Build from source</li> <li>Changelog \u2014 Release notes</li> </ul>"},{"location":"contributing/state-engine/","title":"State Engine Internals","text":"<p>How the automatic state engine works under the hood.</p>"},{"location":"contributing/state-engine/#overview","title":"Overview","text":"<p>The state engine runs after you've composed observations but before applying desired state. It analyzes component health, categorizes errors, manages conditions, and decides reconciliation behavior.</p> <p>Flow: <code>Fetch \u2192 Compose \u2192 **StateEngine** \u2192 Apply \u2192 Events \u2192 Status</code></p>"},{"location":"contributing/state-engine/#error-categorization","title":"Error Categorization","text":"<p>All errors are automatically categorized using <code>CategorizeError()</code>:</p>"},{"location":"contributing/state-engine/#infrastructure-errors","title":"Infrastructure Errors","text":"<p>Detection: Network timeouts, connection refused, DNS failures, 5xx responses, rate limiting</p> <p>Behavior: - Sets <code>DependenciesReachable=False</code> - Triggers requeue with exponential backoff - Applies 10-second grace period before degrading components - Component state: <code>Degraded</code> (after grace period)</p>"},{"location":"contributing/state-engine/#auth-errors","title":"Auth Errors","text":"<p>Detection: 401 Unauthorized, 403 Forbidden, auth-related log patterns (S3, HuggingFace)</p> <p>Behavior: - Sets <code>AuthValid=False</code> - Stops apply phase (user must fix) - Component state: <code>Failed</code> (requires spec/secret change)</p> <p>Log patterns detected: - S3: <code>access denied</code>, <code>InvalidAccessKeyId</code>, <code>NoCredentialProviders</code> - HuggingFace: <code>Access to model X is restricted</code>, <code>Cannot access gated repo</code>, <code>Invalid token</code></p>"},{"location":"contributing/state-engine/#invalidspec-errors","title":"InvalidSpec Errors","text":"<p>Detection: Invalid resource specs, conflicts, already exists, 4xx errors</p> <p>Behavior: - Sets <code>ConfigValid=False</code> - Stops apply phase (user must fix) - Component state: <code>Failed</code> (requires spec change)</p>"},{"location":"contributing/state-engine/#missingupstreamdependency-errors","title":"MissingUpstreamDependency Errors","text":"<p>Detection: User-referenced resources not found (runtimeConfig, secrets, configmaps)</p> <p>Behavior: - Sets <code>ConfigValid=False</code> - Stops apply phase (user must fix) - Component state: <code>Failed</code> (requires user to create the referenced resource)</p> <p>Distinction: These are resources the user referenced in their spec, not internal resources the controller creates.</p>"},{"location":"contributing/state-engine/#missingdownstreamdependency-errors","title":"MissingDownstreamDependency Errors","text":"<p>Detection: 404 NotFound for internal resources (pods, jobs, deployments being created)</p> <p>Behavior: - Marks component as <code>Progressing</code> (waiting state) - Does not fail the resource - Normal reconciliation continues - Component state: <code>Progressing</code> (will self-heal)</p> <p>Distinction: These are resources the controller is creating/managing - they're expected to be missing during initial reconciliation.</p>"},{"location":"contributing/state-engine/#resourceexhaustion-errors","title":"ResourceExhaustion Errors","text":"<p>Detection: OOM kills, disk full, quota exceeded, storage exhaustion log patterns</p> <p>Behavior: - Component state: <code>Failed</code> (requires resource limit/quota increase) - Does not set <code>ConfigValid=False</code> (it's a platform/capacity issue, not a config issue)</p> <p>Log patterns detected: - <code>no space left on device</code> - <code>disk full</code> - <code>quota exceeded</code> - Pod termination reason: <code>OOMKilled</code></p>"},{"location":"contributing/state-engine/#unknown-errors","title":"Unknown Errors","text":"<p>Behavior: Treated as infrastructure errors (requeue with backoff)</p>"},{"location":"contributing/state-engine/#pod-log-inspection","title":"Pod Log Inspection","text":"<p>The <code>GetPodsHealth</code> utility automatically inspects pod logs to categorize failures beyond what Kubernetes API provides:</p> <p>How it works: 1. Checks for image pull errors (auth, not found, backoff) 2. For failed pods, fetches the last 50 lines of logs from the failed container 3. Matches log patterns to categorize the failure type 4. Returns categorized error with log excerpt for debugging</p> <p>Pattern matching order (first match wins): 1. Resource not found (404, \"Repository Not Found\") - checked first because HuggingFace returns 401 for non-existent repos 2. Auth errors (credentials, tokens, access denied) 3. Storage exhaustion (disk full, quota exceeded)</p> <p>Example categorization: <pre><code>// Pod failed with exit code 1\n// Logs contain: \"Access to model Qwen/Qwen3-32B is restricted\"\n// \u2192 Categorized as Auth error\n// \u2192 Status shows: \"Container download failed with exit code 1: ...\\n\\nLog excerpt:\\nAccess to model Qwen/Qwen3-32B is restricted\"\n</code></pre></p> <p>This automatic inspection eliminates the need for manual log checking - the controller surfaces the root cause directly in the status.</p>"},{"location":"contributing/state-engine/#grace-period-logic","title":"Grace Period Logic","text":"<p>When infrastructure errors occur, components don't immediately degrade:</p> <ol> <li>First occurrence: <code>DependenciesReachable</code> set to <code>False</code>, component stays <code>Ready</code>/<code>Progressing</code></li> <li>0-10 seconds: Grace period - component maintains current state</li> <li>After 10 seconds: Component degrades to <code>Degraded</code></li> </ol> <p>This prevents status flapping from transient network issues.</p> <p>Implementation: Uses <code>LastTransitionTime</code> on the <code>DependenciesReachable</code> condition.</p>"},{"location":"contributing/state-engine/#condition-management","title":"Condition Management","text":""},{"location":"contributing/state-engine/#component-conditions","title":"Component Conditions","text":"<p>For each component in <code>GetComponentHealth()</code>, the engine creates a condition:</p> <ul> <li>Component name: <code>\"Model\"</code> \u2192 Condition: <code>\"ModelReady\"</code></li> <li>State mapping:</li> <li><code>Ready</code> \u2192 <code>ConditionTrue</code></li> <li><code>Progressing</code> \u2192 <code>ConditionUnknown</code></li> <li><code>Failed</code>/<code>Degraded</code>/<code>NotAvailable</code> \u2192 <code>ConditionFalse</code></li> </ul>"},{"location":"contributing/state-engine/#parent-conditions","title":"Parent Conditions","text":"<p>Three parent conditions are created only when relevant (lazy creation):</p> <p><code>AuthValid</code>: - Created when auth errors occur (set to <code>False</code>) - Transitions to <code>True</code> when errors clear - Never deleted once added</p> <p><code>ConfigValid</code>: - Created when spec validation errors occur (set to <code>False</code>) - Transitions to <code>True</code> when errors clear - Never deleted once added</p> <p><code>DependenciesReachable</code>: - Created when infrastructure errors occur (set to <code>False</code>) - Transitions to <code>True</code> when errors clear - Never deleted once added</p>"},{"location":"contributing/state-engine/#ready-condition","title":"Ready Condition","text":"<p>Always set. Aggregates all component states:</p> <ul> <li><code>True</code>: All components Ready, no auth/config/infra errors</li> <li><code>False</code>: Any component failed, or auth/config/infra errors present</li> </ul>"},{"location":"contributing/state-engine/#condition-lifecycle","title":"Condition Lifecycle","text":"<p>Conditions follow specific lifecycle rules for creation, transition, and deletion.</p>"},{"location":"contributing/state-engine/#creation","title":"Creation","text":"<p>Conditions are created at different times depending on their type:</p> <p>Always-present conditions:</p> Condition When Created <code>Ready</code> First reconcile (always exists) <code>{Component}Ready</code> First time component appears in <code>GetComponentHealth()</code> <p>Lazy-created conditions (only appear when relevant):</p> Condition When Created Why Lazy <code>AuthValid</code> First auth error Many controllers never have auth errors <code>ConfigValid</code> First spec validation error Most specs are valid <code>DependenciesReachable</code> First infrastructure error Usually infrastructure is healthy <p>This keeps the conditions list clean for happy-path resources. A resource that never encounters auth errors will never show <code>AuthValid</code> - reducing noise in <code>kubectl get</code> output.</p>"},{"location":"contributing/state-engine/#transitions","title":"Transitions","text":"<p>Conditions transition based on observed state. Only Status or Reason changes update <code>LastTransitionTime</code>. Message-only changes are informational and don't trigger a transition.</p> <p>Lazy condition lifecycle:</p> <pre><code>[not present] \u2192 Error occurs \u2192 False \u2192 Error clears \u2192 True (persists)\n</code></pre> <p>Once a lazy condition appears, it stays forever. After recovery, it shows <code>True</code> as an audit trail that the error occurred and was resolved. This is useful for debugging (\"this resource had auth issues at some point\").</p>"},{"location":"contributing/state-engine/#status-field","title":"Status Field","text":"<p>The <code>status.Status</code> field is set to the \"worst\" component state using priority ordering:</p> <p>Priority (worst to best): 1. <code>Failed</code> - Terminal errors requiring user intervention (auth, invalid spec, resource exhaustion) 2. <code>Degraded</code> - Recoverable issues (infrastructure errors after grace period, missing upstream dependencies) 3. <code>NotAvailable</code> - Resource exists but not available due to some reason 4. <code>Pending</code> - Waiting for scheduling/resources 5. <code>Progressing</code> - Actively working toward Ready (internal deps, jobs running) 6. <code>Ready/Running</code> - Fully operational</p> <p>State Derivation from Errors:</p> <p>When <code>ComponentHealth.State</code> is not explicitly set, the state is derived from errors:</p> <pre><code>// DeriveStateFromErrors rules:\n- No errors \u2192 Ready\n- Auth, InvalidSpec, ResourceExhaustion \u2192 Failed (requires user action)\n- MissingUpstreamDependency, Infrastructure \u2192 Degraded (may recover)\n- MissingDownstreamDependency \u2192 Progressing (will self-heal)\n</code></pre> <p>During grace period: Component state is preserved (doesn't degrade to <code>Degraded</code>) until 10 seconds have passed.</p>"},{"location":"contributing/state-engine/#reconciliation-decisions","title":"Reconciliation Decisions","text":"<p>The state engine returns a <code>StateEngineDecision</code>:</p> <pre><code>type StateEngineDecision struct {\n    ShouldApply   bool   // Skip apply phase?\n    ShouldRequeue bool   // Return error to requeue?\n    RequeueError  error  // Error for controller-runtime\n}\n</code></pre> <p>Decision logic:</p> <ul> <li><code>AuthValid=False</code> \u2192 <code>ShouldApply=false</code> (stop apply)</li> <li><code>ConfigValid=False</code> \u2192 <code>ShouldApply=false</code> (stop apply)</li> <li>Infrastructure errors \u2192 <code>ShouldRequeue=true</code> (exponential backoff)</li> </ul>"},{"location":"contributing/state-engine/#observability","title":"Observability","text":"<p>The state engine automatically configures event and log emission:</p>"},{"location":"contributing/state-engine/#for-component-conditions","title":"For Component Conditions","text":"<ul> <li><code>Ready</code>/<code>Progressing</code> states \u2192 <code>AsInfo()</code> (normal event, info log on transition)</li> <li><code>Failed</code>/<code>Degraded</code>/<code>NotAvailable</code> states \u2192 <code>AsError()</code> (warning event, error log recurring)</li> </ul>"},{"location":"contributing/state-engine/#for-parent-conditions","title":"For Parent Conditions","text":"<ul> <li><code>AuthValid=False</code> \u2192 <code>AsError()</code> (recurring)</li> <li><code>ConfigValid=False</code> \u2192 <code>AsError()</code> (recurring)</li> <li><code>DependenciesReachable=False</code> \u2192 <code>AsError()</code> (recurring)</li> <li>All <code>=True</code> transitions \u2192 <code>AsInfo()</code></li> </ul>"},{"location":"contributing/state-engine/#manual-override","title":"Manual Override","text":"<p>If you implement <code>ManualStatusController</code> (SetStatus), the state engine:</p> <ul> <li>\u2705 Still categorizes errors for requeue decisions</li> <li>\u2705 Still applies infrastructure error requeue logic</li> <li>\u274c Does NOT set any conditions or status fields (you control everything)</li> </ul>"},{"location":"contributing/testing/","title":"Testing","text":"<p>AIM Engine uses Go unit tests and Chainsaw for declarative e2e tests.</p>"},{"location":"contributing/testing/#unit-tests","title":"Unit Tests","text":"<pre><code>make test                           # All unit tests (excludes e2e)\ngo test ./internal/aimservice -v    # Specific package\ngo test ./internal/... -run TestFoo # Specific test\n</code></pre>"},{"location":"contributing/testing/#e2e-tests-chainsaw","title":"E2E Tests (Chainsaw)","text":"<p>Chainsaw tests are declarative YAML files in <code>tests/e2e/</code>. Each test directory contains a <code>chainsaw-test.yaml</code> that defines steps: apply resources, assert conditions, run scripts.</p>"},{"location":"contributing/testing/#running-tests","title":"Running Tests","text":"<pre><code># Ensure the operator is running and ready\nmake wait-ready\n\n# Run all tests for the current environment\nmake test-chainsaw\n\n# Run a specific test directory\nmake test-chainsaw CHAINSAW_TEST_DIR=tests/e2e/aimservice/frozen\n</code></pre>"},{"location":"contributing/testing/#environment-selectors","title":"Environment Selectors","text":"<p>Tests are filtered by environment. When <code>ENV=kind</code> (default), tests tagged with <code>requires=longhorn</code> or other infrastructure requirements are excluded automatically.</p>"},{"location":"contributing/testing/#test-reports","title":"Test Reports","text":"<p>JSON reports are written to <code>.tmp/chainsaw-reports/chainsaw-report.json</code>. Analyze failures:</p> <pre><code># List failed tests\njq -r '.tests[] | select(.steps[].operations[].failure) | .name' \\\n  .tmp/chainsaw-reports/chainsaw-report.json | sort -u\n\n# Get failure details\njq -r '.tests[] | select(.steps[].operations[].failure) |\n  {name, failures: [.steps[].operations[] | select(.failure) | .failure.error]}' \\\n  .tmp/chainsaw-reports/chainsaw-report.json\n</code></pre>"},{"location":"contributing/testing/#correlating-with-operator-logs","title":"Correlating with Operator Logs","text":"<p>Chainsaw creates unique namespaces like <code>chainsaw-&lt;adjective&gt;-&lt;noun&gt;</code> for each test. Extract the namespace from test failures and search operator logs:</p> <pre><code>LOG=$(ls -t .tmp/logs/air-*.log | head -1)\ngrep \"chainsaw-&lt;namespace&gt;\" \"$LOG\"\n</code></pre>"},{"location":"contributing/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"contributing/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/e2e/my-feature/\n  chainsaw-test.yaml    # Test definition\n  resource.yaml         # Resources to apply\n  assert.yaml           # Expected state assertions\n</code></pre>"},{"location":"contributing/testing/#example-test","title":"Example Test","text":"<pre><code>apiVersion: chainsaw.kyverno.io/v1alpha1\nkind: Test\nmetadata:\n  name: basic-service\nspec:\n  steps:\n    - try:\n        - apply:\n            file: service.yaml\n        - assert:\n            file: assert.yaml\n            timeout: 120s\n</code></pre>"},{"location":"contributing/testing/#debug-simulation","title":"Debug Simulation","text":"<p>For tests that involve model downloads, use simulation mode to avoid real network calls:</p> <pre><code>env:\n  - name: AIM_DEBUG_SIMULATE_HF_DOWNLOAD\n    value: \"true\"\n  - name: AIM_DEBUG_SIMULATE_HF_DURATION\n    value: \"2\"\n</code></pre>"},{"location":"contributing/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup \u2014 Local environment configuration</li> <li>Controller Patterns \u2014 Understanding the reconciliation framework</li> </ul>"},{"location":"getting-started/architecture/","title":"Architecture","text":"<p>AIM Engine is a Kubernetes operator that orchestrates the full lifecycle of AI inference workloads. It bridges the gap between model artifacts and production-ready inference endpoints by coordinating several Kubernetes-native components.</p>"},{"location":"getting-started/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph User[\"User Resources\"]\n        AIMService[\"AIMService\"]\n        AIMModel[\"AIMModel /&lt;br/&gt;AIMClusterModel\"]\n        ModelSource[\"AIMClusterModelSource\"]\n        RuntimeConfig[\"AIMRuntimeConfig /&lt;br/&gt;AIMClusterRuntimeConfig\"]\n    end\n\n    subgraph Operator[\"AIM Engine Operator\"]\n        direction TB\n        Reconciler[\"Reconciliation Engine\"]\n        Selection[\"Template Selection\"]\n        CacheCtrl[\"Cache Controller\"]\n        ModelCtrl[\"Model Controller\"]\n    end\n\n    subgraph Managed[\"Managed Resources\"]\n        Template[\"AIMServiceTemplate /&lt;br/&gt;AIMClusterServiceTemplate\"]\n        TemplateCache[\"AIMTemplateCache\"]\n        Artifact[\"AIMArtifact\"]\n        ISVC[\"KServe&lt;br/&gt;InferenceService\"]\n        HTTPRoute[\"Gateway API&lt;br/&gt;HTTPRoute\"]\n    end\n\n    subgraph Infra[\"Infrastructure\"]\n        KServe[\"KServe\"]\n        GatewayAPI[\"Gateway API\"]\n        PVC[\"Persistent Volumes\"]\n        GPU[\"AMD GPUs\"]\n    end\n\n    AIMService --&gt; Reconciler\n    AIMModel --&gt; ModelCtrl\n    ModelSource --&gt;|discovers| AIMModel\n    RuntimeConfig --&gt; Reconciler\n\n    Reconciler --&gt; Selection\n    Selection --&gt; Template\n    Reconciler --&gt; CacheCtrl\n    CacheCtrl --&gt; TemplateCache\n    TemplateCache --&gt; Artifact\n    Artifact --&gt; PVC\n\n    Reconciler --&gt; ISVC\n    Reconciler --&gt; HTTPRoute\n\n    ISVC --&gt; KServe\n    HTTPRoute --&gt; GatewayAPI\n    KServe --&gt; GPU</code></pre>"},{"location":"getting-started/architecture/#resource-relationships","title":"Resource Relationships","text":"<p>The diagram below shows how AIM resources relate to each other during a typical service deployment:</p> <pre><code>flowchart LR\n    subgraph input[\"Input\"]\n        Service[\"AIMService\"]\n    end\n\n    subgraph resolution[\"Resolution\"]\n        Model[\"AIMModel\"]\n        Template[\"AIMServiceTemplate\"]\n        RC[\"AIMRuntimeConfig\"]\n    end\n\n    subgraph output[\"Output\"]\n        ISVC[\"InferenceService\"]\n        Route[\"HTTPRoute\"]\n        Cache[\"AIMTemplateCache\"]\n    end\n\n    Service --&gt;|resolves| Model\n    Service --&gt;|selects| Template\n    Service --&gt;|reads| RC\n    Service --&gt;|creates| ISVC\n    Service --&gt;|creates| Route\n    Service --&gt;|triggers| Cache</code></pre>"},{"location":"getting-started/architecture/#component-overview","title":"Component Overview","text":"Component Purpose Scope AIMService Primary resource for deploying inference endpoints Namespace AIMModel / AIMClusterModel Maps model names to container images Namespace / Cluster AIMServiceTemplate / AIMClusterServiceTemplate Defines runtime profiles (GPU, precision, optimization) Namespace / Cluster AIMRuntimeConfig / AIMClusterRuntimeConfig Provides storage defaults, routing, and environment variables Namespace / Cluster AIMClusterModelSource Discovers models automatically from container registries Cluster AIMArtifact Manages model artifact downloads to persistent volumes Namespace"},{"location":"getting-started/architecture/#cluster-vs-namespace-scoping","title":"Cluster vs Namespace Scoping","text":"<p>Several CRDs have both a namespace-scoped and a cluster-scoped variant:</p> Namespace-Scoped Cluster-Scoped Purpose <code>AIMModel</code> <code>AIMClusterModel</code> Model definitions <code>AIMServiceTemplate</code> <code>AIMClusterServiceTemplate</code> Runtime profiles <code>AIMRuntimeConfig</code> <code>AIMClusterRuntimeConfig</code> Storage, routing, and environment defaults <p>Cluster-scoped resources are shared across all namespaces. A cluster admin creates them to provide platform-wide defaults: a model catalog, validated runtime profiles, and shared configuration.</p> <p>Namespace-scoped resources are visible only within their namespace. Teams create them for custom models, per-project overrides, or private configurations.</p>"},{"location":"getting-started/architecture/#resolution-order","title":"Resolution Order","text":"<p>When an AIMService needs a model, template, or config, AIM Engine resolves the reference in this order:</p> <ol> <li>Namespace \u2014 look for the resource in the service's namespace</li> <li>Cluster \u2014 if not found, fall back to the cluster-scoped variant</li> </ol> <p>Namespace always wins. This lets teams override any cluster default by creating a namespace resource with the same name.</p> <p>RuntimeConfig is special: if both namespace and cluster configs exist, they are merged rather than one replacing the other. Namespace values override cluster values for any fields that are set in both.</p> <p>The resolution scope (<code>Namespace</code>, <code>Cluster</code>, or <code>Merged</code>) is recorded in the AIMService status so you can see which scope was used:</p> <pre><code>kubectl get aimservice &lt;name&gt; -o jsonpath='{.status.resolvedModel.scope}'\n</code></pre>"},{"location":"getting-started/architecture/#reconciliation-flow","title":"Reconciliation Flow","text":"<p>When an <code>AIMService</code> is created or updated, the operator follows this pipeline:</p> <pre><code>flowchart LR\n    Fetch[\"Fetch&lt;br/&gt;&lt;small&gt;Gather all referenced&lt;br/&gt;resources&lt;/small&gt;\"]\n    Compose[\"Compose&lt;br/&gt;&lt;small&gt;Interpret state and&lt;br/&gt;check health&lt;/small&gt;\"]\n    Plan[\"Plan&lt;br/&gt;&lt;small&gt;Decide what to&lt;br/&gt;create or update&lt;/small&gt;\"]\n    Apply[\"Apply&lt;br/&gt;&lt;small&gt;Execute changes&lt;br/&gt;against the cluster&lt;/small&gt;\"]\n    Status[\"Status&lt;br/&gt;&lt;small&gt;Update conditions&lt;br/&gt;and health&lt;/small&gt;\"]\n\n    Fetch --&gt; Compose --&gt; Plan --&gt; Apply --&gt; Status</code></pre> <p>Each step is designed to be idempotent: the operator converges toward the desired state on every reconciliation loop, handling partial failures and eventual consistency gracefully.</p>"},{"location":"getting-started/architecture/#integration-points","title":"Integration Points","text":"<p>KServe provides the underlying model serving runtime. AIM Engine creates and manages <code>InferenceService</code> resources, translating its high-level configuration into KServe-native specs.</p> <p>Gateway API handles HTTP routing. When routing is enabled, AIM Engine creates <code>HTTPRoute</code> resources that expose inference endpoints through a configured Gateway.</p> <p>Persistent Volumes back the caching system. Model artifacts are downloaded once to shared PVCs and reused across service replicas and restarts.</p> <p>AMD GPUs are detected via node labels. The template selection algorithm filters candidates based on available GPU hardware in the cluster.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers installing AIM Engine on a Kubernetes cluster.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"Component Minimum Version Notes Kubernetes 1.28+ Cluster with AMD GPU nodes KServe v0.16.1 See KServe Configuration Gateway API v1.3.0 Required for HTTP routing cert-manager v1.16+ Required by KServe and optional metrics TLS <p>Optional components:</p> Component Version Purpose KEDA 2.18+ Autoscaling with OpenTelemetry metrics OpenTelemetry Operator 0.101+ Custom metrics collection for autoscaling Longhorn or similar CSI \u2014 ReadWriteMany storage for model caching"},{"location":"getting-started/installation/#install-with-helm","title":"Install with Helm","text":""},{"location":"getting-started/installation/#1-install-crds","title":"1. Install CRDs","text":"<p>CRDs are distributed separately from the Helm chart and must be installed first:</p> <pre><code>helm install aim-engine-crds oci://docker.io/amdenterpriseai/charts/aim-engine-crds \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --create-namespace\n</code></pre> <p>Or from a local file:</p> <pre><code>kubectl apply -f crds.yaml\nkubectl wait --for=condition=Established crd --all --timeout=60s\n</code></pre>"},{"location":"getting-started/installation/#2-install-the-operator","title":"2. Install the Operator","text":"<pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --create-namespace\n</code></pre> <p>See Helm Chart Values for all configurable values (replicas, resources, metrics, CRD management, etc.).</p>"},{"location":"getting-started/installation/#3-enable-model-discovery-recommended","title":"3. Enable Model Discovery (Recommended)","text":"<p>Automatically populate the model catalog from AMD's published AIM container images:</p> <pre><code>helm upgrade aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --namespace aim-system \\\n  --set clusterModelSource.enable=true\n</code></pre> <p>This creates an <code>AIMClusterModelSource</code> that discovers <code>amdenterpriseai/aim-*</code> images and registers them as <code>AIMClusterModel</code> resources. See Model Catalog for more details.</p>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>Build and install from the repository:</p> <pre><code>git clone https://github.com/amd-enterprise-ai/aim-engine.git\ncd aim-engine\n\n# Generate CRDs and Helm chart\nmake crds\nmake helm\n\n# Install CRDs\nkubectl apply -f dist/crds.yaml\nkubectl wait --for=condition=Established crd --all --timeout=60s\n\n# Install the operator\nhelm install aim-engine ./dist/chart \\\n  --namespace aim-system \\\n  --create-namespace\n</code></pre> <p>Tip</p> <p>This project uses mise to manage tool versions (Go, controller-gen, etc.). Run <code>mise install</code> and <code>eval \"$(mise activate bash)\"</code> to get the correct versions on your PATH. See Development Setup for details.</p>"},{"location":"getting-started/installation/#common-configuration","title":"Common Configuration","text":""},{"location":"getting-started/installation/#enable-cluster-runtime-defaults","title":"Enable Cluster Runtime Defaults","text":"<p>Set up cluster-wide routing and storage defaults:</p> <pre><code>helm upgrade aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --namespace aim-system \\\n  --set clusterRuntimeConfig.enable=true \\\n  --set clusterRuntimeConfig.spec.routing.enabled=true \\\n  --set clusterRuntimeConfig.spec.routing.gatewayRef.name=aim-gateway \\\n  --set clusterRuntimeConfig.spec.routing.gatewayRef.namespace=kgateway-system\n</code></pre> <p>See Helm Chart Values for all available options.</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Check that the operator is running:</p> <pre><code>kubectl get pods -n aim-system\n</code></pre> <p>Expected output:</p> <pre><code>NAME                                              READY   STATUS    RESTARTS   AGE\naim-engine-controller-manager-xxxxx-yyyyy         1/1     Running   0          30s\n</code></pre> <p>Verify CRDs are installed:</p> <pre><code>kubectl get crds | grep aim.eai.amd.com\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<pre><code># Remove the operator\nhelm uninstall aim-engine -n aim-system\n\n# Remove CRDs\nhelm uninstall aim-engine-crds -n aim-system\n</code></pre> <p>Warning</p> <p>Uninstalling the CRDs release deletes all AIM custom resources from the cluster. Remove the operator first, then the CRDs only if you want a full cleanup.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quickstart \u2014 Deploy your first inference service</li> <li>KServe Configuration \u2014 Configure KServe for AIM Engine</li> <li>Helm Chart Values \u2014 Full reference for all chart values</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Deploy your first inference service in minutes.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>AIM Engine installed on your cluster</li> <li>AMD GPUs available in the cluster</li> <li><code>kubectl</code> configured to access your cluster</li> </ul>"},{"location":"getting-started/quickstart/#step-1-check-available-models","title":"Step 1: Check Available Models","text":"<p>If you enabled model discovery during installation, models are already available:</p> <pre><code>kubectl get aimclustermodels\n</code></pre> <p>If no models are listed, create one manually:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: qwen3-32b\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <pre><code>kubectl apply -f model.yaml\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-deploy-an-inference-service","title":"Step 2: Deploy an Inference Service","text":"<p>Create an <code>AIMService</code> to deploy the model:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: default\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <pre><code>kubectl apply -f service.yaml\n</code></pre> <p>AIM Engine automatically:</p> <ol> <li>Resolves or creates a matching model</li> <li>Selects the best runtime template for your GPU hardware</li> <li>Downloads the model weights (this can take several minutes for large models)</li> <li>Creates a KServe InferenceService once the download completes</li> <li>Starts serving the model</li> </ol>"},{"location":"getting-started/quickstart/#caching","title":"Caching","text":"<p>Model weights are always downloaded to a persistent volume before the InferenceService starts. The caching mode controls whether that PVC is shared or isolated:</p> <ul> <li><code>Shared</code> (default) \u2014 The PVC is shared across all services using the same template. Once one service downloads the model, others reuse it immediately.</li> <li><code>Dedicated</code> \u2014 Each service gets its own PVC, isolated from other services.</li> </ul> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: default\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  caching:\n    mode: Dedicated\n</code></pre> <p>See Model Caching for more on caching modes and configuration.</p>"},{"location":"getting-started/quickstart/#step-3-monitor-progress","title":"Step 3: Monitor Progress","text":"<p>Watch the service status:</p> <pre><code>kubectl get aimservice qwen-chat -w\n</code></pre> <p>The status progresses through: <code>Pending</code> \u2192 <code>Starting</code> \u2192 <code>Running</code>. The service pauses in <code>Starting</code> while model weights are downloaded.</p> <p>For more detail, check the conditions:</p> <pre><code>kubectl get aimservice qwen-chat -o jsonpath='{.status.conditions}' | jq\n</code></pre>"},{"location":"getting-started/quickstart/#step-4-send-a-request","title":"Step 4: Send a Request","text":"<p>Once the service is <code>Running</code>, find the inference endpoint:</p> <pre><code>kubectl get inferenceservice -n default -l aim.eai.amd.com/service.name=qwen-chat\n</code></pre> <p>InferenceService names are derived, so use the name returned by the command above and port-forward its predictor service:</p> <pre><code>kubectl port-forward -n default svc/&lt;isvc-name&gt;-predictor 8080:80\n</code></pre> <pre><code>curl http://localhost:8080/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"qwen-chat\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n  }'\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Deploying Services \u2014 Scaling, caching, routing, and more configuration options</li> <li>Model Catalog \u2014 Browse and manage available models</li> <li>Architecture \u2014 Understand how AIM Engine components work together</li> </ul>"},{"location":"guides/deploying-services/","title":"Deploying Inference Services","text":"<p><code>AIMService</code> is the primary resource for deploying inference endpoints. It combines a model image, optional runtime configuration, and HTTP routing to produce a production-ready inference service.</p>"},{"location":"guides/deploying-services/#quick-start","title":"Quick Start","text":"<p>The minimal service requires just an AIM container image:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <p>This creates an inference service using the default runtime configuration and automatically selected profile.</p>"},{"location":"guides/deploying-services/#common-configuration","title":"Common Configuration","text":""},{"location":"guides/deploying-services/#scaling","title":"Scaling","text":"<p>Control the number of replicas:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  replicas: 3\n</code></pre>"},{"location":"guides/deploying-services/#autoscaling","title":"Autoscaling","text":"<p>AIMService supports automatic scaling based on custom metrics using KEDA (Kubernetes Event-driven Autoscaling). This enables your inference services to scale dynamically based on real-time demand.</p>"},{"location":"guides/deploying-services/#basic-autoscaling","title":"Basic Autoscaling","text":"<p>Enable autoscaling by specifying minimum and maximum replica counts:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  minReplicas: 1\n  maxReplicas: 5\n</code></pre> <p>This configures KEDA to manage scaling between 1 and 5 replicas. Without custom metrics, KEDA uses default scaling behavior.</p>"},{"location":"guides/deploying-services/#custom-metrics-with-opentelemetry","title":"Custom Metrics with OpenTelemetry","text":"<p>For precise control over scaling behavior, configure custom metrics from the inference runtime. vLLM exposes metrics via OpenTelemetry that can drive scaling decisions:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  minReplicas: 1\n  maxReplicas: 3\n  autoScaling:\n    metrics:\n      - type: PodMetric\n        podmetric:\n          metric:\n            backend: \"opentelemetry\"\n            metricNames:\n              - vllm:num_requests_running\n            query: \"vllm:num_requests_running\"\n            operationOverTime: \"avg\"\n          target:\n            type: Value\n            value: \"1\"\n</code></pre> <p>This configuration scales based on the average number of running requests across pods. When the average exceeds 1, KEDA scales up; when it drops below, KEDA scales down.</p>"},{"location":"guides/deploying-services/#metric-configuration-options","title":"Metric Configuration Options","text":"Field Description Default <code>backend</code> Metrics backend to use <code>opentelemetry</code> <code>serverAddress</code> Address of the metrics server <code>keda-otel-scaler.keda.svc:4317</code> <code>metricNames</code> List of metrics to collect from pods - <code>query</code> Query to retrieve metrics from the backend - <code>operationOverTime</code> Aggregation operation: <code>last_one</code>, <code>avg</code>, <code>max</code>, <code>min</code>, <code>rate</code>, <code>count</code> <code>last_one</code>"},{"location":"guides/deploying-services/#target-types","title":"Target Types","text":"Type Description Field <code>Value</code> Scale based on absolute metric value <code>value</code> <code>AverageValue</code> Scale based on average value across pods <code>averageValue</code> <code>Utilization</code> Scale based on percentage utilization (resource metrics only) <code>averageUtilization</code>"},{"location":"guides/deploying-services/#common-vllm-metrics","title":"Common vLLM Metrics","text":"<p>These metrics are commonly used for autoscaling vLLM-based inference services:</p> Metric Description Scaling Use Case <code>vllm:num_requests_running</code> Number of requests currently being processed Scale based on concurrent load <code>vllm:num_requests_waiting</code> Number of requests waiting in queue Scale based on queue depth"},{"location":"guides/deploying-services/#how-it-works","title":"How It Works","text":"<p>When autoscaling is configured, AIMService:</p> <ol> <li>Creates a KServe InferenceService with the <code>serving.kserve.io/autoscalerClass: keda</code> annotation</li> <li>KEDA creates a <code>ScaledObject</code> that monitors the specified metrics</li> <li>KEDA creates and manages an <code>HorizontalPodAutoscaler</code> (HPA) based on the ScaledObject</li> <li>The HPA scales the deployment between <code>minReplicas</code> and <code>maxReplicas</code> based on metric values</li> </ol>"},{"location":"guides/deploying-services/#monitoring-autoscaling","title":"Monitoring Autoscaling","text":"<p>First, get the derived KServe InferenceService name for the AIMService:</p> <pre><code>kubectl -n &lt;namespace&gt; get inferenceservice -l aim.eai.amd.com/service.name=&lt;service-name&gt;\n</code></pre> <p>KEDA resources are named from the InferenceService name (<code>&lt;isvc-name&gt;</code>), not the AIMService name:</p> <pre><code>kubectl -n &lt;namespace&gt; get scaledobject &lt;isvc-name&gt;-predictor -o yaml\nkubectl -n &lt;namespace&gt; get hpa keda-hpa-&lt;isvc-name&gt;-predictor\n</code></pre> <p>Watch scaling events in real-time:</p> <pre><code>kubectl -n &lt;namespace&gt; get hpa keda-hpa-&lt;isvc-name&gt;-predictor -w\n</code></pre> <p>View current metrics:</p> <pre><code>kubectl -n &lt;namespace&gt; describe hpa keda-hpa-&lt;isvc-name&gt;-predictor\n</code></pre>"},{"location":"guides/deploying-services/#prerequisites","title":"Prerequisites","text":"<p>Autoscaling requires:</p> <ul> <li>KEDA installed in the cluster</li> <li>KEDA OpenTelemetry Scaler (<code>keda-otel-scaler</code>) deployed if using OpenTelemetry metrics</li> <li>OpenTelemetry Collector configured to scrape metrics from inference pods</li> </ul>"},{"location":"guides/deploying-services/#resource-limits","title":"Resource Limits","text":"<p>Override default resource allocations:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n</code></pre>"},{"location":"guides/deploying-services/#runtime-configuration","title":"Runtime Configuration","text":"<p>Reference a specific runtime configuration for credentials and defaults:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  runtimeConfigName: team-config  # defaults to 'default' if omitted\n</code></pre> <p>Runtime configurations provide: - Routing defaults</p> <p>See Runtime Configuration for details.</p>"},{"location":"guides/deploying-services/#http-routing","title":"HTTP Routing","text":"<p>Enable external HTTP access through Gateway API:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n</code></pre>"},{"location":"guides/deploying-services/#custom-paths","title":"Custom Paths","text":"<p>Override the default path using templates:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/{.metadata.namespace}/chat/{.metadata.name}\"\n</code></pre> <p>Templates use JSONPath expressions wrapped in <code>{...}</code>: - <code>{.metadata.namespace}</code> - service namespace - <code>{.metadata.name}</code> - service name - <code>{.metadata.labels['team']}</code> - label value (label must exist)</p> <p>The final path is lowercased, URL-encoded, and limited to 200 characters.</p> <p>Note: If a label or field doesn't exist, the service will enter a degraded state. Ensure all referenced fields are present.</p>"},{"location":"guides/deploying-services/#authentication","title":"Authentication","text":"<p>For models requiring authentication (e.g., gated Hugging Face models):</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n</code></pre> <p>For private container registries:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  imagePullSecrets:\n    - name: registry-credentials\n</code></pre>"},{"location":"guides/deploying-services/#monitoring-service-status","title":"Monitoring Service Status","text":"<p>Check service readiness:</p> <pre><code>kubectl -n &lt;namespace&gt; get aimservice &lt;name&gt;\n</code></pre> <p>View detailed status:</p> <pre><code>kubectl -n &lt;namespace&gt; describe aimservice &lt;name&gt;\n</code></pre>"},{"location":"guides/deploying-services/#status-values","title":"Status Values","text":"<p>The <code>status</code> field shows the overall service state:</p> <ul> <li>Pending: Initial state, resolving model and template references</li> <li>Starting: Creating infrastructure (InferenceService, routing, caches)</li> <li>Running: Service is ready and serving traffic</li> <li>Degraded: Service is running but has warnings (e.g., routing issues, template not optimal)</li> <li>Failed: Service cannot start due to terminal errors</li> </ul>"},{"location":"guides/deploying-services/#status-fields","title":"Status Fields","text":"Field Description <code>status</code> Overall service status (Pending, Starting, Running, Degraded, Failed) <code>observedGeneration</code> Most recent generation observed by the controller <code>conditions</code> Detailed conditions tracking different aspects of service lifecycle <code>resolvedRuntimeConfig</code> Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>resolvedModel</code> Metadata about the model image that was resolved (name, namespace, scope, UID) <code>resolvedTemplate</code> Metadata about the template that was selected (name, namespace, scope, UID) <code>routing</code> Observed routing configuration including the rendered HTTP path"},{"location":"guides/deploying-services/#conditions","title":"Conditions","text":"<p>Services track detailed conditions to help diagnose issues:</p> <ul> <li>Framework conditions: <code>DependenciesReachable</code>, <code>AuthValid</code>, <code>ConfigValid</code>, <code>Ready</code></li> <li>Component conditions: <code>ModelReady</code>, <code>TemplateReady</code>, <code>RuntimeConfigReady</code>, <code>CacheReady</code>, <code>InferenceServiceReady</code>, <code>InferenceServicePodsReady</code>, <code>HTTPRouteReady</code>, <code>HPAReady</code></li> <li>Common reasons:</li> <li>Model/template resolution: <code>ModelNotFound</code>, <code>ModelNotReady</code>, <code>Resolved</code>, <code>TemplateNotFound</code>, <code>TemplateSelectionAmbiguous</code></li> <li>Runtime and cache lifecycle: <code>CreatingRuntime</code>, <code>RuntimeReady</code>, <code>CacheCreating</code>, <code>CacheReady</code>, <code>CacheFailed</code></li> <li>Routing and autoscaling: <code>PathTemplateInvalid</code>, <code>HTTPRouteAccepted</code>, <code>HTTPRoutePending</code>, <code>HPAOperational</code></li> </ul>"},{"location":"guides/deploying-services/#example-status","title":"Example Status","text":"<pre><code>$ kubectl -n ml-team get aimservice qwen-chat -o yaml\n</code></pre> <pre><code>status:\n  status: Running\n  observedGeneration: 1\n  conditions:\n    - type: ModelReady\n      status: \"True\"\n      reason: ModelResolved\n      message: \"AIMModel qwen-qwen3-32b is ready\"\n    - type: TemplateReady\n      status: \"True\"\n      reason: Resolved\n      message: \"AIMClusterServiceTemplate qwen3-32b-latency is ready\"\n    - type: CacheReady\n      status: \"True\"\n      reason: CacheReady\n      message: \"Template cache is ready\"\n    - type: InferenceServiceReady\n      status: \"True\"\n      reason: RuntimeReady\n      message: \"InferenceService is ready\"\n    - type: HTTPRouteReady\n      status: \"True\"\n      reason: HTTPRouteAccepted\n      message: \"HTTPRoute is accepted by gateway\"\n    - type: Ready\n      status: \"True\"\n      reason: AllComponentsReady\n      message: \"All components are ready\"\n  resolvedRuntimeConfig:\n    name: default\n    namespace: ml-team\n    scope: Namespace\n    kind: aim.eai.amd.com/v1alpha1/AIMRuntimeConfig\n  resolvedModel:\n    name: qwen-qwen3-32b\n    namespace: ml-team\n    scope: Namespace\n    kind: aim.eai.amd.com/v1alpha1/AIMModel\n  resolvedTemplate:\n    name: qwen3-32b-latency\n    scope: Cluster\n    kind: aim.eai.amd.com/v1alpha1/AIMClusterServiceTemplate\n  routing:\n    path: /ml-team/qwen-chat\n</code></pre>"},{"location":"guides/deploying-services/#complete-example","title":"Complete Example","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\n  labels:\n    team: research\nspec:\n  model:\n    name: qwen-qwen3-32b\n  template:\n    name: qwen3-32b-latency\n  runtimeConfigName: team-config\n  replicas: 2\n  resources:\n    limits:\n      cpu: \"6\"\n      memory: 48Gi\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/team/{.metadata.labels['team']}/chat\"\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n</code></pre>"},{"location":"guides/deploying-services/#model-caching","title":"Model Caching","text":"<p>Model caching is enabled by default in <code>Shared</code> mode, pre-downloading model artifacts so they are ready when the inference service starts. To use a dedicated cache owned by the service instead:</p> <pre><code>spec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  caching:\n    mode: Dedicated\n</code></pre> <p>How caching works:</p> <ol> <li>An <code>AIMTemplateCache</code> is created for the service's template, if it doesn't already exist</li> <li><code>AIMArtifact</code> resources download model artifacts to PVCs</li> <li>The service waits for caches to become available before starting</li> <li>Cached models are mounted directly into the inference container</li> </ol>"},{"location":"guides/deploying-services/#cache-preservation-on-deletion","title":"Cache Preservation on Deletion","text":"<p>Cache behavior on service deletion depends on the mode:</p> <ul> <li>Shared (default): Caches persist independently and can be reused by future services</li> <li>Dedicated: Caches are garbage-collected with the service</li> </ul> <p>See Model Caching for detailed information on cache lifecycle and management.</p>"},{"location":"guides/deploying-services/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/deploying-services/#service-stuck-in-pending","title":"Service stuck in Pending","text":"<p>Check if the runtime config exists: <pre><code>kubectl -n &lt;namespace&gt; get aimruntimeconfig\n</code></pre></p> <p>Check if templates are available: <pre><code>kubectl -n &lt;namespace&gt; get aimservicetemplate\nkubectl get aimclusterservicetemplate\n</code></pre></p>"},{"location":"guides/deploying-services/#routing-not-working","title":"Routing not working","text":"<p>Verify the HTTPRoute was created: <pre><code>kubectl -n &lt;namespace&gt; get httproute -l aim.eai.amd.com/service.name=&lt;service-name&gt;\n</code></pre></p> <p>Check for path template errors in status: <pre><code>kubectl -n &lt;namespace&gt; get aimservice &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"HTTPRouteReady\")]}'\n</code></pre></p>"},{"location":"guides/deploying-services/#model-not-found","title":"Model not found","text":"<p>Verify the model exists: <pre><code>kubectl -n &lt;namespace&gt; get aimmodel &lt;model-name&gt;\nkubectl get aimclustermodel &lt;model-name&gt;\n</code></pre></p> <p>If using <code>spec.model.image</code> directly, verify the image URI is accessible and the runtime config is properly configured for model creation.</p>"},{"location":"guides/deploying-services/#related-documentation","title":"Related Documentation","text":"<ul> <li>Runtime Configuration - Configure runtime settings and credentials</li> <li>Models - Understanding the model catalog</li> <li>Templates - Deep dive on templates and discovery</li> <li>Model Caching - Cache lifecycle and deletion behavior</li> </ul>"},{"location":"guides/model-caching/","title":"Model Caching","text":"<p>Model caching pre-downloads model artifacts to shared persistent volumes, reducing startup time and bandwidth usage across service replicas and restarts.</p>"},{"location":"guides/model-caching/#caching-modes","title":"Caching Modes","text":"<p>Control caching behavior with <code>spec.caching.mode</code>:</p> Mode Behavior <code>Shared</code> Reuses shared cache assets across services that use the same template. This is the default. <code>Dedicated</code> Creates service-owned dedicated cache assets, isolated from other services. <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  caching:\n    mode: Shared\n</code></pre> <p>Note</p> <p>The caching mode is immutable after creation. Legacy values <code>Always</code>, <code>Auto</code>, and <code>Never</code> are accepted for backward compatibility (<code>Always</code>/<code>Auto</code> map to <code>Shared</code>, <code>Never</code> maps to <code>Dedicated</code>).</p>"},{"location":"guides/model-caching/#how-caching-works","title":"How Caching Works","text":"<p>When caching is active, AIM Engine creates a hierarchy of resources:</p> <ol> <li>AIMTemplateCache \u2014 Groups all model artifacts for a specific template on a shared PVC</li> <li>AIMArtifact \u2014 Manages the download of individual model sources</li> <li>PVC + Download Job \u2014 The actual storage and download execution</li> </ol> <p>The template cache is owned by the template (not the service), so multiple services sharing the same template reuse the same cache.</p>"},{"location":"guides/model-caching/#download-protocols","title":"Download Protocols","text":"<p>For HuggingFace models (<code>hf://</code> sources), AIM Engine tries download protocols in sequence:</p> Protocol Description <code>XET</code> XetHub protocol (fastest for large models) <code>HF_TRANSFER</code> HuggingFace Transfer (optimized multi-part download) <code>HTTP</code> Standard HTTP download (slowest, most compatible) <p>The default order is <code>XET,HF_TRANSFER</code>. If a protocol fails, the downloader cleans up incomplete files and tries the next one.</p> <p>Override the protocol order via runtime configuration:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  env:\n    - name: AIM_DOWNLOADER_PROTOCOL\n      value: \"HF_TRANSFER,HTTP\"\n</code></pre>"},{"location":"guides/model-caching/#storage-sizing","title":"Storage Sizing","text":"<p>AIM Engine automatically sizes PVCs based on discovered model sizes plus a headroom percentage (default 10%). Configure the headroom via cluster runtime config:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  storage:\n    pvcHeadroomPercent: 15\n    defaultStorageClassName: longhorn\n</code></pre>"},{"location":"guides/model-caching/#monitoring-cache-status","title":"Monitoring Cache Status","text":"<p>Check the status of template caches and artifacts:</p> <pre><code># List template caches\nkubectl get aimtemplatecache -n &lt;namespace&gt;\n\n# List artifacts\nkubectl get aimartifact -n &lt;namespace&gt;\n\n# Check artifact download progress\nkubectl get aimartifact &lt;name&gt; -n &lt;namespace&gt; -o jsonpath='{.status}' | jq\n</code></pre>"},{"location":"guides/model-caching/#next-steps","title":"Next Steps","text":"<ul> <li>Model Caching Concepts \u2014 Cache hierarchy, ownership, and deletion behavior</li> <li>Storage Configuration \u2014 PVC and storage class setup</li> <li>Environment Variables \u2014 Downloader configuration</li> </ul>"},{"location":"guides/model-catalog/","title":"Model Catalog","text":"<p>AIM Engine maintains a catalog of available AI models as Kubernetes custom resources. This guide covers browsing, discovering, and managing models.</p>"},{"location":"guides/model-catalog/#browsing-models","title":"Browsing Models","text":"<p>List all available models:</p> <pre><code># Cluster-scoped models (available to all namespaces)\nkubectl get aimclustermodels\n\n# Namespace-scoped models\nkubectl get aimmodels -n &lt;namespace&gt;\n</code></pre> <p>View model details:</p> <pre><code>kubectl get aimclustermodel qwen3-32b -o yaml\n</code></pre> <p>Key fields to look for:</p> <ul> <li><code>spec.image</code> \u2014 The container image for this model</li> <li><code>status.status</code> \u2014 Current state (<code>Ready</code>, <code>Pending</code>, etc.)</li> <li><code>metadata.labels</code> \u2014 Model metadata (hardware, precision, etc.)</li> </ul>"},{"location":"guides/model-catalog/#automatic-model-discovery","title":"Automatic Model Discovery","text":"<p><code>AIMClusterModelSource</code> automatically discovers models from container registries and creates <code>AIMClusterModel</code> resources.</p>"},{"location":"guides/model-catalog/#setting-up-discovery","title":"Setting Up Discovery","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: amd-models\nspec:\n  registry: docker.io\n  filters:\n    - image: \"amdenterpriseai/aim-*\"\n      versions:\n        - \"&gt;=0.8.4\"\n  syncInterval: 1h\n  maxModels: 500\n</code></pre>"},{"location":"guides/model-catalog/#filtering-images","title":"Filtering Images","text":"<p>Use wildcards and version constraints to control which images are discovered:</p> <pre><code>spec:\n  filters:\n    - image: \"amdenterpriseai/aim-*\"\n      exclude:\n        - \"amdenterpriseai/aim-experimental\"\n      versions:\n        - \"&gt;=1.0.0\"\n        - \"&lt;2.0.0\"\n</code></pre> <p><code>exclude</code> values are exact repository matches (wildcards are not supported in <code>exclude</code>).</p>"},{"location":"guides/model-catalog/#private-registries","title":"Private Registries","text":"<p>Authenticate to private registries using image pull secrets:</p> <pre><code>spec:\n  registry: ghcr.io\n  imagePullSecrets:\n    - name: ghcr-pull-secret\n  filters:\n    - image: \"my-org/aim-*\"\n</code></pre> <p>The secret must exist in the operator namespace (typically <code>aim-system</code>).</p>"},{"location":"guides/model-catalog/#monitoring-sync-status","title":"Monitoring Sync Status","text":"<pre><code>kubectl get aimclustermodelsource amd-models -o jsonpath='{.status}' | jq\n</code></pre>"},{"location":"guides/model-catalog/#creating-models-manually","title":"Creating Models Manually","text":"<p>Create a namespace-scoped model:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMModel\nmetadata:\n  name: qwen3-32b\n  namespace: ml-team\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre> <p>Or a cluster-scoped model:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: qwen3-32b\nspec:\n  image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n</code></pre>"},{"location":"guides/model-catalog/#model-resolution","title":"Model Resolution","text":"<p>When an <code>AIMService</code> references a model by name, AIM Engine resolves it in this order:</p> <ol> <li>Namespace-scoped <code>AIMModel</code> with that name</li> <li>Cluster-scoped <code>AIMClusterModel</code> with that name</li> </ol> <p>Namespace-scoped resources take precedence, allowing teams to override cluster models.</p> <p>When using <code>model.image</code> instead of <code>model.name</code>, AIM Engine searches for any model matching that image URI. If none exists, it creates an <code>AIMModel</code> automatically.</p>"},{"location":"guides/model-catalog/#next-steps","title":"Next Steps","text":"<ul> <li>Deploying Services \u2014 Use models in inference services</li> <li>Model Sources \u2014 Deep dive into AIMClusterModelSource</li> <li>AIM Models \u2014 Full model lifecycle and discovery mechanics</li> </ul>"},{"location":"guides/multi-tenancy/","title":"Multi-Tenancy","text":"<p>AIM Engine supports multi-tenant deployments through a combination of cluster-scoped and namespace-scoped resources.</p>"},{"location":"guides/multi-tenancy/#resource-scoping","title":"Resource Scoping","text":"Resource Cluster-Scoped Namespace-Scoped Models <code>AIMClusterModel</code> <code>AIMModel</code> Templates <code>AIMClusterServiceTemplate</code> <code>AIMServiceTemplate</code> Runtime Config <code>AIMClusterRuntimeConfig</code> <code>AIMRuntimeConfig</code> Model Sources <code>AIMClusterModelSource</code> \u2014 Services \u2014 <code>AIMService</code> Artifacts \u2014 <code>AIMArtifact</code> <p>Namespace-scoped resources always take precedence over cluster-scoped ones during resolution.</p>"},{"location":"guides/multi-tenancy/#team-isolation","title":"Team Isolation","text":"<p>A typical multi-tenant setup:</p> <ol> <li>Cluster admin creates cluster-scoped resources shared by all teams:</li> <li><code>AIMClusterModelSource</code> for model discovery</li> <li><code>AIMClusterRuntimeConfig</code> for default routing, storage, and policies</li> <li> <p><code>AIMClusterServiceTemplate</code> for validated runtime profiles</p> </li> <li> <p>Teams work in their own namespaces with:</p> </li> <li><code>AIMService</code> resources for their inference endpoints</li> <li><code>AIMRuntimeConfig</code> for team-specific credentials and overrides</li> <li><code>AIMModel</code> for custom models only their team needs</li> </ol>"},{"location":"guides/multi-tenancy/#example-namespace-configuration","title":"Example: Namespace Configuration","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team-a\nspec:\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: team-a-hf-token\n          key: token\n  routing:\n    pathTemplate: \"/team-a/{.metadata.name}\"\n</code></pre>"},{"location":"guides/multi-tenancy/#override-hierarchy","title":"Override Hierarchy","text":"<p>Configuration is resolved with the most specific scope winning:</p> Setting Resolution Order Model <code>AIMModel</code> (namespace) \u2192 <code>AIMClusterModel</code> (cluster) Template <code>AIMServiceTemplate</code> (namespace) \u2192 <code>AIMClusterServiceTemplate</code> (cluster) Runtime config <code>AIMRuntimeConfig</code> (namespace) \u2192 <code>AIMClusterRuntimeConfig</code> (cluster) Environment vars Service \u2192 RuntimeConfig (namespace) \u2192 ClusterRuntimeConfig"},{"location":"guides/multi-tenancy/#label-propagation","title":"Label Propagation","text":"<p>AIM Engine can propagate labels from <code>AIMService</code> resources to managed child resources (InferenceService, HTTPRoute, PVCs). This is useful for cost tracking, team attribution, and policy enforcement.</p> <p>Enable via runtime configuration:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  labelPropagation:\n    enabled: true\n    match:\n      - \"aim.eai.amd.com/*\"\n      - \"team-*\"\n      - \"cost-center\"\n</code></pre> <p>Labels on the <code>AIMService</code> matching these patterns are automatically applied to all child resources. Labels matching <code>aim.eai.amd.com/*</code> are always propagated regardless of this setting.</p>"},{"location":"guides/multi-tenancy/#rbac","title":"RBAC","text":"<p>AIM Engine creates helper ClusterRoles for each CRD when <code>rbacHelpers.enable</code> is true (default):</p> Role Permissions <code>aimservice-admin</code> Full access to AIMService resources <code>aimservice-editor</code> Create, update, delete AIMService resources <code>aimservice-viewer</code> Read-only access to AIMService resources <p>Similar roles exist for all CRDs. Bind these to team groups or service accounts:</p> <pre><code>kubectl create rolebinding team-a-aimservice \\\n  --clusterrole=aimservice-editor \\\n  --group=team-a \\\n  --namespace=ml-team-a\n</code></pre>"},{"location":"guides/multi-tenancy/#next-steps","title":"Next Steps","text":"<ul> <li>Runtime Configuration \u2014 Configuration resolution details</li> <li>Security \u2014 RBAC and security configuration</li> <li>Private Registries \u2014 Per-team credential management</li> </ul>"},{"location":"guides/private-registries/","title":"Private Registries","text":"<p>This guide covers configuring authentication for private container registries, HuggingFace Hub, and S3-compatible storage.</p>"},{"location":"guides/private-registries/#container-image-pull-secrets","title":"Container Image Pull Secrets","text":""},{"location":"guides/private-registries/#per-service-secrets","title":"Per-Service Secrets","text":"<p>Provide image pull secrets directly on the service:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\nspec:\n  model:\n    image: my-registry.example.com/aim-qwen3:latest\n  imagePullSecrets:\n    - name: my-registry-creds\n</code></pre> <p>The secret must exist in the same namespace as the service.</p>"},{"location":"guides/private-registries/#model-source-secrets","title":"Model Source Secrets","text":"<p>For <code>AIMClusterModelSource</code> pulling from private registries, secrets must be in the operator namespace:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: private-models\nspec:\n  registry: ghcr.io\n  imagePullSecrets:\n    - name: ghcr-pull-secret\n  filters:\n    - image: \"my-org/aim-*\"\n</code></pre>"},{"location":"guides/private-registries/#huggingface-authentication","title":"HuggingFace Authentication","text":"<p>For models sourced from private HuggingFace repositories (<code>hf://</code> URLs), provide a token via environment variables in the runtime configuration:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: hf-credentials\n          key: token\n</code></pre> <p>Create the secret:</p> <pre><code>kubectl create secret generic hf-credentials \\\n  --from-literal=token=hf_your_token_here \\\n  -n ml-team\n</code></pre>"},{"location":"guides/private-registries/#s3-compatible-storage","title":"S3-Compatible Storage","text":"<p>For model artifacts stored in S3-compatible storage, configure credentials via environment variables:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  env:\n    - name: AWS_ACCESS_KEY_ID\n      valueFrom:\n        secretKeyRef:\n          name: s3-credentials\n          key: access-key\n    - name: AWS_SECRET_ACCESS_KEY\n      valueFrom:\n        secretKeyRef:\n          name: s3-credentials\n          key: secret-key\n    - name: AWS_ENDPOINT_URL\n      value: \"https://s3.example.com\"\n</code></pre>"},{"location":"guides/private-registries/#credential-scope","title":"Credential Scope","text":"<p>Environment variables from runtime configurations are merged in this order (highest to lowest priority):</p> <ol> <li><code>AIMService.spec.env</code> \u2014 per-service</li> <li><code>AIMRuntimeConfig.spec.env</code> \u2014 per-namespace</li> <li><code>AIMClusterRuntimeConfig.spec.env</code> \u2014 cluster-wide</li> </ol> <p>This allows you to set cluster-wide defaults (e.g., HuggingFace token) and override per namespace or service when needed.</p>"},{"location":"guides/private-registries/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/private-registries/#image-pull-errors","title":"Image Pull Errors","text":"<p>Check pod events for pull failures:</p> <pre><code>kubectl get pods -l serving.kserve.io/inferenceservice=&lt;service-name&gt; -n &lt;namespace&gt;\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre> <p>Common causes:</p> <ul> <li>Secret doesn't exist in the correct namespace</li> <li>Secret has incorrect credentials</li> <li>Registry URL is wrong in the model image</li> </ul>"},{"location":"guides/private-registries/#download-authentication-failures","title":"Download Authentication Failures","text":"<p>Check artifact download job logs:</p> <pre><code>kubectl get jobs -l aim.eai.amd.com/artifact=&lt;artifact-name&gt; -n &lt;namespace&gt;\nkubectl logs job/&lt;job-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"guides/private-registries/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Tenancy \u2014 Per-namespace credential isolation</li> <li>Runtime Configuration \u2014 Environment variable resolution</li> </ul>"},{"location":"guides/routing-and-ingress/","title":"Routing and Ingress","text":"<p>AIM Engine uses the Kubernetes Gateway API to expose inference services via HTTP. When routing is enabled, AIM Engine creates <code>HTTPRoute</code> resources that route traffic through a configured Gateway to the KServe predictor service.</p>"},{"location":"guides/routing-and-ingress/#enabling-routing","title":"Enabling Routing","text":""},{"location":"guides/routing-and-ingress/#per-service-routing","title":"Per-Service Routing","text":"<p>Enable routing on an individual service:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\n  namespace: ml-team\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: kgateway-system\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.name}\"\n</code></pre> <p>This creates an HTTPRoute matching the path <code>/ml-team/qwen-chat</code> and forwarding to the predictor service.</p>"},{"location":"guides/routing-and-ingress/#cluster-wide-routing-defaults","title":"Cluster-Wide Routing Defaults","text":"<p>Set routing defaults for all services via runtime configuration:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  routing:\n    enabled: true\n    gatewayRef:\n      group: gateway.networking.k8s.io\n      kind: Gateway\n      name: inference-gateway\n      namespace: kgateway-system\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.name}\"\n</code></pre> <p>With cluster defaults in place, services inherit routing configuration automatically. A service can override any field by specifying its own <code>spec.routing</code>.</p>"},{"location":"guides/routing-and-ingress/#path-templates","title":"Path Templates","text":"<p>Path templates use JSONPath expressions in <code>{...}</code> to build route paths from service metadata:</p> Template Example Result <code>/{.metadata.namespace}/{.metadata.name}</code> <code>/ml-team/qwen-chat</code> <code>/models/{.metadata.name}</code> <code>/models/qwen-chat</code> <code>/{.metadata.namespace}/{.metadata.labels['team']}/inference</code> <code>/ml-team/nlp/inference</code> <p>Path templates have a maximum length of 200 characters. If no template is specified, the default path is <code>/{namespace}/{uid}</code>.</p>"},{"location":"guides/routing-and-ingress/#request-timeout","title":"Request Timeout","text":"<p>Set an HTTP request timeout for the route:</p> <pre><code>spec:\n  routing:\n    requestTimeout: 120s\n</code></pre>"},{"location":"guides/routing-and-ingress/#annotations","title":"Annotations","text":"<p>Add annotations to the generated HTTPRoute:</p> <pre><code>spec:\n  routing:\n    annotations:\n      example.com/rate-limit: \"100\"\n</code></pre> <p>Annotations from the runtime config are merged with service-level annotations, with service-level values taking precedence.</p>"},{"location":"guides/routing-and-ingress/#routing-precedence","title":"Routing Precedence","text":"<p>Configuration is resolved in this order (highest to lowest priority):</p> <ol> <li><code>AIMService.spec.routing</code> \u2014 service-level overrides</li> <li><code>AIMRuntimeConfig.spec.routing</code> \u2014 namespace defaults</li> <li><code>AIMClusterRuntimeConfig.spec.routing</code> \u2014 cluster defaults</li> </ol>"},{"location":"guides/routing-and-ingress/#how-it-works","title":"How It Works","text":"<p>AIM Engine creates an HTTPRoute with:</p> <ul> <li>Parent: The gateway from <code>gatewayRef</code></li> <li>Path match: <code>PathPrefix</code> with the resolved path template</li> <li>Backend: KServe predictor service (<code>{isvc-name}-predictor</code>, where <code>isvc-name</code> is the derived InferenceService name) on port 80</li> <li>URL rewrite: The matched prefix is rewritten to <code>/</code> so backends receive clean paths like <code>/v1/chat/completions</code></li> </ul>"},{"location":"guides/routing-and-ingress/#next-steps","title":"Next Steps","text":"<ul> <li>Deploying Services \u2014 Full service configuration</li> <li>Runtime Configuration \u2014 Routing defaults and resolution</li> </ul>"},{"location":"guides/scaling-and-autoscaling/","title":"Scaling and Autoscaling","text":"<p>AIM Engine supports static replica scaling and KEDA-based autoscaling with OpenTelemetry metrics.</p>"},{"location":"guides/scaling-and-autoscaling/#static-scaling","title":"Static Scaling","text":"<p>Set a fixed number of replicas:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  replicas: 3\n</code></pre>"},{"location":"guides/scaling-and-autoscaling/#autoscaling-with-keda","title":"Autoscaling with KEDA","text":"<p>For demand-based scaling, use <code>minReplicas</code> and <code>maxReplicas</code> instead of <code>replicas</code>. AIM Engine configures KServe to use KEDA as the autoscaler.</p>"},{"location":"guides/scaling-and-autoscaling/#prerequisites","title":"Prerequisites","text":"<p>Install KEDA and the OpenTelemetry integration:</p> <ul> <li>KEDA v2.18+</li> <li>OpenTelemetry Operator</li> <li>KEDA OpenTelemetry scaler (<code>keda-otel-scaler</code>)</li> </ul>"},{"location":"guides/scaling-and-autoscaling/#basic-autoscaling","title":"Basic Autoscaling","text":"<pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  minReplicas: 1\n  maxReplicas: 4\n</code></pre> <p>AIM Engine automatically:</p> <ol> <li>Sets the KServe autoscaler class to <code>keda</code></li> <li>Injects an OpenTelemetry sidecar for metrics collection</li> <li>KEDA creates an HPA (<code>keda-hpa-{isvc-name}-predictor</code>, based on the derived InferenceService name)</li> </ol>"},{"location":"guides/scaling-and-autoscaling/#custom-metrics","title":"Custom Metrics","text":"<p>Override the default scaling behavior with custom metrics:</p> <pre><code>apiVersion: aim.eai.amd.com/v1alpha1\nkind: AIMService\nmetadata:\n  name: qwen-chat\nspec:\n  model:\n    image: amdenterpriseai/aim-qwen-qwen3-32b:0.8.5\n  minReplicas: 1\n  maxReplicas: 8\n  autoScaling:\n    metrics:\n      - type: PodMetric\n        podmetric:\n          metric:\n            backend: opentelemetry\n            metricNames:\n              - vllm:num_requests_running\n            query: \"vllm:num_requests_running\"\n            operationOverTime: \"avg\"\n          target:\n            type: Value\n            value: \"1\"\n</code></pre>"},{"location":"guides/scaling-and-autoscaling/#available-metrics","title":"Available Metrics","text":"<p>Common vLLM metrics for scaling decisions:</p> Metric Description Use Case <code>vllm:num_requests_running</code> Currently processing requests Scale on active load <code>vllm:num_requests_waiting</code> Queued requests Scale on queue depth"},{"location":"guides/scaling-and-autoscaling/#metric-configuration","title":"Metric Configuration","text":"Field Description <code>backend</code> Metrics backend (<code>opentelemetry</code>) <code>serverAddress</code> KEDA OTel scaler address (default: <code>keda-otel-scaler.keda.svc:4317</code>) <code>metricNames</code> Metric names to query <code>query</code> Query expression <code>operationOverTime</code> Aggregation: <code>last_one</code>, <code>avg</code>, <code>max</code>, <code>min</code>, <code>rate</code>, <code>count</code>"},{"location":"guides/scaling-and-autoscaling/#target-types","title":"Target Types","text":"Type Field Description <code>Value</code> <code>value</code> Scale when metric exceeds this absolute value <code>AverageValue</code> <code>averageValue</code> Scale when per-pod average exceeds this value <code>Utilization</code> <code>averageUtilization</code> Scale on percentage utilization"},{"location":"guides/scaling-and-autoscaling/#monitoring-scaling","title":"Monitoring Scaling","text":"<p>Check the current scaling state:</p> <pre><code># AIMService status\nkubectl get aimservice qwen-chat -o jsonpath='{.status.runtime}' | jq\n\n# KEDA HPA status\nkubectl get hpa -n &lt;namespace&gt; -l aim.eai.amd.com/service.name=qwen-chat\n</code></pre>"},{"location":"guides/scaling-and-autoscaling/#next-steps","title":"Next Steps","text":"<ul> <li>Deploying Services \u2014 Full service configuration reference</li> <li>Monitoring \u2014 Metrics and observability</li> </ul>"},{"location":"reference/cli/","title":"CLI and Operator Flags","text":"<p>The AIM Engine operator binary accepts the following command-line flags.</p>"},{"location":"reference/cli/#controller-flags","title":"Controller Flags","text":"Flag Type Default Description <code>--metrics-bind-address</code> string <code>\"0\"</code> Address for the metrics endpoint. Use <code>:8443</code> for HTTPS via cert-manager, <code>:8080</code> for HTTP, or <code>0</code> to disable. <code>--health-probe-bind-address</code> string <code>:8081</code> Address for the health probe endpoint. <code>--leader-elect</code> bool <code>false</code> Enable leader election for high availability. Uses lease ID <code>3be10d2f.eai.amd.com</code>. <code>--metrics-secure</code> bool <code>true</code> Serve metrics over HTTPS. Set to <code>false</code> for HTTP. <code>--enable-http2</code> bool <code>false</code> Enable HTTP/2 for metrics and webhook servers. Disabled by default due to CVE-2023-44487."},{"location":"reference/cli/#tls-certificate-flags","title":"TLS Certificate Flags","text":"Flag Type Default Description <code>--webhook-cert-path</code> string <code>\"\"</code> Directory containing webhook server TLS certificate. <code>--webhook-cert-name</code> string <code>tls.crt</code> Webhook certificate file name. <code>--webhook-cert-key</code> string <code>tls.key</code> Webhook private key file name. <code>--metrics-cert-path</code> string <code>\"\"</code> Directory containing metrics server TLS certificate. <code>--metrics-cert-name</code> string <code>tls.crt</code> Metrics certificate file name. <code>--metrics-cert-key</code> string <code>tls.key</code> Metrics private key file name."},{"location":"reference/cli/#logging-flags-zap","title":"Logging Flags (Zap)","text":"<p>The operator uses controller-runtime's Zap logging integration.</p> Flag Type Default Description <code>--zap-devel</code> bool <code>false</code> Enable development mode (human-readable, debug level). <code>--zap-encoder</code> string <code>json</code> Log encoding format: <code>json</code> or <code>console</code>. <code>--zap-log-level</code> string <code>info</code> Log level: <code>debug</code>, <code>info</code>, <code>error</code>, or an integer. <code>--zap-stacktrace-level</code> string <code>dpanic</code> Minimum level for stack traces: <code>info</code>, <code>error</code>, or <code>dpanic</code>."},{"location":"reference/cli/#health-endpoints","title":"Health Endpoints","text":"Path Port Description <code>/healthz</code> 8081 Liveness probe \u2014 returns 200 if the process is alive <code>/readyz</code> 8081 Readiness probe \u2014 returns 200 if the operator is ready to reconcile"},{"location":"reference/cli/#configuring-via-helm","title":"Configuring via Helm","text":"<p>Override flags in the Helm chart using <code>manager.args</code>:</p> <pre><code>manager:\n  args:\n    - --leader-elect\n    - --zap-log-level=debug\n    - --metrics-secure=false\n</code></pre> <p>Or via command line:</p> <pre><code>helm install aim-engine oci://docker.io/amdenterpriseai/charts/aim-engine \\\n  --version &lt;version&gt; \\\n  --set 'manager.args={--leader-elect,--zap-log-level=debug}'\n</code></pre>"},{"location":"reference/cli/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring \u2014 Metrics and log analysis</li> <li>Helm Chart Values \u2014 Full chart configuration</li> </ul>"},{"location":"reference/conditions/","title":"Conditions Reference","text":"<p>Every AIM resource reports its state through standard Kubernetes conditions. This page catalogs all conditions, their reasons, and what triggers them.</p>"},{"location":"reference/conditions/#reading-conditions","title":"Reading Conditions","text":"<pre><code>kubectl get aimservice &lt;name&gt; -o jsonpath='{.status.conditions}' | jq\n</code></pre> <p>Each condition has:</p> <ul> <li>type \u2014 The condition name (e.g., <code>Ready</code>)</li> <li>status \u2014 <code>True</code>, <code>False</code>, or <code>Unknown</code></li> <li>reason \u2014 Machine-readable cause</li> <li>message \u2014 Human-readable description</li> <li>lastTransitionTime \u2014 When the status last changed</li> </ul>"},{"location":"reference/conditions/#framework-conditions","title":"Framework Conditions","text":"<p>These conditions are managed by the reconciliation framework and appear on all AIM resources.</p>"},{"location":"reference/conditions/#dependenciesreachable","title":"DependenciesReachable","text":"<p>Whether upstream dependencies (referenced models, templates, configs) can be fetched.</p> Status Reason Description <code>True</code> <code>Reachable</code> All dependencies are reachable <code>False</code> <code>InfrastructureError</code> Cannot reach one or more dependencies"},{"location":"reference/conditions/#authvalid","title":"AuthValid","text":"<p>Whether authentication and authorization for referenced secrets and registries are valid.</p> Status Reason Description <code>True</code> <code>AuthenticationValid</code> Authentication and authorization successful <code>False</code> <code>AuthError</code> Authentication or authorization failure"},{"location":"reference/conditions/#configvalid","title":"ConfigValid","text":"<p>Whether the resource's spec is valid and all referenced resources exist.</p> Status Reason Description <code>True</code> <code>ConfigurationValid</code> Configuration is valid <code>False</code> <code>InvalidSpec</code> Configuration validation failed <code>False</code> <code>ReferenceNotFound</code> A referenced resource does not exist"},{"location":"reference/conditions/#ready","title":"Ready","text":"<p>Overall readiness \u2014 the aggregate of all other conditions and component health.</p> Status Reason Description <code>True</code> <code>AllComponentsReady</code> All components are ready <code>False</code> <code>ComponentsNotReady</code> One or more components are not ready <code>False</code> <code>Progressing</code> Waiting for components to become ready"},{"location":"reference/conditions/#aimservice-conditions","title":"AIMService Conditions","text":"<p>In addition to the framework conditions, AIMService reports component-specific conditions.</p>"},{"location":"reference/conditions/#modelready","title":"ModelReady","text":"Status Reason Description <code>True</code> <code>ModelResolved</code> Model found and ready <code>False</code> <code>ModelNotFound</code> Referenced model does not exist <code>False</code> <code>ModelNotReady</code> Model exists but is not ready <code>False</code> <code>CreatingModel</code> Auto-creating a model from image"},{"location":"reference/conditions/#templateready","title":"TemplateReady","text":"Status Reason Description <code>True</code> <code>Resolved</code> Template found and ready <code>False</code> <code>TemplateNotFound</code> No matching template found <code>False</code> <code>TemplateNotReady</code> Template exists but is not ready <code>False</code> <code>TemplateSelectionAmbiguous</code> Multiple templates scored equally"},{"location":"reference/conditions/#runtimeconfigready","title":"RuntimeConfigReady","text":"Status Reason Description <code>True</code> <code>RuntimeConfigResolved</code> Runtime config found <code>False</code> <code>ReferenceNotFound</code> Referenced runtime config does not exist"},{"location":"reference/conditions/#cacheready","title":"CacheReady","text":"Status Reason Description <code>True</code> <code>CacheReady</code> Model cache is populated <code>False</code> <code>CacheNotReady</code> Cache exists but download is incomplete <code>False</code> <code>CacheFailed</code> Cache download failed <code>False</code> <code>CacheLost</code> Previously-ready cache is no longer available <code>False</code> <code>CacheCreating</code> Creating template cache"},{"location":"reference/conditions/#inferenceserviceready","title":"InferenceServiceReady","text":"Status Reason Description <code>True</code> <code>RuntimeReady</code> KServe InferenceService is serving <code>False</code> <code>CreatingRuntime</code> Creating or updating InferenceService"},{"location":"reference/conditions/#inferenceservicepodsready","title":"InferenceServicePodsReady","text":"<p>Tracks whether the predictor pods are running and ready.</p>"},{"location":"reference/conditions/#httprouteready","title":"HTTPRouteReady","text":"Status Reason Description <code>True</code> <code>HTTPRouteAccepted</code> HTTPRoute accepted by the Gateway <code>False</code> <code>HTTPRoutePending</code> HTTPRoute exists but is still pending acceptance <code>False</code> <code>PathTemplateInvalid</code> Path template failed to resolve <code>False</code> <code>GatewayNotConfigured</code> Routing enabled but no <code>gatewayRef</code> configured"},{"location":"reference/conditions/#hpaready","title":"HPAReady","text":"Status Reason Description <code>True</code> <code>HPAOperational</code> HPA is active and metrics are available <code>False</code> <code>HPANotFound</code> Waiting for KEDA to create HPA <code>False</code> <code>WaitingForMetrics</code> InferenceService not ready yet; metrics unavailable"},{"location":"reference/conditions/#aimmodel-aimclustermodel-conditions","title":"AIMModel / AIMClusterModel Conditions","text":""},{"location":"reference/conditions/#ready_1","title":"Ready","text":"Status Reason Description <code>True</code> <code>AllTemplatesReady</code> All discovered templates are ready <code>True</code> <code>SomeTemplatesReady</code> At least one template is ready <code>True</code> <code>NoTemplatesExpected</code> Model has no templates (by design) <code>False</code> <code>SomeTemplatesDegraded</code> Some templates are degraded <code>False</code> <code>TemplatesProgressing</code> Templates are still being discovered <code>False</code> <code>AllTemplatesFailed</code> All templates failed <code>False</code> <code>NoTemplatesAvailable</code> No templates available for this model <code>False</code> <code>AwaitingMetadata</code> Waiting for model metadata extraction <code>False</code> <code>CreatingTemplates</code> Creating service templates <code>False</code> <code>MetadataExtractionFailed</code> Failed to extract model metadata"},{"location":"reference/conditions/#aimservicetemplate-aimclusterservicetemplate-conditions","title":"AIMServiceTemplate / AIMClusterServiceTemplate Conditions","text":""},{"location":"reference/conditions/#discovered","title":"Discovered","text":"Status Reason Description <code>True</code> <code>DiscoveryComplete</code> Profiles successfully discovered <code>True</code> <code>InlineModelSources</code> Template has inline model sources (no discovery needed) <code>False</code> <code>AwaitingDiscovery</code> Discovery job not yet complete <code>False</code> <code>DiscoveryFailed</code> Discovery job failed"},{"location":"reference/conditions/#cacheready_1","title":"CacheReady","text":"Status Reason Description <code>True</code> <code>AllCachesReady</code> All template caches are ready <code>False</code> <code>CreatingCaches</code> Creating caches <code>False</code> <code>CachesNotReady</code> Some caches are not ready <code>False</code> <code>NoCaches</code> No caches exist"},{"location":"reference/conditions/#modelfound","title":"ModelFound","text":"<p>Whether the referenced model exists and is accessible.</p>"},{"location":"reference/conditions/#aimtemplatecache-conditions","title":"AIMTemplateCache Conditions","text":""},{"location":"reference/conditions/#templatefound","title":"TemplateFound","text":"<p>Whether the parent template exists and is accessible.</p>"},{"location":"reference/conditions/#artifactsready","title":"ArtifactsReady","text":"Status Reason Description <code>True</code> <code>AllCachesReady</code> All artifacts downloaded <code>False</code> <code>CreatingCaches</code> Creating artifact resources <code>False</code> <code>CachesNotReady</code> Some artifacts not ready"},{"location":"reference/conditions/#aimartifact-conditions","title":"AIMArtifact Conditions","text":""},{"location":"reference/conditions/#ready_2","title":"Ready","text":"Status Reason Description <code>True</code> <code>Verified</code> Download complete and verified <code>False</code> <code>Downloading</code> Download in progress <code>False</code> <code>Verifying</code> Verifying downloaded data"},{"location":"reference/conditions/#condition-polarity","title":"Condition Polarity","text":"<p>All conditions follow positive polarity \u2014 <code>status: True</code> means healthy. When building dashboards or alerting:</p> <ul> <li>Green: condition <code>status: True</code></li> <li>Yellow: condition <code>status: False</code> with reason containing <code>Progressing</code>, <code>Creating</code>, <code>Awaiting</code></li> <li>Red: condition <code>status: False</code> with reason containing <code>Failed</code>, <code>Error</code>, <code>NotFound</code>, <code>Invalid</code></li> </ul>"},{"location":"reference/environment-variables/","title":"Environment Variables","text":"<p>Environment variables used by the AIM Engine operator and artifact downloader.</p>"},{"location":"reference/environment-variables/#operator-environment-variables","title":"Operator Environment Variables","text":"Variable Description <code>AIM_SYSTEM_NAMESPACE</code> Namespace where the operator is deployed. Set automatically by the deployment. <code>POD_NAME</code> Operator pod name. Used for discovery lock identity."},{"location":"reference/environment-variables/#artifact-downloader-variables","title":"Artifact Downloader Variables","text":"<p>These are set automatically by the operator on download jobs.</p>"},{"location":"reference/environment-variables/#download-configuration","title":"Download Configuration","text":"Variable Default Description <code>AIM_DOWNLOADER_PROTOCOL</code> <code>XET,HF_TRANSFER</code> Comma-separated protocol sequence for HuggingFace downloads. Tried in order; falls back on failure. <code>MOUNT_PATH</code> <code>/cache</code> PVC mount path in the download container. <code>TARGET_DIR</code> <code>/cache</code> Download target directory. <code>EXPECTED_SIZE_BYTES</code> (computed) Expected model size in bytes. <code>ARTIFACT_NAME</code> (from resource) Name of the AIMArtifact resource. <code>ARTIFACT_NAMESPACE</code> (from resource) Namespace of the AIMArtifact resource. <code>STALL_TIMEOUT</code> <code>120</code> Seconds to wait before considering a download stalled. <code>TMPDIR</code> <code>/tmp/</code> Temporary directory for downloads. <code>HF_HOME</code> <code>/tmp/.hf</code> HuggingFace cache directory."},{"location":"reference/environment-variables/#download-protocols","title":"Download Protocols","text":"<p>The <code>AIM_DOWNLOADER_PROTOCOL</code> variable accepts a comma-separated list of:</p> Protocol Description <code>XET</code> XetHub protocol \u2014 fastest for large models <code>HF_TRANSFER</code> HuggingFace Transfer \u2014 optimized multi-part download <code>HTTP</code> Standard HTTP \u2014 slowest but most compatible <p>The downloader tries each protocol in order. On failure, it cleans up <code>.incomplete</code> files and moves to the next protocol.</p>"},{"location":"reference/environment-variables/#debug-and-simulation-variables","title":"Debug and Simulation Variables","text":"<p>These are for testing only and should not be used in production.</p> Variable Description <code>AIM_DEBUG_SIMULATE_HF_DOWNLOAD</code> Enable HuggingFace download simulation mode. <code>AIM_DEBUG_SIMULATE_HF_FAIL_PROTOCOLS</code> Comma-separated protocols to simulate failure (e.g., <code>XET,HF_TRANSFER</code>). <code>AIM_DEBUG_SIMULATE_HF_DURATION</code> Sleep duration per simulated attempt (default: <code>2</code> seconds). <code>AIM_DEBUG_SIMULATE_DOWNLOAD</code> Simulate general download phases. <code>AIM_DEBUG_DOWNLOAD_DURATION</code> Simulated download duration (default: <code>10</code> seconds). <code>AIM_DEBUG_VERIFY_DURATION</code> Simulated verify duration (default: <code>10</code> seconds). <code>AIM_DEBUG_VERIFY_FAIL</code> Simulate verification failure. <code>AIM_DEBUG_CAUSE_HANG</code> Cause the downloader to hang (testing finalizer behavior). <code>AIM_DEBUG_CAUSE_FAILURE</code> Cause immediate download failure."},{"location":"reference/environment-variables/#inference-container-variables","title":"Inference Container Variables","text":"<p>These are set on inference containers by the operator:</p> Variable Source Description <code>AIM_CACHE_PATH</code> Constant Base path for cached model artifacts. <code>VLLM_ENABLE_METRICS</code> Constant Always <code>true</code> \u2014 enables vLLM Prometheus metrics. <code>AIM_PROFILE_ID</code> Template Active profile identifier. <code>AIM_METRIC</code> Template Optimization metric (<code>latency</code> or <code>throughput</code>). <code>AIM_PRECISION</code> Template Model precision (e.g., <code>fp16</code>, <code>fp8</code>). <code>AIM_MODEL_ID</code> Template Model identifier for custom models. <code>AIM_ENGINE_ARGS</code> Merged JSON-encoded engine arguments, merged from service, template, runtime config, and profile."},{"location":"reference/environment-variables/#environment-variable-merge-order","title":"Environment Variable Merge Order","text":"<p>When the same variable is set at multiple levels, the most specific wins:</p> <ol> <li><code>AIMService.spec.env</code> (highest priority)</li> <li><code>AIMServiceTemplate.spec.env</code> (plus template-derived vars such as metric/precision/profile)</li> <li>Merged runtime config env (<code>AIMRuntimeConfig.spec.env</code> overriding <code>AIMClusterRuntimeConfig.spec.env</code>)</li> <li>Operator defaults (lowest priority)</li> </ol>"},{"location":"reference/environment-variables/#next-steps","title":"Next Steps","text":"<ul> <li>Model Caching Guide \u2014 Download protocol configuration</li> <li>Private Registries \u2014 Authentication environment variables</li> <li>CLI and Operator Flags \u2014 Operator binary flags</li> </ul>"},{"location":"reference/helm-values/","title":"Helm Chart Values","text":"<p>Reference for all configurable values in the AIM Engine Helm chart.</p>"},{"location":"reference/helm-values/#controller-manager","title":"Controller Manager","text":"<p>Controller manager configuration</p> Parameter Description Default <code>manager.replicas</code> Number of operator replicas <code>1</code> <code>manager.image.repository</code> Operator container image repository <code>docker.io/amdenterpriseai/aim-engine</code> <code>manager.image.tag</code> Operator container image tag <code>latest</code> <code>manager.image.pullPolicy</code> Image pull policy <code>IfNotPresent</code> <code>manager.imagePullSecrets</code> Secrets for pulling the operator image from private registries <code>[]</code> <code>manager.args</code> Controller command-line arguments <code>[\"--leader-elect\"]</code> <code>manager.env</code> Additional environment variables for the controller <code>[]</code> <code>manager.podSecurityContext.runAsNonRoot</code> Require non-root user <code>true</code> <code>manager.podSecurityContext.seccompProfile.type</code> Seccomp profile type <code>RuntimeDefault</code> <code>manager.securityContext.allowPrivilegeEscalation</code> Prevent privilege escalation <code>false</code> <code>manager.securityContext.capabilities.drop</code> Dropped Linux capabilities <code>[\"ALL\"]</code> <code>manager.securityContext.readOnlyRootFilesystem</code> Read-only root filesystem <code>true</code> <code>manager.resources.limits.cpu</code> CPU limit <code>500m</code> <code>manager.resources.limits.memory</code> Memory limit <code>4Gi</code> <code>manager.resources.requests.cpu</code> CPU request <code>100m</code> <code>manager.resources.requests.memory</code> Memory request <code>256Mi</code>"},{"location":"reference/helm-values/#rbac-helpers","title":"RBAC Helpers","text":"<p>Create admin/editor/viewer ClusterRoles for each CRD</p> Parameter Description Default <code>rbacHelpers.enable</code> Enable RBAC helper roles <code>true</code>"},{"location":"reference/helm-values/#crds","title":"CRDs","text":"<p>Custom Resource Definitions</p> Parameter Description Default <code>crd.enable</code> Install CRDs with the chart <code>true</code> <code>crd.keep</code> Keep CRDs when uninstalling (prevents data loss) <code>true</code>"},{"location":"reference/helm-values/#metrics","title":"Metrics","text":"<p>Controller metrics endpoint</p> Parameter Description Default <code>metrics.enable</code> Enable metrics endpoint <code>true</code> <code>metrics.port</code> Metrics endpoint port <code>8443</code>"},{"location":"reference/helm-values/#cert-manager","title":"Cert-Manager","text":"<p>Cert-manager integration for TLS certificates</p> Parameter Description Default <code>certManager.enable</code> Enable cert-manager integration <code>false</code>"},{"location":"reference/helm-values/#prometheus","title":"Prometheus","text":"<p>Prometheus ServiceMonitor for metrics scraping</p> Parameter Description Default <code>prometheus.enable</code> Create a Prometheus ServiceMonitor resource <code>false</code>"},{"location":"reference/helm-values/#cluster-runtime-configuration","title":"Cluster Runtime Configuration","text":"<p>Cluster-wide runtime configuration for AIM resources. Creates an AIMClusterRuntimeConfig CR when enabled.</p> Parameter Description Default <code>clusterRuntimeConfig.enable</code> Enable creation of the AIMClusterRuntimeConfig resource <code>false</code> <code>clusterRuntimeConfig.name</code> Name of the AIMClusterRuntimeConfig resource <code>default</code>"},{"location":"reference/helm-values/#cluster-model-source","title":"Cluster Model Source","text":"<p>Cluster-wide model source for automatic model discovery from container registries. Creates an AIMClusterModelSource CR when enabled, installing latest AIM Container Images.</p> Parameter Description Default <code>clusterModelSource.enable</code> Enable creation of the AIMClusterModelSource resource <code>false</code> <code>clusterModelSource.name</code> Name of the AIMClusterModelSource resource <code>amd-aim-model-source</code> <code>clusterModelSource.spec</code> Spec fields for the AIMClusterModelSource <code>clusterModelSource.spec.registry</code> Container registry to sync from (e.g., docker.io, ghcr.io, gcr.io) <code>docker.io</code> <code>clusterModelSource.spec.filters</code> Filters define which images to discover and sync. Each filter specifies an image pattern with optional version constraints. <code>clusterModelSource.spec.syncInterval</code> How often to sync with the registry (minimum recommended: 15m) <code>1h</code> <code>clusterModelSource.spec.maxModels</code> Maximum number of AIMClusterModel resources to create (prevents runaway creation) <code>500</code>"},{"location":"reference/naming-and-labels/","title":"Naming and Label Conventions","text":"<p>AIM Engine creates derived resources (InferenceServices, HTTPRoutes, PVCs, Jobs, etc.) that do not share their parent's name. This page documents the naming algorithm, all label keys, and how to query AIM-managed resources.</p>"},{"location":"reference/naming-and-labels/#derived-naming","title":"Derived Naming","text":""},{"location":"reference/naming-and-labels/#algorithm","title":"Algorithm","text":"<p>Derived names are generated by <code>GenerateDerivedName</code>, which produces deterministic, RFC 1123-compliant names:</p> <ol> <li>Sanitize each name part \u2014 lowercase, replace non-alphanumeric characters with <code>-</code>, trim leading/trailing dashes</li> <li>Hash \u2014 compute SHA-256 of inputs (sorted deterministically), truncate to a configured hex length</li> <li>Assemble \u2014 join sanitized parts with <code>-</code>, append <code>-{hash}</code></li> <li>Fit \u2014 if the result exceeds 63 characters, iteratively shorten the longest part until it fits</li> </ol>"},{"location":"reference/naming-and-labels/#why-derived-names","title":"Why Derived Names?","text":"<p>Kubernetes names have a 63-character limit. AIM Engine often needs to encode multiple dimensions (template name, service name, GPU model, precision) into a single name. The hash suffix guarantees uniqueness when names are truncated.</p> <p>Important</p> <p>Derived resource names are not predictable from the parent name alone. Always use labels (not name matching) to find child resources.</p>"},{"location":"reference/naming-and-labels/#derived-resource-names","title":"Derived Resource Names","text":"Resource Created By Name Parts Hash Source InferenceService AIMService <code>[serviceName]</code> namespace HTTPRoute AIMService <code>[serviceName]</code> namespace AIMTemplateCache (shared) AIMService <code>[templateName]</code> namespace AIMTemplateCache (dedicated) AIMService <code>[templateName, serviceName]</code> service UID AIMModel (from image) AIMService <code>[imageName, imageTag]</code> image URI AIMClusterModel AIMClusterModelSource <code>[repository, tag]</code> registry + repo + tag AIMServiceTemplate (discovered) AIMModel <code>[imageName, metric-precision-gpu]</code> hash string AIMArtifact AIMTemplateCache <code>[sourceURI]</code> source URI + env + storage PVC AIMArtifact <code>[artifactName, \"cache\"]</code> artifact UID Download Job AIMArtifact <code>[artifactName, \"download\"]</code> artifact UID Check-size Job AIMArtifact <code>[artifactName, \"check-size\"]</code> artifact UID"},{"location":"reference/naming-and-labels/#labels","title":"Labels","text":""},{"location":"reference/naming-and-labels/#aim-domain-labels","title":"AIM Domain Labels","text":"<p>All AIM labels use the <code>aim.eai.amd.com/</code> prefix.</p>"},{"location":"reference/naming-and-labels/#ownership-and-identity","title":"Ownership and Identity","text":"Label Value Purpose <code>aim.eai.amd.com/service.name</code> Service name Framework-applied owner label (<code>{controller}.name</code>) for AIMService-managed resources <code>aim.eai.amd.com/model</code> Model name Identifies the owning model <code>aim.eai.amd.com/template</code> Template name Identifies the owning template <code>aim.eai.amd.com/template-cache.name</code> Cache name Identifies the owning template cache <code>aim.eai.amd.com/origin</code> <code>auto-generated</code>, <code>manual</code> How the resource was created <code>aim.eai.amd.com/managed-by</code> <code>aim-controller</code> Marks operator-managed resources <code>aim.eai.amd.com/component</code> <code>inference</code>, <code>discovery</code>, <code>cache</code>, <code>check-size</code> Functional role of the resource"},{"location":"reference/naming-and-labels/#runtime-attributes","title":"Runtime Attributes","text":"Label Value Purpose <code>aim.eai.amd.com/metric</code> <code>latency</code>, <code>throughput</code> Optimization metric <code>aim.eai.amd.com/precision</code> <code>fp8</code>, <code>fp16</code>, <code>bf16</code> Numeric precision <code>aim.eai.amd.com/gpu.model</code> <code>MI300X</code>, <code>MI325X</code>, etc. GPU model <code>aim.eai.amd.com/gpu.count</code> <code>\"1\"</code>, <code>\"4\"</code> GPU count"},{"location":"reference/naming-and-labels/#cache-labels","title":"Cache Labels","text":"Label Value Purpose <code>aim.eai.amd.com/cache-type</code> <code>temp</code>, <code>persistent</code>, <code>dedicated</code> PVC cache type <code>aim.eai.amd.com/cache.type</code> <code>artifact</code>, <code>template-cache</code> Cache resource type <code>aim.eai.amd.com/cache.name</code> Artifact name Identifies the cache resource <code>aim.eai.amd.com/model.source</code> <code>huggingface</code>, <code>s3</code> Model download source"},{"location":"reference/naming-and-labels/#template-labels","title":"Template Labels","text":"Label Value Purpose <code>aim.eai.amd.com/template.name</code> Template name On artifacts \u2014 parent template <code>aim.eai.amd.com/template.scope</code> <code>Namespace</code>, <code>Cluster</code> Template scope <code>aim.eai.amd.com/template.index</code> <code>\"0\"</code>, <code>\"1\"</code> Profile index in template <code>aim.eai.amd.com/template.metric</code> <code>latency</code>, <code>throughput</code> Template metric <code>aim.eai.amd.com/template.precision</code> <code>fp8</code>, <code>fp16</code> Template precision <code>aim.eai.amd.com/template.alias</code> User alias Custom template alias <code>aim.eai.amd.com/custom-model</code> <code>\"true\"</code> Marks custom model templates <code>aim.eai.amd.com/source-model</code> Model identifier Source model reference"},{"location":"reference/naming-and-labels/#standard-kubernetes-labels","title":"Standard Kubernetes Labels","text":"Label Value Purpose <code>app.kubernetes.io/managed-by</code> <code>aim-{controller}-controller</code> Controller that owns the child resource <code>app.kubernetes.io/component</code> <code>inference</code>, <code>routing</code>, <code>model-storage</code>, <code>discovery</code> Functional component <code>app.kubernetes.io/name</code> <code>aim-discovery</code>, <code>aim-engine</code> Application name"},{"location":"reference/naming-and-labels/#controller-labels","title":"Controller Labels","text":"<p>The reconciler adds <code>aim.eai.amd.com/{controller}.name</code> = parent resource name to all managed children. For example, a resource managed by the AIMService controller gets:</p> <pre><code>aim.eai.amd.com/service.name: qwen-chat\n</code></pre>"},{"location":"reference/naming-and-labels/#querying-aim-resources","title":"Querying AIM Resources","text":""},{"location":"reference/naming-and-labels/#find-all-resources-for-a-service","title":"Find All Resources for a Service","text":"<pre><code>kubectl get all -l aim.eai.amd.com/service.name=qwen-chat -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/naming-and-labels/#find-the-inferenceservice-for-a-service","title":"Find the InferenceService for a Service","text":"<pre><code>kubectl get inferenceservice -l aim.eai.amd.com/service.name=qwen-chat -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/naming-and-labels/#find-artifacts-for-a-template-cache","title":"Find Artifacts for a Template Cache","text":"<pre><code>kubectl get aimartifact -l aim.eai.amd.com/template-cache.name=&lt;cache-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/naming-and-labels/#find-discovery-jobs-for-a-template","title":"Find Discovery Jobs for a Template","text":"<pre><code>kubectl get jobs -l aim.eai.amd.com/template=&lt;template-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/naming-and-labels/#find-download-jobs-for-an-artifact","title":"Find Download Jobs for an Artifact","text":"<pre><code>kubectl get jobs -l aim.eai.amd.com/cache.name=&lt;artifact-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"reference/naming-and-labels/#find-all-auto-generated-resources","title":"Find All Auto-Generated Resources","text":"<pre><code>kubectl get aimmodel -l aim.eai.amd.com/origin=auto-generated --all-namespaces\n</code></pre>"},{"location":"reference/naming-and-labels/#field-indexers","title":"Field Indexers","text":"<p>The operator maintains field indexes for efficient lookups:</p> Index Field Resource Description <code>.spec.templateRef</code> AIMService Services by template reference <code>.status.resolvedTemplate.name</code> AIMService Services by resolved template <code>.spec.templateName</code> AIMTemplateCache Caches by template name <code>.spec.templateScope</code> AIMTemplateCache Caches by template scope <code>.spec.modelName</code> AIMServiceTemplate Templates by model name <code>.spec.image</code> AIMModel / AIMClusterModel Models by image URI <code>.spec.runtimeConfigName</code> Multiple CRDs Resources by runtime config <code>.spec.sourceUri</code> AIMArtifact Artifacts by source URI <p>Some index key names are legacy internal identifiers (for example, <code>.spec.templateRef</code>) and may not exactly match the current CRD JSON field path.</p>"},{"location":"reference/api/v1alpha1/","title":"API Reference","text":""},{"location":"reference/api/v1alpha1/#packages","title":"Packages","text":"<ul> <li>aim.eai.amd.com/v1alpha1</li> </ul>"},{"location":"reference/api/v1alpha1/#aimeaiamdcomv1alpha1","title":"aim.eai.amd.com/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the aim v1alpha1 API group.</p>"},{"location":"reference/api/v1alpha1/#resource-types","title":"Resource Types","text":"<ul> <li>AIMArtifact</li> <li>AIMArtifactList</li> <li>AIMClusterModel</li> <li>AIMClusterModelList</li> <li>AIMClusterModelSource</li> <li>AIMClusterModelSourceList</li> <li>AIMClusterRuntimeConfig</li> <li>AIMClusterRuntimeConfigList</li> <li>AIMClusterServiceTemplate</li> <li>AIMClusterServiceTemplateList</li> <li>AIMModel</li> <li>AIMModelList</li> <li>AIMRuntimeConfig</li> <li>AIMRuntimeConfigList</li> <li>AIMService</li> <li>AIMServiceList</li> <li>AIMServiceTemplate</li> <li>AIMServiceTemplateList</li> <li>AIMTemplateCache</li> <li>AIMTemplateCacheList</li> </ul>"},{"location":"reference/api/v1alpha1/#aimartifact","title":"AIMArtifact","text":"<p>AIMArtifact is the Schema for the artifacts API</p> <p>Appears in: - AIMArtifactList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMArtifact</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMArtifactSpec <code>status</code> AIMArtifactStatus"},{"location":"reference/api/v1alpha1/#aimartifactlist","title":"AIMArtifactList","text":"<p>AIMArtifactList contains a list of AIMArtifact</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMArtifactList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMArtifact array"},{"location":"reference/api/v1alpha1/#aimartifactmode","title":"AIMArtifactMode","text":"<p>Underlying type: string</p> <p>AIMArtifactMode indicates the ownership mode of a artifact, derived from owner references.</p> <p>Validation: - Enum: [Dedicated Shared]</p> <p>Appears in: - AIMArtifactStatus</p> Field Description <code>Dedicated</code> ArtifactModeDedicated indicates the cache has owner references and will begarbage collected when its owners are deleted. <code>Shared</code> ArtifactModeShared indicates the cache has no owner references and persistsindependently, available for sharing across services."},{"location":"reference/api/v1alpha1/#aimartifactspec","title":"AIMArtifactSpec","text":"<p>AIMArtifactSpec defines the desired state of AIMArtifact</p> <p>Appears in: - AIMArtifact</p> Field Description Default Validation <code>sourceUri</code> string SourceURI specifies the source location of the model to download.Supported protocols: hf:// (HuggingFace) and s3:// (S3-compatible storage).This field uniquely identifies the artifact and is immutable after creation.Example: hf://meta-llama/Llama-3-8B MinLength: 1 Pattern: <code>^(hf\\|s3)://[^ \\t\\r\\n]+$</code> <code>modelId</code> string ModelID is the canonical identifier in {org}/{name} format.Determines the cache download path: /workspace/cache/{modelId}For HuggingFace sources, this is typically derived from the URI (e.g., \"meta-llama/Llama-3-8B\").For S3 sources, this must be explicitly provided (e.g., \"my-team/fine-tuned-llama\").When not specified, derived from SourceURI for HuggingFace sources. Pattern: <code>^[a-zA-Z0-9_-]+/[a-zA-Z0-9._-]+$</code> Optional: {}  <code>storageClassName</code> string StorageClassName specifies the storage class for the cache volume.When not specified, uses the cluster default storage class. Optional: {}  <code>size</code> Quantity Size specifies the size of the cache volume Optional: {}  <code>env</code> EnvVar array Env lists the environment variables to use for authentication when downloading models.These variables are used for authentication with model registries (e.g., HuggingFace tokens). Optional: {}  <code>modelDownloadImage</code> string ModelDownloadImage specifies the container image used to download and initialize the artifact.This image runs as a job to download model artifacts from the source URI to the cache volume.When not specified, defaults to \"ghcr.io/silogen/aim-artifact-downloader:0.2.0\". ghcr.io/silogen/aim-artifact-downloader:0.2.0 Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}"},{"location":"reference/api/v1alpha1/#aimartifactstatus","title":"AIMArtifactStatus","text":"<p>AIMArtifactStatus defines the observed state of AIMArtifact</p> <p>Appears in: - AIMArtifact</p> Field Description Default Validation <code>observedGeneration</code> integer <code>conditions</code> Condition array Conditions represent the latest available observations of the artifact's state <code>status</code> AIMStatus Status represents the current status of the artifact Pending Enum: [Pending Progressing Ready Degraded Failed NotAvailable]  <code>progress</code> DownloadProgress Progress represents the download progress when Status is Progressing Optional: {}  <code>download</code> DownloadState Download represents the current download attempt state, patched by the downloader pod.Shows which protocol is active, what attempt we're on, etc. Optional: {}  <code>displaySize</code> string DisplaySize is the human-readable effective size (spec or discovered) Optional: {}  <code>lastUsed</code> Time LastUsed represents the last time a model was deployed that used this cache <code>persistentVolumeClaim</code> string PersistentVolumeClaim represents the name of the created PVC <code>mode</code> AIMArtifactMode Mode indicates the ownership mode of this artifact, derived from owner references.- Dedicated: Has owner references, will be garbage collected when owners are deleted.- Shared: No owner references, persists independently and can be shared. Enum: [Dedicated Shared] Optional: {}  <code>discoveredSizeBytes</code> integer DiscoveredSizeBytes is the model size discovered via check-size job.Populated when spec.size is not provided. Optional: {}  <code>allocatedSize</code> Quantity AllocatedSize is the actual PVC size requested (including headroom). Optional: {}  <code>headroomPercent</code> integer HeadroomPercent is the headroom percentage that was applied to the PVC size. Optional: {}"},{"location":"reference/api/v1alpha1/#aimcachingmode","title":"AIMCachingMode","text":"<p>Underlying type: string</p> <p>AIMCachingMode controls caching behavior for a service. Canonical values are Dedicated and Shared. Legacy values are accepted for backward compatibility: - Always maps to Shared - Auto maps to Shared - Never maps to Dedicated</p> <p>Validation: - Enum: [Dedicated Shared Auto Always Never]</p> <p>Appears in: - AIMServiceCachingConfig</p> Field Description <code>Dedicated</code> CachingModeDedicated always creates service-owned dedicated caches/artifacts. <code>Shared</code> CachingModeShared reuses and creates shared caches/artifacts. <code>Auto</code> CachingModeAuto is deprecated legacy value that maps to Shared. <code>Always</code> CachingModeAlways is deprecated legacy value that maps to Shared. <code>Never</code> CachingModeNever is deprecated legacy value that maps to Dedicated."},{"location":"reference/api/v1alpha1/#aimclustermodel","title":"AIMClusterModel","text":"<p>AIMClusterModel is a cluster-scoped model catalog entry for AIM container images.</p> <p>Cluster-scoped models can be referenced by AIMServices in any namespace, making them ideal for shared model deployments across teams and projects. Like namespace-scoped AIMModels, cluster models trigger discovery jobs to extract metadata and generate service templates.</p> <p>When both cluster and namespace models exist for the same container image, services will preferentially use the namespace-scoped AIMModel when referenced by image URI.</p> <p>Appears in: - AIMClusterModelList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterModel</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMModelSpec <code>status</code> AIMModelStatus"},{"location":"reference/api/v1alpha1/#aimclustermodellist","title":"AIMClusterModelList","text":"<p>AIMClusterModelList contains a list of AIMClusterModel.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterModel array"},{"location":"reference/api/v1alpha1/#aimclustermodelsource","title":"AIMClusterModelSource","text":"<p>AIMClusterModelSource automatically discovers and syncs AI model images from container registries.</p> <p>Appears in: - AIMClusterModelSourceList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelSource</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterModelSourceSpec <code>status</code> AIMClusterModelSourceStatus"},{"location":"reference/api/v1alpha1/#aimclustermodelsourcelist","title":"AIMClusterModelSourceList","text":"<p>AIMClusterModelSourceList contains a list of AIMClusterModelSource.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelSourceList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterModelSource array"},{"location":"reference/api/v1alpha1/#aimclustermodelsourcespec","title":"AIMClusterModelSourceSpec","text":"<p>AIMClusterModelSourceSpec defines the desired state of AIMClusterModelSource.</p> <p>Appears in: - AIMClusterModelSource</p> Field Description Default Validation <code>registry</code> string Registry to sync from (e.g., docker.io, ghcr.io, gcr.io).Defaults to docker.io if not specified. docker.io Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets contains references to secrets for authenticating to private registries.Secrets must exist in the operator namespace (typically aim-system).Used for both registry catalog listing and image metadata extraction. Optional: {}  <code>filters</code> ModelSourceFilter array Filters define which images to discover and sync.Each filter specifies an image pattern with optional version constraints and exclusions.Multiple filters are combined with OR logic (any match includes the image). MaxItems: 100 MinItems: 1  <code>syncInterval</code> Duration SyncInterval defines how often to sync with the registry.Defaults to 1h. Minimum recommended interval is 15m to avoid rate limiting.Format: duration string (e.g., \"30m\", \"1h\", \"2h30m\"). 1h Optional: {}  <code>versions</code> string array Versions specifies global semantic version constraints applied to all filters.Individual filters can override this with their own version constraints.Constraints use semver syntax: &gt;=1.0.0, &lt;2.0.0, ~1.2.0, ^1.0.0, etc.Non-semver tags (e.g., \"latest\", \"dev\") are silently skipped.Version ranges work on all registries (including ghcr.io, gcr.io) when combined withexact repository names (no wildcards). The controller uses the Tags List API to fetchall tags for the repository and filters them by the semver constraint.Example: registry=ghcr.io, filters=[{image: \"silogen/aim-llama\"}], versions=[\"&gt;=1.0.0\"]will fetch all tags from ghcr.io/silogen/aim-llama and include only those &gt;=1.0.0. Optional: {}  <code>maxModels</code> integer MaxModels is the maximum number of AIMClusterModel resources to create from this source.Once this limit is reached, no new models will be created, even if more matching images are discovered.Existing models are never deleted.This prevents runaway model creation from overly broad filters. 100 Maximum: 10000 Minimum: 1 Optional: {}"},{"location":"reference/api/v1alpha1/#aimclustermodelsourcestatus","title":"AIMClusterModelSourceStatus","text":"<p>AIMClusterModelSourceStatus defines the observed state of AIMClusterModelSource.</p> <p>Appears in: - AIMClusterModelSource</p> Field Description Default Validation <code>status</code> string Status represents the overall state of the model source. Enum: [Pending Starting Progressing Ready Running Degraded NotAvailable Failed] Optional: {}  <code>lastSyncTime</code> Time LastSyncTime is the timestamp of the last successful registry sync.Updated after each successful sync operation. Optional: {}  <code>discoveredModels</code> integer DiscoveredModels is the count of AIMClusterModel resources managed by this source.Includes both existing and newly created models. Optional: {}  <code>availableModels</code> integer AvailableModels is the total count of images discovered in the registry that match the filters.This may be higher than DiscoveredModels if maxModels limit was reached. Optional: {}  <code>modelsLimitReached</code> boolean ModelsLimitReached indicates whether the maxModels limit has been reached.When true, no new models will be created even if more matching images are discovered. Optional: {}  <code>conditions</code> Condition array Conditions represent the latest available observations of the source's state.Standard conditions: Ready, Syncing, RegistryReachable. Optional: {}  <code>observedGeneration</code> integer ObservedGeneration reflects the generation of the most recently observed spec. Optional: {}"},{"location":"reference/api/v1alpha1/#aimclusterruntimeconfig","title":"AIMClusterRuntimeConfig","text":"<p>AIMClusterRuntimeConfig is a cluster-scoped runtime configuration for AIM services, models, and templates.</p> <p>Cluster-scoped runtime configs provide platform-wide defaults that apply to all namespaces, making them ideal for organization-level policies such as storage classes, discovery behavior, model creation scope, and routing configuration.</p> <p>When both cluster and namespace runtime configs exist with the same name, the configs are merged, and the namespace-scoped AIMRuntimeConfig takes precedence for any field that is set in both.</p> <p>Appears in: - AIMClusterRuntimeConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterRuntimeConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterRuntimeConfigSpec <code>status</code> AIMRuntimeConfigStatus"},{"location":"reference/api/v1alpha1/#aimclusterruntimeconfiglist","title":"AIMClusterRuntimeConfigList","text":"<p>AIMClusterRuntimeConfigList contains a list of AIMClusterRuntimeConfig.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterRuntimeConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterRuntimeConfig array"},{"location":"reference/api/v1alpha1/#aimclusterruntimeconfigspec","title":"AIMClusterRuntimeConfigSpec","text":"<p>AIMClusterRuntimeConfigSpec defines cluster-wide defaults for AIM resources.</p> <p>Appears in: - AIMClusterRuntimeConfig</p> Field Description Default Validation <code>storage</code> AIMStorageConfig Storage configures storage defaults for this service's PVCs and caches.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing configuration for this service.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.When set on AIMService, these take highest precedence in the merge hierarchy.When set on RuntimeConfig, these provide namespace/cluster-level defaults.Merge order (highest to lowest): Service.Env &gt; Template.Env &gt; RuntimeConfig.Env &gt; Profile.Env Optional: {}  <code>model</code> AIMModelConfig Model controls model creation and discovery defaults.This field only applies to RuntimeConfig/ClusterRuntimeConfig and is not available for services. Optional: {}  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. Optional: {}  <code>defaultStorageClassName</code> string DEPRECATED: Use Storage.DefaultStorageClassName instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.DefaultStorageClassName is not set,the value will be automatically migrated. Optional: {}  <code>pvcHeadroomPercent</code> integer DEPRECATED: Use Storage.PVCHeadroomPercent instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.PVCHeadroomPercent is not set,the value will be automatically migrated. Optional: {}"},{"location":"reference/api/v1alpha1/#aimclusterservicetemplate","title":"AIMClusterServiceTemplate","text":"<p>AIMClusterServiceTemplate is a cluster-scoped template that defines runtime profiles for AIM services.</p> <p>Cluster-scoped templates can be used by AIMServices in any namespace, making them ideal for platform-wide model configurations that should be shared across teams and projects. Unlike namespace-scoped AIMServiceTemplates, cluster templates do not support caching configuration and must be managed by cluster administrators, since caches themselves are namespace-scoped.</p> <p>When both cluster and namespace templates exist with the same name, the namespace-scoped template takes precedence for services in that namespace.</p> <p>Appears in: - AIMClusterServiceTemplateList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterServiceTemplate</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterServiceTemplateSpec <code>status</code> AIMServiceTemplateStatus"},{"location":"reference/api/v1alpha1/#aimclusterservicetemplatelist","title":"AIMClusterServiceTemplateList","text":"<p>AIMClusterServiceTemplateList contains a list of AIMClusterServiceTemplate.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMClusterServiceTemplateList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterServiceTemplate array"},{"location":"reference/api/v1alpha1/#aimclusterservicetemplatespec","title":"AIMClusterServiceTemplateSpec","text":"<p>AIMClusterServiceTemplateSpec defines the desired state of AIMClusterServiceTemplate (cluster-scoped).</p> <p>A cluster-scoped template that selects a runtime profile for a given AIM model.</p> <p>Appears in: - AIMClusterServiceTemplate</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for each replica.For GPU models, defines the GPU count and model types required for deployment.For CPU-only models, defines CPU resource requirements.This field is immutable after creation. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. Optional: {}  <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. Optional: {}  <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. Optional: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. Optional: {}  <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use.When set, the discovery job will be instructed to use this specific profile. Optional: {}  <code>type</code> AIMProfileType Type indicates the optimization level of this template.- optimized: Template has been tuned for performance- preview: Template is experimental/pre-release- unoptimized: Default, no specific optimizations appliedWhen nil, the type is determined by discovery. When set, overrides discovery. Enum: [optimized preview unoptimized] Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.These variables are passed to the inference runtime and can be usedto configure runtime behavior, authentication, or other settings. Optional: {}"},{"location":"reference/api/v1alpha1/#aimcpurequirements","title":"AIMCpuRequirements","text":"<p>AIMCpuRequirements specifies CPU resource requirements.</p> <p>Appears in: - AIMHardwareRequirements</p> Field Description Default Validation <code>requests</code> Quantity Requests is the number of CPU cores to request. Required and must be &gt; 0. Required: {}  <code>limits</code> Quantity Limits is the maximum number of CPU cores to allow. Optional: {}"},{"location":"reference/api/v1alpha1/#aimcustommodelspec","title":"AIMCustomModelSpec","text":"<p>AIMCustomModelSpec contains configuration for custom models. These fields are only used when modelSources is specified (custom models). For image-based models, these settings come from discovery.</p> <p>Appears in: - AIMModelSpec</p> Field Description Default Validation <code>hardware</code> AIMHardwareRequirements Hardware specifies default hardware requirements for all templates.Individual templates can override these defaults.Required when modelSources is set and customTemplates is empty. Optional: {}  <code>type</code> AIMProfileType Type specifies default type for all templates.Individual templates can override this default.When nil, templates default to \"unoptimized\". Enum: [optimized preview unoptimized] Optional: {}"},{"location":"reference/api/v1alpha1/#aimcustomtemplate","title":"AIMCustomTemplate","text":"<p>AIMCustomTemplate defines a custom template configuration for a model. When modelSources are specified directly on AIMModel, customTemplates allow defining explicit hardware requirements and profiles, skipping the discovery job.</p> <p>Appears in: - AIMModelSpec</p> Field Description Default Validation <code>name</code> string Name is the template name. If not provided, auto-generated from model name + profile. MaxLength: 63 Optional: {}  <code>type</code> AIMProfileType Type indicates the optimization status of this template.- optimized: Template has been tuned for performance- preview: Template is experimental/pre-release- unoptimized: Default, no specific optimizations applied unoptimized Enum: [optimized preview unoptimized] Optional: {}  <code>env</code> EnvVar array Env specifies environment variable overrides when this template is selected. MaxItems: 64 Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for this template.Optional when spec.hardware is set (inherits from spec).When both are set, values are merged field-by-field with template taking precedence. Optional: {}  <code>profile</code> AIMTemplateProfile Profile declares runtime profile variables for template selection.Used when multiple templates exist to select based on metric/precision. Optional: {}"},{"location":"reference/api/v1alpha1/#aimdiscoveryprofilemetadata","title":"AIMDiscoveryProfileMetadata","text":"<p>AIMDiscoveryProfileMetadata describes the characteristics of a discovered deployment profile.</p> <p>Appears in: - AIMDiscoveryProfile</p> Field Description Default Validation <code>engine</code> string Engine identifies the inference engine used for this profile (e.g., \"vllm\", \"tgi\"). Optional: {}  <code>gpu</code> string GPU specifies the GPU model this profile is optimized for (e.g., \"MI300X\", \"MI325X\"). Optional: {}  <code>gpu_count</code> integer GPUCount indicates how many GPUs are required per replica for this profile. Optional: {}  <code>metric</code> AIMMetric Metric indicates the optimization goal for this profile (\"latency\" or \"throughput\"). Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision specifies the numeric precision used in this profile (e.g., \"fp16\", \"fp8\"). Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>type</code> AIMProfileType Type specifies the optimization level of this profile (optimized, unoptimized, preview). Enum: [optimized preview unoptimized] Optional: {}"},{"location":"reference/api/v1alpha1/#aimgpurequirements","title":"AIMGpuRequirements","text":"<p>AIMGpuRequirements specifies GPU resource requirements.</p> <p>Appears in: - AIMHardwareRequirements</p> Field Description Default Validation <code>requests</code> integer Requests is the number of GPUs to set as requests/limits.Set to 0 to target GPU nodes without consuming GPU resources (useful for testing). Minimum: 0 Optional: {}  <code>model</code> string Model limits deployment to a specific GPU model.Example: \"MI300X\"Cannot be combined with minVram. MaxLength: 64 Optional: {}  <code>minVram</code> Quantity MinVRAM limits deployment to GPUs having at least this much VRAM.Used for capacity planning when the model size is known but any GPU withsufficient VRAM is acceptable.Cannot be combined with model. Optional: {}  <code>resourceName</code> string ResourceName is the Kubernetes resource name for GPU resources.Defaults to \"amd.com/gpu\" if not specified. amd.com/gpu Optional: {}"},{"location":"reference/api/v1alpha1/#aimhardwarerequirements","title":"AIMHardwareRequirements","text":"<p>AIMHardwareRequirements specifies compute resource requirements for custom models. Used in AIMModelSpec and AIMCustomTemplate to define GPU and CPU needs.</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMCustomModelSpec - AIMCustomTemplate - AIMRuntimeParameters - AIMServiceModelCustom - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMServiceTemplateStatus</p> Field Description Default Validation <code>gpu</code> AIMGpuRequirements GPU specifies GPU requirements. If not set, no GPUs are requested (CPU-only model). Optional: {}  <code>cpu</code> AIMCpuRequirements CPU specifies CPU requirements. Optional: {}"},{"location":"reference/api/v1alpha1/#aimmetric","title":"AIMMetric","text":"<p>Underlying type: string</p> <p>AIMMetric enumerates the targeted service characteristic</p> <p>Validation: - Enum: [latency throughput]</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMDiscoveryProfileMetadata - AIMProfileMetadata - AIMRuntimeParameters - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMTemplateProfile</p> Field Description <code>latency</code> <code>throughput</code>"},{"location":"reference/api/v1alpha1/#aimmodel","title":"AIMModel","text":"<p>AIMModel is the Schema for namespace-scoped AIM model catalog entries.</p> <p>Appears in: - AIMModelList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMModel</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMModelSpec <code>status</code> AIMModelStatus"},{"location":"reference/api/v1alpha1/#aimmodelconfig","title":"AIMModelConfig","text":"<p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec</p> Field Description Default Validation <code>autoDiscovery</code> boolean AutoDiscovery controls whether models run discovery by default.When true, models run discovery jobs to extract metadata and auto-create templates.When false, discovery is skipped. Discovery failures are non-fatal and reported via conditions. Optional: {}"},{"location":"reference/api/v1alpha1/#aimmodeldiscoveryconfig","title":"AIMModelDiscoveryConfig","text":"<p>AIMModelDiscoveryConfig controls discovery behavior for a model.</p> <p>Appears in: - AIMModelSpec</p> Field Description Default Validation <code>extractMetadata</code> boolean ExtractMetadata controls whether metadata extraction runs for this model.During metadata extraction, the controller connects to the image registry andextracts the image's labels. true Optional: {}  <code>createServiceTemplates</code> boolean CreateServiceTemplates controls whether (cluster) service templates are auto-created from the image metadata. true Optional: {}"},{"location":"reference/api/v1alpha1/#aimmodellist","title":"AIMModelList","text":"<p>AIMModelList contains a list of AIMModel.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMModelList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMModel array"},{"location":"reference/api/v1alpha1/#aimmodelsource","title":"AIMModelSource","text":"<p>AIMModelSource describes a model artifact that must be downloaded for inference. Discovery extracts these from the container's configuration to enable caching and validation.</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMModelSpec - AIMServiceModelCustom - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMServiceTemplateStatus - AIMTemplateCacheSpec</p> Field Description Default Validation <code>modelId</code> string ModelID is the canonical identifier in {org}/{name} format.Determines the cache mount path: /workspace/cache/{modelId}For HuggingFace sources, this typically mirrors the URI path (e.g., meta-llama/Llama-3-8B).For S3 sources, users define their own organizational structure. Pattern: <code>^[a-zA-Z0-9_-]+/[a-zA-Z0-9._-]+$</code> Required: {}  <code>sourceUri</code> string SourceURI is the location from which the model should be downloaded.Supported schemes:- hf://org/model - Hugging Face Hub model- s3://bucket/key - S3-compatible storage Pattern: <code>^(hf\\|s3)://[^ \\t\\r\\n]+$</code> <code>size</code> Quantity Size is the expected storage space required for this model artifact.Used for PVC sizing and capacity planning during cache creation.Optional - if not specified, the download job will discover the size automatically.Can be set explicitly to pre-allocate storage or override auto-discovery. Optional: {}  <code>env</code> EnvVar array Env specifies per-source credential overrides.These variables are used for authentication when downloading this specific source.Takes precedence over base-level env for the same variable name. Optional: {}"},{"location":"reference/api/v1alpha1/#aimmodelsourcetype","title":"AIMModelSourceType","text":"<p>Underlying type: string</p> <p>AIMModelSourceType indicates how a model's artifacts are sourced.</p> <p>Validation: - Enum: [Image Custom]</p> <p>Appears in: - AIMModelStatus</p> Field Description <code>Image</code> AIMModelSourceTypeImage indicates the model is discovered from container image labels. <code>Custom</code> AIMModelSourceTypeCustom indicates the model uses explicit spec.modelSources."},{"location":"reference/api/v1alpha1/#aimmodelspec","title":"AIMModelSpec","text":"<p>AIMModelSpec defines the desired state of AIMModel.</p> <p>Appears in: - AIMClusterModel - AIMModel</p> Field Description Default Validation <code>image</code> string Image is the container image URI for this AIM model.This image is inspected by the operator to select runtime profiles used by templates.Discovery behavior is controlled by the discovery field and runtime config's AutoDiscovery setting. MinLength: 1  <code>discovery</code> AIMModelDiscoveryConfig Discovery controls discovery behavior for this model.When unset, uses runtime config defaults. Optional: {}  <code>defaultServiceTemplate</code> string DefaultServiceTemplate specifies the default AIMServiceTemplate to use when creating services for this model.When set, services that reference this model will use this template if no template is explicitly specified.If this is not set, a template will be automatically selected. Optional: {}  <code>custom</code> AIMCustomModelSpec Custom contains configuration for custom models (models with inline modelSources).Only used when modelSources are specified; ignored for image-based models. Optional: {}  <code>customTemplates</code> AIMCustomTemplate array CustomTemplates defines explicit template configurations for this model.These templates are created directly without running a discovery job.Can be used with or without modelSources to define custom deployment configurations.If omitted when modelSources is set, a single template is auto-generatedusing the custom.hardware requirements. MaxItems: 16 Optional: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources to use for this model.When specified, these sources are used instead of auto-discovery from the container image.This enables pre-creating custom models with explicit model sources.The size field is optional - if not specified, it will be discovered by the download job.AIM runtime currently supports only one model source. MaxItems: 1 Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling the model container image.These secrets are used for:- OCI registry metadata extraction during discovery- Pulling the image for inference servicesThe secrets are merged with any runtime config defaults.For namespace-scoped models, secrets must exist in the same namespace.For cluster-scoped models, secrets must exist in the operator namespace. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for authentication during model discovery and metadata extraction.These variables are used for authentication with model registries (e.g., HuggingFace tokens). Optional: {}  <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this model.This includes metadata extraction jobs and any other model-related operations.If empty, the default service account for the namespace is used. Optional: {}  <code>resources</code> ResourceRequirements Resources defines the default resource requirements for services using this model.Template- or service-level values override these defaults. Optional: {}  <code>imageMetadata</code> ImageMetadata ImageMetadata is the metadata that is used to determine which recommended service templates to create,and to drive clients with richer metadata regarding this particular model. For most cases the user doesnot need to set this field manually, for images that have the supported labels embedded in themthe <code>AIM(Cluster)Model.status.imageMetadata</code> field is automatically filled from the container image labels.This field is intended to be used when there are network restrictions, or in other similar situations.If this field is set, the remote extraction will not be performed at all."},{"location":"reference/api/v1alpha1/#aimmodelstatus","title":"AIMModelStatus","text":"<p>AIMModelStatus defines the observed state of AIMModel.</p> <p>Appears in: - AIMClusterModel - AIMModel</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller <code>status</code> AIMStatus Status represents the overall status of the image based on its templates Pending Enum: [Pending Progressing Ready Degraded Failed NotAvailable]  <code>conditions</code> Condition array Conditions represent the latest available observations of the model's state <code>resolvedRuntimeConfig</code> AIMResolvedReference ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. Optional: {}  <code>imageMetadata</code> ImageMetadata ImageMetadata is the metadata extracted from an AIM image Optional: {}  <code>sourceType</code> AIMModelSourceType SourceType indicates how this model's artifacts are sourced.- \"Image\": Model discovered from container image labels- \"Custom\": Model uses explicit spec.modelSourcesSet by the controller based on whether spec.modelSources is populated. Enum: [Image Custom] Optional: {}"},{"location":"reference/api/v1alpha1/#aimprecision","title":"AIMPrecision","text":"<p>Underlying type: string</p> <p>AIMPrecision enumerates supported numeric precisions</p> <p>Validation: - Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMDiscoveryProfileMetadata - AIMProfileMetadata - AIMRuntimeParameters - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMTemplateProfile</p> Field Description <code>auto</code> <code>fp4</code> <code>fp8</code> <code>fp16</code> <code>fp32</code> <code>bf16</code> <code>int4</code> <code>int8</code>"},{"location":"reference/api/v1alpha1/#aimprofile","title":"AIMProfile","text":"<p>AIMProfile contains the cached discovery results for a template. This is the processed and validated version of AIMDiscoveryProfile that is stored in the template's status after successful discovery.</p> <p>The profile serves as a cache of runtime configuration, eliminating the need to re-run discovery for each service that uses this template. Services and caching mechanisms reference this cached profile for deployment parameters and model sources.</p> <p>See discovery.go for AIMDiscoveryProfile (the raw discovery output) and the relationship between these types.</p> <p>Appears in: - AIMServiceTemplateStatus</p> Field Description Default Validation <code>engine_args</code> JSON EngineArgs contains runtime-specific engine configuration as a free-form JSON object.The structure depends on the inference engine being used (e.g., vLLM, TGI).These arguments are passed to the runtime container to configure model loading and inference. Schemaless: {}  <code>env_vars</code> object (keys:string, values:string) EnvVars contains environment variables required by the runtime for this profile.These may include engine-specific settings, optimization flags, or hardware configuration. Optional: {}  <code>metadata</code> AIMProfileMetadata Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>originalDiscoveryOutput</code> JSON OriginalDiscoveryOutput contains the raw discovery job JSON output.This preserves the complete discovery result from the dry-run container,including all fields that may not be mapped to structured fields above. Schemaless: {} Optional: {}"},{"location":"reference/api/v1alpha1/#aimprofilemetadata","title":"AIMProfileMetadata","text":"<p>AIMProfileMetadata describes the characteristics of a cached deployment profile. This is identical to AIMDiscoveryProfileMetadata but exists in the template status namespace.</p> <p>Appears in: - AIMProfile</p> Field Description Default Validation <code>engine</code> string Engine identifies the inference engine used for this profile (e.g., \"vllm\", \"tgi\"). Optional: {}  <code>gpu</code> string GPU specifies the GPU model this profile is optimized for (e.g., \"MI300X\", \"MI325X\"). Optional: {}  <code>gpuCount</code> integer GPUCount indicates how many GPUs are required per replica for this profile. Optional: {}  <code>metric</code> AIMMetric Metric indicates the optimization goal for this profile (\"latency\" or \"throughput\"). Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision specifies the numeric precision used in this profile (e.g., \"fp16\", \"fp8\"). Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>type</code> AIMProfileType Type indicates the optimization level of this profile (optimized, preview, unoptimized). Enum: [optimized preview unoptimized] Optional: {}"},{"location":"reference/api/v1alpha1/#aimprofiletype","title":"AIMProfileType","text":"<p>Underlying type: string</p> <p>AIMProfileType indicates the optimization level of a deployment profile.</p> <p>Validation: - Enum: [optimized preview unoptimized]</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMCustomModelSpec - AIMCustomTemplate - AIMDiscoveryProfileMetadata - AIMProfileMetadata - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description <code>optimized</code> AIMProfileTypeOptimized indicates the profile has been fully optimized. <code>preview</code> AIMProfileTypePreview indicates the profile is in preview/beta state. <code>unoptimized</code> AIMProfileTypeUnoptimized indicates the profile has not been optimized."},{"location":"reference/api/v1alpha1/#aimresolutionscope","title":"AIMResolutionScope","text":"<p>Underlying type: string</p> <p>AIMResolutionScope describes the scope of a resolved reference.</p> <p>Validation: - Enum: [Namespace Cluster Merged Unknown]</p> <p>Appears in: - AIMResolvedReference</p> Field Description <code>Namespace</code> AIMResolutionScopeNamespace denotes a namespace-scoped resource. <code>Cluster</code> AIMResolutionScopeCluster denotes a cluster-scoped resource. <code>Merged</code> AIMResolutionScopeMerged denotes that both cluster and namespace configs were merged. <code>Unknown</code> AIMResolutionScopeUnknown denotes that the scope could not be determined."},{"location":"reference/api/v1alpha1/#aimresolvedartifact","title":"AIMResolvedArtifact","text":"<p>Appears in: - AIMTemplateCacheStatus</p> Field Description Default Validation <code>uid</code> string UID of the AIMArtifact resource <code>name</code> string Name of the AIMArtifact resource <code>model</code> string Model is the name of the model that is cached <code>status</code> AIMStatus Status of the artifact <code>persistentVolumeClaim</code> string PersistentVolumeClaim name if available <code>mountPoint</code> string MountPoint is the mount point for the artifact"},{"location":"reference/api/v1alpha1/#aimresolvedreference","title":"AIMResolvedReference","text":"<p>AIMResolvedReference captures metadata about a resolved reference.</p> <p>Appears in: - AIMModelStatus - AIMServiceCacheStatus - AIMServiceStatus - AIMServiceTemplateStatus - AIMTemplateCacheStatus</p> Field Description Default Validation <code>name</code> string Name is the resource name that satisfied the reference. <code>namespace</code> string Namespace identifies where the resource was found when namespace-scoped.Empty indicates a cluster-scoped resource. <code>scope</code> AIMResolutionScope Scope indicates whether the resolved resource was namespace or cluster scoped. Enum: [Namespace Cluster Merged Unknown]  <code>kind</code> string Kind is the fully-qualified kind of the resolved reference, when known. Optional: {}  <code>uid</code> UID UID captures the unique identifier of the resolved reference, when known. Optional: {}"},{"location":"reference/api/v1alpha1/#aimruntimeconfig","title":"AIMRuntimeConfig","text":"<p>AIMRuntimeConfig is the Schema for namespace-scoped AIM runtime configurations.</p> <p>Appears in: - AIMRuntimeConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMRuntimeConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMRuntimeConfigSpec <code>status</code> AIMRuntimeConfigStatus"},{"location":"reference/api/v1alpha1/#aimruntimeconfigcommon","title":"AIMRuntimeConfigCommon","text":"<p>AIMRuntimeConfigCommon captures configuration fields shared across cluster and namespace scopes. These settings apply to both AIMRuntimeConfig (namespace-scoped) and AIMClusterRuntimeConfig (cluster-scoped). It embeds AIMServiceRuntimeConfig which contains fields that can also be overridden at the service level.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigSpec</p> Field Description Default Validation <code>storage</code> AIMStorageConfig Storage configures storage defaults for this service's PVCs and caches.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing configuration for this service.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.When set on AIMService, these take highest precedence in the merge hierarchy.When set on RuntimeConfig, these provide namespace/cluster-level defaults.Merge order (highest to lowest): Service.Env &gt; Template.Env &gt; RuntimeConfig.Env &gt; Profile.Env Optional: {}  <code>model</code> AIMModelConfig Model controls model creation and discovery defaults.This field only applies to RuntimeConfig/ClusterRuntimeConfig and is not available for services. Optional: {}  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. Optional: {}  <code>defaultStorageClassName</code> string DEPRECATED: Use Storage.DefaultStorageClassName instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.DefaultStorageClassName is not set,the value will be automatically migrated. Optional: {}  <code>pvcHeadroomPercent</code> integer DEPRECATED: Use Storage.PVCHeadroomPercent instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.PVCHeadroomPercent is not set,the value will be automatically migrated. Optional: {}"},{"location":"reference/api/v1alpha1/#aimruntimeconfiglabelpropagationspec","title":"AIMRuntimeConfigLabelPropagationSpec","text":"<p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled, if true, allows propagating parent labels to all child resources it creates directlyOnly label keys that match the ones in Match are propagated. false Optional: {}  <code>match</code> string array Match is a list of label keys that will be propagated to any child resources created.Wildcards are supported, so for example <code>org.my/my-key-*</code> would match any label with that prefix. Optional: {}"},{"location":"reference/api/v1alpha1/#aimruntimeconfiglist","title":"AIMRuntimeConfigList","text":"<p>AIMRuntimeConfigList contains a list of AIMRuntimeConfig.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMRuntimeConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMRuntimeConfig array"},{"location":"reference/api/v1alpha1/#aimruntimeconfigspec","title":"AIMRuntimeConfigSpec","text":"<p>AIMRuntimeConfigSpec defines namespace-scoped overrides for AIM resources.</p> <p>Appears in: - AIMRuntimeConfig</p> Field Description Default Validation <code>storage</code> AIMStorageConfig Storage configures storage defaults for this service's PVCs and caches.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing configuration for this service.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.When set on AIMService, these take highest precedence in the merge hierarchy.When set on RuntimeConfig, these provide namespace/cluster-level defaults.Merge order (highest to lowest): Service.Env &gt; Template.Env &gt; RuntimeConfig.Env &gt; Profile.Env Optional: {}  <code>model</code> AIMModelConfig Model controls model creation and discovery defaults.This field only applies to RuntimeConfig/ClusterRuntimeConfig and is not available for services. Optional: {}  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. Optional: {}  <code>defaultStorageClassName</code> string DEPRECATED: Use Storage.DefaultStorageClassName instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.DefaultStorageClassName is not set,the value will be automatically migrated. Optional: {}  <code>pvcHeadroomPercent</code> integer DEPRECATED: Use Storage.PVCHeadroomPercent instead. This field will be removed in a future version.For backward compatibility, if this field is set and Storage.PVCHeadroomPercent is not set,the value will be automatically migrated. Optional: {}"},{"location":"reference/api/v1alpha1/#aimruntimeconfigstatus","title":"AIMRuntimeConfigStatus","text":"<p>AIMRuntimeConfigStatus records the resolved config reference surfaced to consumers.</p> <p>Appears in: - AIMClusterRuntimeConfig - AIMRuntimeConfig</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the last reconciled generation. <code>conditions</code> Condition array Conditions communicate reconciliation progress."},{"location":"reference/api/v1alpha1/#aimruntimeparameters","title":"AIMRuntimeParameters","text":"<p>AIMRuntimeParameters contains the runtime configuration parameters shared across templates and services. Fields use pointers to allow optional usage in different contexts (required in templates, optional in service overrides).</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description Default Validation <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for each replica.For GPU models, defines the GPU count and model types required for deployment.For CPU-only models, defines CPU resource requirements.This field is immutable after creation. Optional: {}"},{"location":"reference/api/v1alpha1/#aimruntimeroutingconfig","title":"AIMRuntimeRoutingConfig","text":"<p>AIMRuntimeRoutingConfig configures HTTP routing defaults for inference services. These settings control how Gateway API HTTPRoutes are created and configured.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceRuntimeConfig - AIMServiceSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled controls whether HTTP routing is managed for inference services using this config.When true, the operator creates HTTPRoute resources for services that reference this config.When false or unset, routing must be explicitly enabled on each service.This provides a namespace or cluster-wide default that individual services can override. Optional: {}  <code>gatewayRef</code> ParentReference GatewayRef specifies the Gateway API Gateway resource that should receive HTTPRoutes.This identifies the parent gateway for routing traffic to inference services.The gateway can be in any namespace (cross-namespace references are supported).If routing is enabled but GatewayRef is not specified, service reconciliation will failwith a validation error. Optional: {}  <code>pathTemplate</code> string PathTemplate defines the HTTP path template for routes, evaluated using JSONPath expressions.The template is rendered against the AIMService object to generate unique paths.Example templates:- <code>/\\{.metadata.namespace\\}/\\{.metadata.name\\}</code> - namespace and service name- <code>/\\{.metadata.namespace\\}/\\{.metadata.labels['team']\\}/inference</code> - with label- <code>/models/\\{.metadata.name\\}</code> - based on service nameThe template must:- Use valid JSONPath expressions wrapped in {...}- Reference fields that exist on the service- Produce a path \u2264 200 characters after rendering- Result in valid URL path segments (lowercase, RFC 1123 compliant)If evaluation fails, the service enters Degraded state with PathTemplateInvalid reason.Individual services can override this template via spec.routing.pathTemplate. Optional: {}  <code>requestTimeout</code> Duration RequestTimeout defines the HTTP request timeout for routes.This sets the maximum duration for a request to complete before timing out.The timeout applies to the entire request/response cycle.If not specified, no timeout is set on the route.Individual services can override this value via spec.routing.requestTimeout. Optional: {}  <code>annotations</code> object (keys:string, values:string) Annotations defines default annotations to add to all HTTPRoute resources.Services can add additional annotations or override these via spec.routingAnnotations.When both are specified, service annotations take precedence for conflicting keys.Common use cases include ingress controller settings, rate limiting, monitoring labels,and security policies that should apply to all services using this config. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservice","title":"AIMService","text":"<p>AIMService manages a KServe-based AIM inference service for the selected model and template. Note: KServe uses {name}-{namespace} format which must not exceed 63 characters. This constraint is validated at runtime since CEL cannot access metadata.namespace.</p> <p>Appears in: - AIMServiceList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMService</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMServiceSpec <code>status</code> AIMServiceStatus"},{"location":"reference/api/v1alpha1/#aimserviceautoscaling","title":"AIMServiceAutoScaling","text":"<p>AIMServiceAutoScaling configures KEDA-based autoscaling with custom metrics. This enables automatic scaling based on metrics collected from OpenTelemetry.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>metrics</code> AIMServiceMetricsSpec array Metrics is a list of metrics to be used for autoscaling.Each metric defines a source (PodMetric) and target values. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicecachestatus","title":"AIMServiceCacheStatus","text":"<p>AIMServiceCacheStatus captures cache-related status for an AIMService.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>templateCacheRef</code> AIMResolvedReference TemplateCacheRef references the TemplateCache being used, if any. Optional: {}  <code>retryAttempts</code> integer RetryAttempts tracks how many times this service has attempted to retry a failed cache.Each service gets exactly one retry attempt. When a TemplateCache enters Failed state,this counter is incremented from 0 to 1 after deleting failed Artifacts.If the retry fails (cache enters Failed again with attempts == 1), the service degrades. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicecachingconfig","title":"AIMServiceCachingConfig","text":"<p>AIMServiceCachingConfig controls caching behavior for a service.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>mode</code> AIMCachingMode Mode controls when to use caching.Canonical values:- Shared (default): reuse/create shared cache assets- Dedicated: create service-owned dedicated cache assetsLegacy values are accepted and normalized:- Always -&gt; Shared- Auto -&gt; Shared- Never -&gt; Dedicated Shared Enum: [Dedicated Shared Auto Always Never] Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicelist","title":"AIMServiceList","text":"<p>AIMServiceList contains a list of AIMService.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMServiceList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMService array"},{"location":"reference/api/v1alpha1/#aimservicemetrictarget","title":"AIMServiceMetricTarget","text":"<p>AIMServiceMetricTarget defines the target value for a metric. Specifies how the metric value should be interpreted and what target to maintain.</p> <p>Appears in: - AIMServicePodMetricSource</p> Field Description Default Validation <code>type</code> string Type specifies how to interpret the metric value.\"Value\": absolute value target (use Value field)\"AverageValue\": average value across all pods (use AverageValue field)\"Utilization\": percentage utilization for resource metrics (use AverageUtilization field) Enum: [Value AverageValue Utilization]  <code>value</code> string Value is the target value of the metric (as a quantity).Used when Type is \"Value\".Example: \"1\" for 1 request, \"100m\" for 100 millicores Optional: {}  <code>averageValue</code> string AverageValue is the target value of the average of the metric across all relevant pods (as a quantity).Used when Type is \"AverageValue\".Example: \"100m\" for 100 millicores per pod Optional: {}  <code>averageUtilization</code> integer AverageUtilization is the target value of the average of the resource metric across all relevant pods,represented as a percentage of the requested value of the resource for the pods.Used when Type is \"Utilization\". Only valid for Resource metric source type.Example: 80 for 80% utilization Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicemetricsspec","title":"AIMServiceMetricsSpec","text":"<p>AIMServiceMetricsSpec defines a single metric for autoscaling. Specifies the metric source type and configuration.</p> <p>Appears in: - AIMServiceAutoScaling</p> Field Description Default Validation <code>type</code> string Type is the type of metric source.Valid values: \"PodMetric\" (per-pod custom metrics). Enum: [PodMetric]  <code>podmetric</code> AIMServicePodMetricSource PodMetric refers to a metric describing each pod in the current scale target.Used when Type is \"PodMetric\". Supports backends like OpenTelemetry for custom metrics. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicemodel","title":"AIMServiceModel","text":"<p>AIMServiceModel specifies which model to deploy. Exactly one field must be set.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>name</code> string Name references an existing AIMModel or AIMClusterModel by metadata.name.The controller looks for a namespace-scoped AIMModel first, then falls back to cluster-scoped AIMClusterModel.Example: <code>meta-llama-3-8b</code> Optional: {}  <code>image</code> string Image specifies a container image URI directly.The controller searches for an existing model with this image, or creates one if none exists.Auto-created models are namespace-scoped and can be reused by other services.Example: <code>ghcr.io/silogen/llama-3-8b:v1.2.0</code> Optional: {}  <code>custom</code> AIMServiceModelCustom Custom specifies a custom model configuration with explicit base image,model sources, and hardware requirements. The controller will search foran existing matching AIMModel or auto-create one if not found. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicemodelcustom","title":"AIMServiceModelCustom","text":"<p>AIMServiceModelCustom specifies a custom model configuration with explicit base image, model sources, and hardware requirements. Used for ad-hoc custom model deployments.</p> <p>Appears in: - AIMServiceModel</p> Field Description Default Validation <code>baseImage</code> string BaseImage is the container image URI for the AIM base image.This will be used as the image for the auto-created AIMModel.Example: <code>ghcr.io/silogen/aim-base:0.7.0</code> Required: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources to use.The controller will search for or create an AIMModel with these sources.The size field is optional - if not specified, it will be discovered by the download job.AIM runtime currently supports only one model source. MaxItems: 1 MinItems: 1 Required: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies the GPU and CPU requirements for this custom model.GPU is optional - if not set, no GPUs are requested (CPU-only model). Required: {}"},{"location":"reference/api/v1alpha1/#aimserviceoverrides","title":"AIMServiceOverrides","text":"<p>AIMServiceOverrides allows overriding template parameters at the service level. All fields are optional. When specified, they override the corresponding values from the referenced AIMServiceTemplate.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for each replica.For GPU models, defines the GPU count and model types required for deployment.For CPU-only models, defines CPU resource requirements.This field is immutable after creation. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicepodmetric","title":"AIMServicePodMetric","text":"<p>AIMServicePodMetric identifies the pod metric and its backend. Supports multiple metrics backends including OpenTelemetry.</p> <p>Appears in: - AIMServicePodMetricSource</p> Field Description Default Validation <code>backend</code> string Backend defines the metrics backend to use.If not specified, defaults to \"opentelemetry\". opentelemetry Enum: [opentelemetry] Optional: {}  <code>serverAddress</code> string ServerAddress specifies the address of the metrics backend server.If not specified, defaults to \"keda-otel-scaler.keda.svc:4317\" for OpenTelemetry backend. Optional: {}  <code>metricNames</code> string array MetricNames specifies which metrics to collect from pods and send to ServerAddress.Example: [\"vllm:num_requests_running\"] Optional: {}  <code>query</code> string Query specifies the query to run to retrieve metrics from the backend.The query syntax depends on the backend being used.Example: \"vllm:num_requests_running\" for OpenTelemetry. Optional: {}  <code>operationOverTime</code> string OperationOverTime specifies the operation to aggregate metrics over time.Valid values: \"last_one\", \"avg\", \"max\", \"min\", \"rate\", \"count\"Default: \"last_one\" Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicepodmetricsource","title":"AIMServicePodMetricSource","text":"<p>AIMServicePodMetricSource defines pod-level metrics configuration. Specifies the metric identification and target values for pod-based autoscaling.</p> <p>Appears in: - AIMServiceMetricsSpec</p> Field Description Default Validation <code>metric</code> AIMServicePodMetric Metric contains the metric identification and backend configuration.Defines which metrics to collect and how to query them. <code>target</code> AIMServiceMetricTarget Target specifies the target value for the metric.The autoscaler will scale to maintain this target value."},{"location":"reference/api/v1alpha1/#aimserviceroutingstatus","title":"AIMServiceRoutingStatus","text":"<p>AIMServiceRoutingStatus captures observed routing details.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>path</code> string Path is the HTTP path prefix used when routing is enabled.Example: <code>/tenant/svc-uuid</code> Optional: {}"},{"location":"reference/api/v1alpha1/#aimserviceruntimeconfig","title":"AIMServiceRuntimeConfig","text":"<p>AIMServiceRuntimeConfig contains runtime configuration fields that apply to services. This struct is shared between AIMService.spec (inlined) and AIMRuntimeConfigCommon, allowing services to override these specific runtime settings while inheriting defaults from namespace/cluster RuntimeConfigs.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceSpec</p> Field Description Default Validation <code>storage</code> AIMStorageConfig Storage configures storage defaults for this service's PVCs and caches.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing configuration for this service.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.When set on AIMService, these take highest precedence in the merge hierarchy.When set on RuntimeConfig, these provide namespace/cluster-level defaults.Merge order (highest to lowest): Service.Env &gt; Template.Env &gt; RuntimeConfig.Env &gt; Profile.Env Optional: {}"},{"location":"reference/api/v1alpha1/#aimserviceruntimestatus","title":"AIMServiceRuntimeStatus","text":"<p>AIMServiceRuntimeStatus captures runtime status including replica counts from HPA.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>currentReplicas</code> integer CurrentReplicas is the current number of replicas as reported by the HPA. Optional: {}  <code>desiredReplicas</code> integer DesiredReplicas is the desired number of replicas as determined by the HPA. Optional: {}  <code>minReplicas</code> integer MinReplicas is the minimum number of replicas configured for autoscaling. Optional: {}  <code>maxReplicas</code> integer MaxReplicas is the maximum number of replicas configured for autoscaling. Optional: {}  <code>replicas</code> string Replicas is a formatted display string for kubectl output.Shows \"current\" for fixed replicas or \"current/desired (min-max)\" for autoscaling. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicespec","title":"AIMServiceSpec","text":"<p>AIMServiceSpec defines the desired state of AIMService.</p> <p>Binds a canonical model to an AIMServiceTemplate and configures replicas, caching behavior, and optional overrides. The template governs the base runtime selection knobs, while the overrides field allows service-specific customization.</p> <p>Appears in: - AIMService</p> Field Description Default Validation <code>model</code> AIMServiceModel Model specifies which model to deploy using one of the available reference methods.Use <code>name</code> to reference an existing AIMModel/AIMClusterModel by name, or use <code>image</code>to specify a container image URI directly (which will auto-create a model if needed). <code>template</code> AIMServiceTemplateConfig Template contains template selection and configuration.Use Template.Name to specify an explicit template, or omit to auto-select. Optional: {}  <code>caching</code> AIMServiceCachingConfig Caching controls caching behavior for this service.When nil, defaults to Shared mode. Optional: {}  <code>cacheModel</code> boolean DEPRECATED: Use Caching.Mode instead. This field will be removed in a future version.This field is no longer honored by the controller. Optional: {}  <code>replicas</code> integer Replicas specifies the number of replicas for this service.When not specified, defaults to 1 replica.This value overrides any replica settings from the template.For autoscaling, use MinReplicas and MaxReplicas instead. 1 Optional: {}  <code>minReplicas</code> integer MinReplicas specifies the minimum number of replicas for autoscaling.Defaults to 1. Scale to zero is not supported.When specified with MaxReplicas, enables autoscaling for the service. Minimum: 1 Optional: {}  <code>maxReplicas</code> integer MaxReplicas specifies the maximum number of replicas for autoscaling.Required when MinReplicas is set or when AutoScaling configuration is provided. Minimum: 1 Optional: {}  <code>autoScaling</code> AIMServiceAutoScaling AutoScaling configures advanced autoscaling behavior using KEDA.Supports custom metrics from OpenTelemetry backend.When specified, MinReplicas and MaxReplicas should also be set. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>storage</code> AIMStorageConfig Storage configures storage defaults for this service's PVCs and caches.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing configuration for this service.When set, these values override namespace/cluster runtime config defaults. Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.When set on AIMService, these take highest precedence in the merge hierarchy.When set on RuntimeConfig, these provide namespace/cluster-level defaults.Merge order (highest to lowest): Service.Env &gt; Template.Env &gt; RuntimeConfig.Env &gt; Profile.Env Optional: {}  <code>resources</code> ResourceRequirements Resources overrides the container resource requirements for this service.When specified, these values take precedence over the template and image defaults. Optional: {}  <code>overrides</code> AIMServiceOverrides Overrides allows overriding specific template parameters for this service.When specified, these values take precedence over the template values. Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. Optional: {}  <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for the inference workload.This service account is used by the deployed inference pods.If empty, the default service account for the namespace is used. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicestatus","title":"AIMServiceStatus","text":"<p>AIMServiceStatus defines the observed state of AIMService.</p> <p>Appears in: - AIMService</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of template state. <code>resolvedRuntimeConfig</code> AIMResolvedReference ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. Optional: {}  <code>resolvedModel</code> AIMResolvedReference ResolvedModel captures metadata about the image that was resolved. Optional: {}  <code>status</code> AIMStatus Status represents the current high\u2011level status of the service lifecycle.Values: <code>Pending</code>, <code>Starting</code>, <code>Running</code>, <code>Degraded</code>, <code>Failed</code>. Pending Enum: [Pending Starting Running Degraded Failed]  <code>routing</code> AIMServiceRoutingStatus Routing surfaces information about the configured HTTP routing, when enabled. Optional: {}  <code>resolvedTemplate</code> AIMResolvedReference ResolvedTemplate captures metadata about the template that satisfied the reference. <code>cache</code> AIMServiceCacheStatus Cache captures cache-related status for this service. Optional: {}  <code>runtime</code> AIMServiceRuntimeStatus Runtime captures runtime status including replica counts. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicetemplate","title":"AIMServiceTemplate","text":"<p>AIMServiceTemplate is the Schema for namespace-scoped AIM service templates.</p> <p>Appears in: - AIMServiceTemplateList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMServiceTemplate</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMServiceTemplateSpec <code>status</code> AIMServiceTemplateStatus"},{"location":"reference/api/v1alpha1/#aimservicetemplateconfig","title":"AIMServiceTemplateConfig","text":"<p>AIMServiceTemplateConfig contains template selection configuration for AIMService.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>name</code> string Name is the name of the AIMServiceTemplate or AIMClusterServiceTemplate to use.The template selects the runtime profile and GPU parameters.When not specified, a template will be automatically selected based on the model. Optional: {}  <code>allowUnoptimized</code> boolean AllowUnoptimized, if true, will allow automatic selection of templatesthat resolve to an unoptimized profile. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicetemplatelist","title":"AIMServiceTemplateList","text":"<p>AIMServiceTemplateList contains a list of AIMServiceTemplate.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMServiceTemplateList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMServiceTemplate array"},{"location":"reference/api/v1alpha1/#aimservicetemplatescope","title":"AIMServiceTemplateScope","text":"<p>Underlying type: string</p> <p>AIMServiceTemplateScope is retained for backwards compatibility with existing consumers.</p> <p>Validation: - Enum: [Namespace Cluster Unknown]</p> <p>Appears in: - AIMTemplateCacheSpec</p>"},{"location":"reference/api/v1alpha1/#aimservicetemplatespec","title":"AIMServiceTemplateSpec","text":"<p>AIMServiceTemplateSpec defines the desired state of AIMServiceTemplate (namespace-scoped).</p> <p>A namespaced and versioned template that selects a runtime profile for a given AIM model (by canonical name). Templates are intentionally narrow: they describe runtime selection knobs for the AIM container and do not redefine the full Kubernetes deployment shape.</p> <p>Appears in: - AIMServiceTemplate</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for each replica.For GPU models, defines the GPU count and model types required for deployment.For CPU-only models, defines CPU resource requirements.This field is immutable after creation. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. Optional: {}  <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. Optional: {}  <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. Optional: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. Optional: {}  <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use.When set, the discovery job will be instructed to use this specific profile. Optional: {}  <code>type</code> AIMProfileType Type indicates the optimization level of this template.- optimized: Template has been tuned for performance- preview: Template is experimental/pre-release- unoptimized: Default, no specific optimizations appliedWhen nil, the type is determined by discovery. When set, overrides discovery. Enum: [optimized preview unoptimized] Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.These variables are passed to the inference runtime and can be usedto configure runtime behavior, authentication, or other settings. Optional: {}  <code>caching</code> AIMTemplateCachingConfig Caching configures model caching behavior for this namespace-scoped template.When enabled, models will be cached using the specified environment variablesduring download. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicetemplatespeccommon","title":"AIMServiceTemplateSpecCommon","text":"<p>Appears in: - AIMClusterServiceTemplateSpec - AIMServiceTemplateSpec</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}  <code>hardware</code> AIMHardwareRequirements Hardware specifies GPU and CPU requirements for each replica.For GPU models, defines the GPU count and model types required for deployment.For CPU-only models, defines CPU resource requirements.This field is immutable after creation. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. Optional: {}  <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. Optional: {}  <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. Optional: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. Optional: {}  <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use.When set, the discovery job will be instructed to use this specific profile. Optional: {}  <code>type</code> AIMProfileType Type indicates the optimization level of this template.- optimized: Template has been tuned for performance- preview: Template is experimental/pre-release- unoptimized: Default, no specific optimizations appliedWhen nil, the type is determined by discovery. When set, overrides discovery. Enum: [optimized preview unoptimized] Optional: {}  <code>env</code> EnvVar array Env specifies environment variables for inference containers.These variables are passed to the inference runtime and can be usedto configure runtime behavior, authentication, or other settings. Optional: {}"},{"location":"reference/api/v1alpha1/#aimservicetemplatestatus","title":"AIMServiceTemplateStatus","text":"<p>AIMServiceTemplateStatus defines the observed state of AIMServiceTemplate.</p> <p>Appears in: - AIMClusterServiceTemplate - AIMServiceTemplate</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of template state. <code>resolvedRuntimeConfig</code> AIMResolvedReference ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. Optional: {}  <code>resolvedModel</code> AIMResolvedReference ResolvedModel captures metadata about the image that was resolved. Optional: {}  <code>resolvedCache</code> AIMResolvedReference ResolvedCache captures metadata about which cache is used for this template Optional: {}  <code>resolvedHardware</code> AIMHardwareRequirements ResolvedHardware contains the resolved hardware requirements for this template.These values are computed from discovery results and spec defaults, and representwhat will actually be used when creating InferenceServices.Resolution order: discovery output &gt; spec values &gt; defaults. Optional: {}  <code>resolvedNodeAffinity</code> NodeAffinity ResolvedNodeAffinity contains the computed node affinity rules for GPU scheduling.This is derived from GPU model and minVRAM requirements, merged with any user-specifiedaffinity from the spec. The service controller uses this directly when creating InferenceServices. Optional: {}  <code>hardwareSummary</code> string HardwareSummary is a human-readable display string for the hardware requirements.Format: \"{count} x {model}\" for GPU (e.g., \"2 x MI300X\") or \"CPU\" for CPU-only.This is a computed field for display purposes only. Optional: {}  <code>status</code> AIMStatus Status represents the current high\u2011level status of the template lifecycle.Values: <code>Pending</code>, <code>Progressing</code>, <code>Ready</code>, <code>Degraded</code>, <code>Failed</code>. Pending Enum: [Pending Progressing Ready Degraded Failed NotAvailable]  <code>modelSources</code> AIMModelSource array ModelSources list the models that this template requires to run. These are the models that will becached, if this template is cached. <code>profile</code> AIMProfile Profile contains the full discovery result profile as a free-form JSON object.This includes metadata, engine args, environment variables, and model details. <code>discoveryJob</code> AIMResolvedReference DiscoveryJob is a reference to the job that was run for discovery <code>discovery</code> DiscoveryState Discovery contains state tracking for the discovery process, includingretry attempts and backoff timing for the circuit breaker pattern. Optional: {}"},{"location":"reference/api/v1alpha1/#aimstorageconfig","title":"AIMStorageConfig","text":"<p>AIMStorageConfig configures storage defaults for artifacts and PVCs.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceRuntimeConfig - AIMServiceSpec</p> Field Description Default Validation <code>defaultStorageClassName</code> string DefaultStorageClassName specifies the storage class to use for artifacts and PVCswhen the consuming resource (AIMArtifact, AIMTemplateCache, AIMServiceTemplate) does notspecify a storage class. If this field is empty, the cluster's default storage class is used. Optional: {}  <code>pvcHeadroomPercent</code> integer PVCHeadroomPercent specifies the percentage of extra space to add to PVCsfor model storage. This accounts for filesystem overhead and temporary filesduring model loading. The value represents a percentage (e.g., 10 means 10% extra space).If not specified, defaults to 10%. 10 Minimum: 0 Optional: {}"},{"location":"reference/api/v1alpha1/#aimtemplatecache","title":"AIMTemplateCache","text":"<p>AIMTemplateCache pre-warms artifacts for a specified template.</p> <p>Appears in: - AIMTemplateCacheList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMTemplateCache</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMTemplateCacheSpec <code>status</code> AIMTemplateCacheStatus"},{"location":"reference/api/v1alpha1/#aimtemplatecachelist","title":"AIMTemplateCacheList","text":"<p>AIMTemplateCacheList contains a list of AIMTemplateCache.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.eai.amd.com/v1alpha1</code> <code>kind</code> string <code>AIMTemplateCacheList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMTemplateCache array"},{"location":"reference/api/v1alpha1/#aimtemplatecachemode","title":"AIMTemplateCacheMode","text":"<p>Underlying type: string</p> <p>AIMTemplateCacheMode controls the ownership behavior of artifacts created by a template cache.</p> <p>Validation: - Enum: [Dedicated Shared]</p> <p>Appears in: - AIMTemplateCacheSpec</p> Field Description <code>Dedicated</code> TemplateCacheModeDedicated means artifacts have owner references to the template cache.When the template cache is deleted, all its artifacts are garbage collected.Use this mode for service-specific caches that should be cleaned up with the service. <code>Shared</code> TemplateCacheModeShared means artifacts have no owner references.artifacts persist independently of template cache lifecycle and can be shared.This is the default mode for long-lived, reusable caches."},{"location":"reference/api/v1alpha1/#aimtemplatecachespec","title":"AIMTemplateCacheSpec","text":"<p>AIMTemplateCacheSpec defines the desired state of AIMTemplateCache</p> <p>Appears in: - AIMTemplateCache</p> Field Description Default Validation <code>templateName</code> string TemplateName is the name of the AIMServiceTemplate or AIMClusterServiceTemplate to cache.The controller will first look for a namespace-scoped AIMServiceTemplate in the same namespace.If not found, it will look for a cluster-scoped AIMClusterServiceTemplate with the same name.Namespace-scoped templates take priority over cluster-scoped templates. MinLength: 1  <code>templateScope</code> AIMServiceTemplateScope TemplateScope indicates whether the template is namespace-scoped or cluster-scoped.This field is set by the controller during template resolution. Enum: [Namespace Cluster Unknown] Required: {}  <code>env</code> EnvVar array Env specifies environment variables to use for authentication when downloading models.These variables are used for authentication with model registries (e.g., HuggingFace tokens). Optional: {}  <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. Optional: {}  <code>storageClassName</code> string StorageClassName specifies the storage class for cache volumes.When not specified, uses the cluster default storage class. Optional: {}  <code>downloadImage</code> string DownloadImage specifies the container image used to download and initialize artifacts.When not specified, the controller uses the default model download image. Optional: {}  <code>modelSources</code> AIMModelSource array ModelSources specifies the model sources to cache for this template.These sources are typically copied from the resolved template's model sources. Optional: {}  <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}  <code>mode</code> AIMTemplateCacheMode Mode controls the ownership behavior of artifacts created by this template cache.- Dedicated: artifacts are owned by this template cache and garbage collected when it's deleted.- Shared (default): artifacts have no owner references and persist independently.When a Shared template cache encounters artifacts with owner references, it promotes themto shared by removing the owner references, ensuring they persist for long-term use. Shared Enum: [Dedicated Shared] Optional: {}"},{"location":"reference/api/v1alpha1/#aimtemplatecachestatus","title":"AIMTemplateCacheStatus","text":"<p>AIMTemplateCacheStatus defines the observed state of AIMTemplateCache</p> <p>Appears in: - AIMTemplateCache</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of the template cache state. <code>resolvedRuntimeConfig</code> AIMResolvedReference ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. Optional: {}  <code>status</code> AIMStatus Status represents the current high-level status of the template cache. Pending Enum: [Pending Progressing Ready Failed Degraded NotAvailable]  <code>resolvedTemplateKind</code> string ResolvedTemplateKind indicates whether the template resolved to a namespace-scopedAIMServiceTemplate or cluster-scoped AIMClusterServiceTemplate.Values: \"AIMServiceTemplate\", \"AIMClusterServiceTemplate\" <code>artifacts</code> object (keys:string, values:AIMResolvedArtifact) Artifacts maps model names to their resolved AIMArtifact resources. Optional: {}"},{"location":"reference/api/v1alpha1/#aimtemplatecachingconfig","title":"AIMTemplateCachingConfig","text":"<p>AIMTemplateCachingConfig configures model caching behavior for namespace-scoped templates.</p> <p>Appears in: - AIMServiceTemplateSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled controls whether caching is enabled for this template.Defaults to <code>false</code>. false <code>env</code> EnvVar array Env specifies environment variables to use when downloading the model for caching.These variables are available to the model download process and can be usedto configure download behavior, authentication, proxies, etc.If not set, falls back to the template's top-level Env field. Optional: {}"},{"location":"reference/api/v1alpha1/#aimtemplateprofile","title":"AIMTemplateProfile","text":"<p>AIMTemplateProfile declares profile variables for template selection. Used in AIMCustomTemplate to specify optimization targets.</p> <p>Appears in: - AIMCustomTemplate</p> Field Description Default Validation <code>metric</code> AIMMetric Metric specifies the optimization target (e.g., latency, throughput). Enum: [latency throughput] Optional: {}  <code>precision</code> AIMPrecision Precision specifies the numerical precision (e.g., fp8, fp16, bf16). Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8] Optional: {}"},{"location":"reference/api/v1alpha1/#discoverystate","title":"DiscoveryState","text":"<p>DiscoveryState tracks the discovery process state for circuit breaker logic. This enables exponential backoff and prevents infinite retry loops when discovery jobs fail persistently.</p> <p>Appears in: - AIMServiceTemplateStatus</p> Field Description Default Validation <code>attempts</code> integer Attempts is the number of discovery job attempts that have been made.This counter increments each time a new discovery job is created after a failure. Optional: {}  <code>lastAttemptTime</code> Time LastAttemptTime is the timestamp of the most recent discovery job creation.Used to calculate exponential backoff before the next retry. Optional: {}  <code>lastFailureReason</code> string LastFailureReason captures the reason for the most recent discovery failure.Used to classify failures as terminal vs transient. Optional: {}  <code>specHash</code> string SpecHash is a hash of the template spec fields that affect discovery.When the spec changes, the circuit breaker resets to allow fresh attempts. Optional: {}"},{"location":"reference/api/v1alpha1/#downloadprogress","title":"DownloadProgress","text":"<p>DownloadProgress represents the download progress for a artifact</p> <p>Appears in: - AIMArtifactStatus</p> Field Description Default Validation <code>totalBytes</code> integer TotalBytes is the expected total size of the download in bytes Optional: {}  <code>downloadedBytes</code> integer DownloadedBytes is the number of bytes downloaded so far Optional: {}  <code>percentage</code> integer Percentage is the download progress as a percentage (0-100) Maximum: 100 Minimum: 0 Optional: {}  <code>displayPercentage</code> string DisplayPercentage is a human-readable progress string (e.g., \"45 %\")This field is automatically populated from Progress.Percentage Optional: {}"},{"location":"reference/api/v1alpha1/#downloadstate","title":"DownloadState","text":"<p>DownloadState represents the current download attempt state, updated by the downloader pod</p> <p>Appears in: - AIMArtifactStatus</p> Field Description Default Validation <code>protocol</code> string Protocol is the download protocol currently in use (e.g., \"XET\", \"HF_TRANSFER\", \"HTTP\") Optional: {}  <code>attempt</code> integer Attempt is the current attempt number (1-based) Optional: {}  <code>totalAttempts</code> integer TotalAttempts is the total number of attempts configured via AIM_DOWNLOADER_PROTOCOL Optional: {}  <code>protocolSequence</code> string ProtocolSequence is the configured protocol sequence (e.g., \"HF_TRANSFER,XET\") Optional: {}  <code>message</code> string Message is a human-readable status message from the downloader Optional: {}"},{"location":"reference/api/v1alpha1/#imagemetadata","title":"ImageMetadata","text":"<p>ImageMetadata contains metadata extracted from or provided for a container image.</p> <p>Appears in: - AIMModelSpec - AIMModelStatus</p> Field Description Default Validation <code>model</code> ModelMetadata Model contains AMD Silogen model-specific metadata. Optional: {}  <code>oci</code> OCIMetadata OCI contains standard OCI image metadata. Optional: {}  <code>originalLabels</code> object (keys:string, values:string) OriginalLabels contains the raw OCI image labels as a JSON object.This preserves all labels from the image, including those not mapped to structured fields. Optional: {}"},{"location":"reference/api/v1alpha1/#modelmetadata","title":"ModelMetadata","text":"<p>ModelMetadata contains AMD Silogen model-specific metadata extracted from image labels.</p> <p>Appears in: - ImageMetadata</p> Field Description Default Validation <code>canonicalName</code> string CanonicalName is the canonical model identifier (e.g., mistralai/Mixtral-8x22B-Instruct-v0.1).Extracted from: org.amd.silogen.model.canonicalName Optional: {}  <code>source</code> string Source is the URL where the model can be found.Extracted from: org.amd.silogen.model.source Optional: {}  <code>tags</code> string array Tags are descriptive tags (e.g., [\"text-generation\", \"chat\", \"instruction\"]).Extracted from: org.amd.silogen.model.tags (comma-separated) Optional: {}  <code>versions</code> string array Versions lists available versions.Extracted from: org.amd.silogen.model.versions (comma-separated) Optional: {}  <code>variants</code> string array Variants lists model variants.Extracted from: org.amd.silogen.model.variants (comma-separated) Optional: {}  <code>hfTokenRequired</code> boolean HFTokenRequired indicates if a HuggingFace token is required.Extracted from: org.amd.silogen.hfToken.required Optional: {}  <code>title</code> string Title is the Silogen-specific title for the model.Extracted from: org.amd.silogen.title Optional: {}  <code>descriptionFull</code> string DescriptionFull is the full description.Extracted from: org.amd.silogen.description.full Optional: {}  <code>releaseNotes</code> string ReleaseNotes contains release notes for this version.Extracted from: org.amd.silogen.release.notes Optional: {}  <code>recommendedDeployments</code> RecommendedDeployment array RecommendedDeployments contains recommended deployment configurations.Extracted from: org.amd.silogen.model.recommendedDeployments (parsed from JSON array) Optional: {}"},{"location":"reference/api/v1alpha1/#modelsourcefilter","title":"ModelSourceFilter","text":"<p>ModelSourceFilter defines a pattern for discovering images. Supports multiple formats: - Repository patterns: \"org/repo\" - matches repositories with wildcards - Repository with tag: \"org/repo:1.0.0\" - exact tag match - Full URI: \"ghcr.io/org/repo:1.0.0\" - overrides registry and tag - Full URI with wildcard: \"ghcr.io/org/repo\" - overrides registry, matches pattern</p> <p>Appears in: - AIMClusterModelSourceSpec</p> Field Description Default Validation <code>image</code> string Image pattern with wildcard and full URI support.Supported formats:- Repository pattern: \"amdenterpriseai/aim-\"- Repository with tag: \"silogen/aim-llama:1.0.0\" (overrides versions field)- Full URI: \"ghcr.io/silogen/aim-google-gemma-3-1b-it:0.8.1-rc1\" (overrides spec.registry and versions)- Full URI with wildcard: \"ghcr.io/silogen/aim-\" (overrides spec.registry)When a full URI is specified (including registry like ghcr.io), only images from thatregistry will match. When a tag is included, it takes precedence over the versions field.Wildcard: * matches any sequence of characters. MaxLength: 512  <code>exclude</code> string array Exclude lists specific repository names to skip (exact match on repository name only, not registry).Useful for excluding base images or experimental versions.Examples:- [\"amdenterpriseai/aim-base\", \"amdenterpriseai/aim-experimental\"]- [\"silogen/aim-base\"] - works with \"ghcr.io/silogen/aim-*\" (registry is not checked in exclusion)Note: Exclusions match against repository names (e.g., \"silogen/aim-base\"), not full URIs. Optional: {}  <code>versions</code> string array Versions specifies semantic version constraints for this filter.If specified, overrides the global Versions field.Only tags that parse as valid semver are considered (including prereleases like 0.8.1-rc1).Ignored if the Image field includes an explicit tag (e.g., \"repo:1.0.0\").Examples: \"&gt;=1.0.0\", \"&lt;2.0.0\", \"~1.2.0\" (patch updates), \"^1.0.0\" (minor updates)Prerelease versions (e.g., 0.8.1-rc1) are supported and follow semver rules:- 0.8.1-rc1 matches \"&gt;=0.8.0\" (prerelease is part of version 0.8.1)- Use \"&gt;=0.8.1-rc1\" to match only that prerelease or higher- Leave empty to match all tags (including prereleases and non-semver tags) Optional: {}"},{"location":"reference/api/v1alpha1/#ocimetadata","title":"OCIMetadata","text":"<p>OCIMetadata contains standard OCI image metadata extracted from image labels.</p> <p>Appears in: - ImageMetadata</p> Field Description Default Validation <code>title</code> string Title is the human-readable title.Extracted from: org.opencontainers.image.title Optional: {}  <code>description</code> string Description is a brief description.Extracted from: org.opencontainers.image.description Optional: {}  <code>licenses</code> string Licenses is the SPDX license identifier(s).Extracted from: org.opencontainers.image.licenses Optional: {}  <code>vendor</code> string Vendor is the organization that produced the image.Extracted from: org.opencontainers.image.vendor Optional: {}  <code>authors</code> string Authors is contact details of the authors.Extracted from: org.opencontainers.image.authors Optional: {}  <code>source</code> string Source is the URL to the source code repository.Extracted from: org.opencontainers.image.source Optional: {}  <code>documentation</code> string Documentation is the URL to documentation.Extracted from: org.opencontainers.image.documentation Optional: {}  <code>created</code> string Created is the creation timestamp.Extracted from: org.opencontainers.image.created Optional: {}  <code>revision</code> string Revision is the source control revision.Extracted from: org.opencontainers.image.revision Optional: {}  <code>version</code> string Version is the image version.Extracted from: org.opencontainers.image.version Optional: {}"},{"location":"reference/api/v1alpha1/#recommendeddeployment","title":"RecommendedDeployment","text":"<p>RecommendedDeployment describes a recommended deployment configuration for a model.</p> <p>Appears in: - ModelMetadata</p> Field Description Default Validation <code>gpuModel</code> string GPUModel is the GPU model name (e.g., MI300X, MI325X) Optional: {}  <code>gpuCount</code> integer GPUCount is the number of GPUs required Optional: {}  <code>precision</code> string Precision is the recommended precision (e.g., fp8, fp16, bf16) Optional: {}  <code>metric</code> string Metric is the optimization target (e.g., latency, throughput) Optional: {}  <code>profileId</code> string ProfileId is the unique identifier of the AIM profile for this deployment.When set, templates created from this deployment will use this profile IDto deterministically select the correct runtime profile in the AIM container. Optional: {}  <code>description</code> string Description provides additional context about this deployment configuration Optional: {}"},{"location":"reference/api/v1alpha1/#runtimeconfigref","title":"RuntimeConfigRef","text":"<p>Appears in: - AIMArtifactSpec - AIMClusterServiceTemplateSpec - AIMModelSpec - AIMServiceSpec - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMTemplateCacheSpec</p> Field Description Default Validation <code>runtimeConfigName</code> string Name is the name of the runtime config to use for this resource. If a runtime config with this name exists bothas a namespace and a cluster runtime config, the values are merged together, the namespace config taking priorityover the cluster config when there are conflicts. If this field is empty or set to <code>default</code>, the namespace / clusterruntime config with the name <code>default</code> is used, if it exists. Optional: {}"}]}